<!-- <div align="center">
<h1>
  âœ¨Skywork
</h1>
</div> -->
<div align="center"><img src="misc/skywork_logo.jpeg" width="550"/></div>

<p align="center">
ğŸ¤— <a href="https://huggingface.co/Skywork" target="_blank">Hugging Face</a> â€¢ ğŸ¤– <a href="https://modelscope.cn/organization/Skywork" target="_blank">ModelScope</a> â€¢ ğŸ’¬ <a href="https://github.com/SkyworkAI/Skywork/blob/main/misc/wechat.png?raw=true" target="_blank">WeChat</a>â€¢ ğŸ“œ<a href="https://arxiv.org/" target="_blank">Tech Report</a>â€¢ ğŸ§®<a href="https://arxiv.org/" target="_blank">Skymath Paper</a>
</p>


<div align="center">


[ğŸ‰å¤©å·¥åœ¨çº¿å¯¹è¯å¹³å°å·²æ­£å¼å‘å…¬ä¼—å¼€æ”¾](https://sso.tiangong.cn/?redirect=https://model-platform.tiangong.cn/overview&client_id=200005)

</div>



<div align="center">


[![GitHub Stars](https://img.shields.io/github/stars/SkyworkAI/Skywork)](https://github.com/SkyworkAI/Skywork/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/SkyworkAI/Skywork)](https://github.com/SkyworkAI/Skywork/fork)
</div>



# æ¨¡å‹ä»‹ç»ï¼ˆIntroductionï¼‰
**Skywork-13B-Math**æ¨¡å‹ç»è¿‡ä¸“é—¨çš„æ•°å­¦èƒ½åŠ›å¼ºåŒ–è®­ç»ƒã€‚åœ¨13Bè§„æ¨¡çš„æ¨¡å‹ä¸­ï¼ŒSkywork-13B-Mathæ¨¡å‹åœ¨GSM8Kè¯„æµ‹ä¸Šå¾—åˆ†ç¬¬ä¸€ï¼ŒåŒæ—¶åœ¨MATHæ•°æ®é›†ä»¥åŠCMATHä¸Šä¹Ÿè¡¨ç°ä¼˜å¼‚ï¼Œå¤„äº13Bæ¨¡å‹é¡¶å°–æ°´å¹³ã€‚

**Skywork-13B-Math**: Skywork-13B-Math model has undergone specialized training to enhance its mathematical abilities. In the 13B-scale model, the Skywork-13B-Math model ranked first in the GSM8K evaluation, and it also performed exceptionally well on the MATH dataset and CMATH, placing it among the top-level 13B models.


å¦‚æœæ‚¨å¸Œæœ›äº†è§£æ›´å¤šçš„ä¿¡æ¯ï¼Œå¦‚è®­ç»ƒæ–¹æ¡ˆï¼Œè¯„ä¼°æ–¹æ³•ï¼Œè¯·å‚è€ƒæˆ‘ä»¬çš„[æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/skywork-tech-report)å’Œ[Skywork-Math](https://arxiv.org/skywork-tech-report)è®ºæ–‡ã€‚

If you are interested in more training and evaluation details, please refer to our [technical report](https://arxiv.org/skywork-tech-report) and [Skywork-Math]((https://arxiv.org/skywork-tech-report)) paper.


# å¿«é€Ÿå¼€å§‹ï¼ˆQuickstartï¼‰
æˆ‘ä»¬å°†æ¨¡å‹å‚æ•°ã€é…ç½®æ–‡ä»¶ã€tokenizerç­‰åœ¨huggingfaceå’Œmodelscopeä¸Šè¿›è¡Œäº†å¼€æºã€‚

We have open-sourced the model parameters, configuration files, tokenizer, and more on Huggingface and Modelscope.

## ä¾èµ–å®‰è£…ï¼ˆRequirementsï¼‰
- Python 3.8åŠä»¥ä¸Šç‰ˆæœ¬
- Pytorch 2.0åŠä»¥ä¸Šç‰ˆæœ¬
- CUDAå»ºè®®ä½¿ç”¨11.4ä»¥ä¸Šç‰ˆæœ¬ã€‚

Skywork-13B-Baseæ¨¡å‹ï¼ŒSkywork-13B-Chatæ¨¡å‹å’ŒSkywork-13B-Mathæ¨¡å‹è¿è¡Œä¸‹é¢çš„è„šæœ¬è¿›è¡ŒPythonä¾èµ–å®‰è£…ã€‚

- Python 3.8 and above
- Pytorch 2.0 and above 
- CUDA 11.4 and above are recommended.

Skywork-13B-Base model, Skywork-13B-Chat model, and Skywork-13B-Math model run the following script for Python dependency installation:

```shell
pip install -r requirements.txt 
```
## Huggingfaceæ¨¡å‹æµ‹è¯•ï¼ˆDemostrationï¼‰


### Math æ¨¡å‹æ¨ç†ï¼ˆMath Model Inferecenï¼‰
```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

tokenizer_path = ""
checkpoint_path = ""

tokenizer = AutoTokenizer.from_pretrained(
    tokenizer_path, use_fast=False, trust_remote_code=True, padding_side='left')

model = AutoModelForCausalLM.from_pretrained(
    checkpoint_path, device_map="auto", trust_remote_code=True).eval()
tokenizer.add_tokens(["[USER]", "[BOT]", "[SEP]"])

def special_encode(input, tokenizer):
    raw_str = "[USER]%s[SEP][BOT]" % input.strip().replace("\r", "")
    eos_id = tokenizer.eos_token_id
    bos_id = tokenizer.bos_token_id
    sep_id = tokenizer.encode("[SEP]")[-1]
    res_id = [eos_id, bos_id]
    arr = raw_str.split("[SEP]")
    for elem_idx in range(len(arr)):
        elem = arr[elem_idx]
        elem_id = tokenizer.encode(elem)[1:]
        res_id += elem_id
        if elem_idx < len(arr) - 1:
            res_id.append(sep_id)

    return res_id
if __name__ == '__main__':
    text = "å°ç‹è¦å°†150åƒå…‹å«è¯é‡20%çš„å†œè¯ç¨€é‡Šæˆå«è¯é‡5%çš„è¯æ°´ï¼éœ€è¦åŠ æ°´å¤šå°‘åƒå…‹ï¼Ÿ"
    text_token_ids = torch.tensor(special_encode(
        text, tokenizer)).to(model.device).reshape(1, -1)
    response = model.generate(text_token_ids, do_sample=False, max_length=512)
    response_text = tokenizer.decode(response.cpu()[0], skip_special_tokens=True).split(
        "[BOT]")[-1].split("[SEP]")[0].strip()
    print(response_text)   
    """è¾“å‡ºç»“æœï¼š
    é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—å‡º150åƒå…‹å«è¯é‡20%çš„å†œè¯ä¸­å«æœ‰å¤šå°‘åƒå…‹çš„è¯ã€‚\n\n150åƒå…‹ * 20% = 30åƒå…‹\n\nç„¶åï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—å‡ºè¦å¾—åˆ°å«è¯é‡5%çš„è¯æ°´ï¼Œéœ€è¦å¤šå°‘åƒå…‹çš„è¯æ°´ã€‚\n\n30åƒå…‹ / 5% = 600åƒå…‹\n\næœ€åï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—å‡ºéœ€è¦åŠ å¤šå°‘åƒå…‹çš„æ°´ã€‚\n\n600åƒå…‹ - 150åƒå…‹ = 450åƒå…‹\n\næ‰€ä»¥ç­”æ¡ˆæ˜¯ï¼Œå°ç‹éœ€è¦åŠ 450åƒå…‹çš„æ°´ã€‚
    """ 
```

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

tokenizer_path = ""
checkpoint_path = ""

tokenizer = AutoTokenizer.from_pretrained(
    tokenizer_path, use_fast=False, trust_remote_code=True, padding_side='left')

model = AutoModelForCausalLM.from_pretrained(
    checkpoint_path, device_map="auto", trust_remote_code=True).eval()
tokenizer.add_tokens(["[USER]", "[BOT]", "[SEP]"])

def special_encode(input, tokenizer):
    raw_str = "[USER]%s[SEP][BOT]" % input.strip().replace("\r", "")
    eos_id = tokenizer.eos_token_id
    bos_id = tokenizer.bos_token_id
    sep_id = tokenizer.encode("[SEP]")[-1]
    res_id = [eos_id, bos_id]
    arr = raw_str.split("[SEP]")
    for elem_idx in range(len(arr)):
        elem = arr[elem_idx]
        elem_id = tokenizer.encode(elem)[1:]
        res_id += elem_id
        if elem_idx < len(arr) - 1:
            res_id.append(sep_id)

    return res_id
if __name__ == '__main__':
    text="Janetâ€™s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?"
    text_token_ids = torch.tensor(special_encode(
        text, tokenizer)).to(model.device).reshape(1, -1)
    response = model.generate(text_token_ids, do_sample=False, max_length=512)
    response_text = tokenizer.decode(response.cpu()[0], skip_special_tokens=True).split(
        "[BOT]")[-1].split("[SEP]")[0].strip()
    print(response_text)    
    """Skywork-13B-Math Response:
    First, we need to find out how many eggs Janet has left after eating for breakfast and baking for her friends. \n\nShe has 16 eggs per day, eats 3 for breakfast and uses 4 for baking. So, 16 - 3 - 4 = 9 eggs are left for selling at the farmers' market.\n\nSince she sells each egg for $2, she makes 9 * 2 = $<<9*2=18>>18 every day at the farmers' market.\n\nSo, the answer is $18.
    """
```

# å£°æ˜å’Œåè®®ï¼ˆDeclaration and License Aggrementï¼‰


## å£°æ˜ï¼ˆDeclarationï¼‰

æˆ‘ä»¬åœ¨æ­¤å£°æ˜ï¼Œä¸è¦åˆ©ç”¨Skyworkæ¨¡å‹è¿›è¡Œä»»ä½•å±å®³å›½å®¶ç¤¾ä¼šå®‰å…¨æˆ–è¿æ³•çš„æ´»åŠ¨ã€‚å¦å¤–ï¼Œæˆ‘ä»¬ä¹Ÿè¦æ±‚ä½¿ç”¨è€…ä¸è¦å°† Skywork æ¨¡å‹ç”¨äºæœªç»é€‚å½“å®‰å…¨å®¡æŸ¥å’Œå¤‡æ¡ˆçš„äº’è”ç½‘æœåŠ¡ã€‚æˆ‘ä»¬å¸Œæœ›æ‰€æœ‰çš„ä½¿ç”¨è€…éƒ½èƒ½éµå®ˆè¿™ä¸ªåŸåˆ™ï¼Œç¡®ä¿ç§‘æŠ€çš„å‘å±•èƒ½åœ¨è§„èŒƒå’Œåˆæ³•çš„ç¯å¢ƒä¸‹è¿›è¡Œã€‚

æˆ‘ä»¬å·²ç»å°½æˆ‘ä»¬æ‰€èƒ½ï¼Œæ¥ç¡®ä¿æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ•°æ®çš„åˆè§„æ€§ã€‚ç„¶è€Œï¼Œå°½ç®¡æˆ‘ä»¬å·²ç»åšå‡ºäº†å·¨å¤§çš„åŠªåŠ›ï¼Œä½†ç”±äºæ¨¡å‹å’Œæ•°æ®çš„å¤æ‚æ€§ï¼Œä»æœ‰å¯èƒ½å­˜åœ¨ä¸€äº›æ— æ³•é¢„è§çš„é—®é¢˜ã€‚å› æ­¤ï¼Œå¦‚æœç”±äºä½¿ç”¨skyworkå¼€æºæ¨¡å‹è€Œå¯¼è‡´çš„ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ•°æ®å®‰å…¨é—®é¢˜ã€å…¬å…±èˆ†è®ºé£é™©ï¼Œæˆ–æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­æˆ–ä¸å½“åˆ©ç”¨æ‰€å¸¦æ¥çš„ä»»ä½•é£é™©å’Œé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚

We hereby declare that the Skywork model should not be used for any activities that pose a threat to national or societal security or engage in unlawful actions. Additionally, we request users not to deploy the Skywork model for internet services without appropriate security reviews and records. We hope that all users will adhere to this principle to ensure that technological advancements occur in a regulated and lawful environment.

We have done our utmost to ensure the compliance of the data used during the model's training process. However, despite our extensive efforts, due to the complexity of the model and data, there may still be unpredictable risks and issues. Therefore, if any problems arise as a result of using the Skywork open-source model, including but not limited to data security issues, public opinion risks, or any risks and problems arising from the model being misled, abused, disseminated, or improperly utilized, we will not assume any responsibility.

## åè®®ï¼ˆLicense Aggrementï¼‰

ç¤¾åŒºä½¿ç”¨Skyworkæ¨¡å‹éœ€è¦éµå¾ª[ã€ŠSkywork æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®ã€‹](https://github.com/SkyworkAI/Skywork/blob/main/Skywork%20æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®.pdf)ã€‚Skyworkæ¨¡å‹æ”¯æŒå•†ä¸šç”¨é€”ï¼Œå¦‚æœæ‚¨è®¡åˆ’å°†Skyworkæ¨¡å‹æˆ–å…¶è¡ç”Ÿå“ç”¨äºå•†ä¸šç›®çš„ï¼Œæ— éœ€å†æ¬¡ç”³è¯·ï¼Œ ä½†è¯·æ‚¨ä»”ç»†é˜…è¯»[ã€ŠSkywork æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®ã€‹](https://github.com/SkyworkAI/Skywork/blob/main/Skywork%20æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®.pdf)å¹¶ä¸¥æ ¼éµå®ˆç›¸å…³æ¡æ¬¾ã€‚ 


The community usage of Skywork model requires [Skywork Community License](https://github.com/SkyworkAI/Skywork/blob/main/Skywork%20Community%20License.pdf). The Skywork model supports commercial use. If you plan to use the Skywork model or its derivatives for commercial purposes, you must abide by terms and conditions within [Skywork Community License](https://github.com/SkyworkAI/Skywork/blob/main/Skywork%20Community%20License.pdf).

  

[ã€ŠSkywork æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®ã€‹ã€‹]:https://github.com/SkyworkAI/Skywork/blob/main/Skywork%20æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®.pdf


[skywork-opensource@kunlun-inc.com]: mailto:skywork-opensource@kunlun-inc.com

# å¼•ç”¨å’Œè”ç³»æˆ‘ä»¬ï¼ˆContact Us and Citationï¼‰
å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œå¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œæ¬¢è¿å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡~

If you find our work helpful, please feel free to cite our paper~
```
@article{skyworktechreport,
  title={},
  author={},
  journal={arXiv preprint arXiv:},
  year={2023}
}
```

```
@article{skyworkmath,
  title={},
  author={},
  journal={arXiv preprint arXiv:},
  year={2023}
}
```
