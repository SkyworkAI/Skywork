[2023-10-23 06:49:14,607] torch.distributed.run: [WARNING] 
[2023-10-23 06:49:14,607] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 06:49:14,607] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-10-23 06:49:14,607] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 06:49:19,471] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:49:19,476] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:49:19,499] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:49:19,544] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:49:19,548] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:49:19,602] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:49:19,614] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:49:19,616] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 50, in <module>
    from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
ImportError: cannot import name 'prepare_model_for_kbit_training' from 'peft' (/usr/local/lib/python3.8/dist-packages/peft/__init__.py)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 50, in <module>
    from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
ImportError: cannot import name 'prepare_model_for_kbit_training' from 'peft' (/usr/local/lib/python3.8/dist-packages/peft/__init__.py)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 50, in <module>
    from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
ImportError: cannot import name 'prepare_model_for_kbit_training' from 'peft' (/usr/local/lib/python3.8/dist-packages/peft/__init__.py)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 50, in <module>
    from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
ImportError: cannot import name 'prepare_model_for_kbit_training' from 'peft' (/usr/local/lib/python3.8/dist-packages/peft/__init__.py)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 50, in <module>
    from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
ImportError: cannot import name 'prepare_model_for_kbit_training' from 'peft' (/usr/local/lib/python3.8/dist-packages/peft/__init__.py)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 50, in <module>
    from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
ImportError: cannot import name 'prepare_model_for_kbit_training' from 'peft' (/usr/local/lib/python3.8/dist-packages/peft/__init__.py)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 50, in <module>
    from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
ImportError: cannot import name 'prepare_model_for_kbit_training' from 'peft' (/usr/local/lib/python3.8/dist-packages/peft/__init__.py)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 50, in <module>
    from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
ImportError: cannot import name 'prepare_model_for_kbit_training' from 'peft' (/usr/local/lib/python3.8/dist-packages/peft/__init__.py)
[2023-10-23 06:49:24,703] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 44000) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train/run_pt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-23_06:49:24
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 44001)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-10-23_06:49:24
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 44002)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-10-23_06:49:24
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 44003)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-10-23_06:49:24
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 44004)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-10-23_06:49:24
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 44005)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-10-23_06:49:24
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 44006)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-10-23_06:49:24
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 44007)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-23_06:49:24
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 44000)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[2023-10-23 06:50:05,939] torch.distributed.run: [WARNING] 
[2023-10-23 06:50:05,939] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 06:50:05,939] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-10-23 06:50:05,939] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 06:50:10,416] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:50:10,428] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:50:10,545] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:50:10,548] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:50:10,553] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:50:10,562] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:50:10,579] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:50:10,609] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 227, in <module>
    class LoraArguments:
  File "train/run_pt.py", line 231, in LoraArguments
    lora_target_modules: Optional[List[str]] = field(
NameError: name 'List' is not defined
Traceback (most recent call last):
  File "train/run_pt.py", line 227, in <module>
    class LoraArguments:
  File "train/run_pt.py", line 231, in LoraArguments
    lora_target_modules: Optional[List[str]] = field(
NameError: name 'List' is not defined
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 227, in <module>
    class LoraArguments:
  File "train/run_pt.py", line 231, in LoraArguments
    lora_target_modules: Optional[List[str]] = field(
NameError: name 'List' is not defined
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 227, in <module>
    class LoraArguments:
  File "train/run_pt.py", line 231, in LoraArguments
    lora_target_modules: Optional[List[str]] = field(
NameError: name 'List' is not defined
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 227, in <module>
    class LoraArguments:
  File "train/run_pt.py", line 231, in LoraArguments
    lora_target_modules: Optional[List[str]] = field(
NameError: name 'List' is not defined
Traceback (most recent call last):
  File "train/run_pt.py", line 227, in <module>
    class LoraArguments:
  File "train/run_pt.py", line 231, in LoraArguments
    lora_target_modules: Optional[List[str]] = field(
NameError: name 'List' is not defined
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 227, in <module>
    class LoraArguments:
  File "train/run_pt.py", line 231, in LoraArguments
    lora_target_modules: Optional[List[str]] = field(
NameError: name 'List' is not defined
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 227, in <module>
    class LoraArguments:
  File "train/run_pt.py", line 231, in LoraArguments
    lora_target_modules: Optional[List[str]] = field(
NameError: name 'List' is not defined
[2023-10-23 06:50:16,039] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 44579) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train/run_pt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-23_06:50:16
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 44580)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-10-23_06:50:16
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 44581)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-10-23_06:50:16
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 44582)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-10-23_06:50:16
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 44583)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-10-23_06:50:16
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 44584)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-10-23_06:50:16
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 44585)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-10-23_06:50:16
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 44586)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-23_06:50:16
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 44579)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[2023-10-23 06:50:29,704] torch.distributed.run: [WARNING] 
[2023-10-23 06:50:29,704] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 06:50:29,704] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-10-23 06:50:29,704] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 06:50:34,035] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:50:34,056] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:50:34,062] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:50:34,091] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:50:34,132] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:50:34,132] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:50:34,138] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 06:50:34,162] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 244, in main
    (ModelArguments, DataArguments, TrainingArguments, LoraArguments)
NameError: name 'DataArguments' is not defined
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 244, in main
    (ModelArguments, DataArguments, TrainingArguments, LoraArguments)
NameError: name 'DataArguments' is not defined
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 244, in main
    (ModelArguments, DataArguments, TrainingArguments, LoraArguments)
NameError: name 'DataArguments' is not defined
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 244, in main
    (ModelArguments, DataArguments, TrainingArguments, LoraArguments)
NameError: name 'DataArguments' is not defined
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 244, in main
    (ModelArguments, DataArguments, TrainingArguments, LoraArguments)
NameError: name 'DataArguments' is not defined
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 244, in main
    (ModelArguments, DataArguments, TrainingArguments, LoraArguments)
NameError: name 'DataArguments' is not defined
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 244, in main
    (ModelArguments, DataArguments, TrainingArguments, LoraArguments)
NameError: name 'DataArguments' is not defined
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 244, in main
    (ModelArguments, DataArguments, TrainingArguments, LoraArguments)
NameError: name 'DataArguments' is not defined
[2023-10-23 06:50:39,798] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 45001) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train/run_pt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-23_06:50:39
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 45002)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-10-23_06:50:39
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 45003)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-10-23_06:50:39
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 45004)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-10-23_06:50:39
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 45005)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-10-23_06:50:39
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 45006)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-10-23_06:50:39
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 45007)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-10-23_06:50:39
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 45008)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-23_06:50:39
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 45001)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[2023-10-23 07:00:13,760] torch.distributed.run: [WARNING] 
[2023-10-23 07:00:13,760] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:00:13,760] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-10-23 07:00:13,760] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:00:18,586] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:00:18,643] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:00:18,675] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:00:18,706] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:00:18,737] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:00:18,749] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:00:18,789] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:00:18,812] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:00:19,293] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:00:19,293] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:00:19,311] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:00:19,311] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:00:19,358] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:00:19,358] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:00:19,403] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:00:19,404] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:00:19,404] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 253, in main
    if lora_args.q_lora:
AttributeError: 'LoraArguments' object has no attribute 'q_lora'
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:00:19,432] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:00:19,432] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:00:19,450] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:00:19,450] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:00:19,484] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:00:19,484] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:00:19,511] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:00:19,511] [INFO] [comm.py:616:init_distributed] cdb=None
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 253, in main
    if lora_args.q_lora:
AttributeError: 'LoraArguments' object has no attribute 'q_lora'
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 253, in main
    if lora_args.q_lora:
AttributeError: 'LoraArguments' object has no attribute 'q_lora'
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 253, in main
    if lora_args.q_lora:
AttributeError: 'LoraArguments' object has no attribute 'q_lora'
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 253, in main
    if lora_args.q_lora:
AttributeError: 'LoraArguments' object has no attribute 'q_lora'
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 253, in main
    if lora_args.q_lora:
AttributeError: 'LoraArguments' object has no attribute 'q_lora'
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 253, in main
    if lora_args.q_lora:
AttributeError: 'LoraArguments' object has no attribute 'q_lora'
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 253, in main
    if lora_args.q_lora:
AttributeError: 'LoraArguments' object has no attribute 'q_lora'
[2023-10-23 07:00:23,858] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 47062) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train/run_pt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-23_07:00:23
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 47063)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-10-23_07:00:23
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 47064)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-10-23_07:00:23
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 47065)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-10-23_07:00:23
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 47066)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-10-23_07:00:23
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 47067)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-10-23_07:00:23
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 47068)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-10-23_07:00:23
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 47069)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-23_07:00:23
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 47062)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[2023-10-23 07:07:21,834] torch.distributed.run: [WARNING] 
[2023-10-23 07:07:21,834] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:07:21,834] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-10-23 07:07:21,834] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:07:26,503] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:07:26,602] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:07:26,649] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:07:26,670] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:07:26,676] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:07:26,707] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:07:26,732] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:07:26,789] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:07:27,132] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:07:27,132] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:07:27,270] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:07:27,270] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:07:27,270] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 253, in main
    if lora_args.use_q_lora:
AttributeError: 'LoraArguments' object has no attribute 'use_q_lora'
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:07:27,322] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:07:27,322] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:07:27,386] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:07:27,386] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:07:27,387] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:07:27,387] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:07:27,430] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:07:27,430] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:07:27,431] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:07:27,432] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:07:27,450] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:07:27,450] [INFO] [comm.py:616:init_distributed] cdb=None
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 253, in main
    if lora_args.use_q_lora:
AttributeError: 'LoraArguments' object has no attribute 'use_q_lora'
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 253, in main
    if lora_args.use_q_lora:
AttributeError: 'LoraArguments' object has no attribute 'use_q_lora'
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 253, in main
    if lora_args.use_q_lora:
AttributeError: 'LoraArguments' object has no attribute 'use_q_lora'
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 253, in main
    if lora_args.use_q_lora:
AttributeError: 'LoraArguments' object has no attribute 'use_q_lora'
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 253, in main
    if lora_args.use_q_lora:
AttributeError: 'LoraArguments' object has no attribute 'use_q_lora'
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 253, in main
    if lora_args.use_q_lora:
AttributeError: 'LoraArguments' object has no attribute 'use_q_lora'
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 253, in main
    if lora_args.use_q_lora:
AttributeError: 'LoraArguments' object has no attribute 'use_q_lora'
[2023-10-23 07:07:31,931] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 49297) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train/run_pt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-23_07:07:31
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 49298)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-10-23_07:07:31
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 49299)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-10-23_07:07:31
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 49300)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-10-23_07:07:31
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 49301)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-10-23_07:07:31
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 49302)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-10-23_07:07:31
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 49303)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-10-23_07:07:31
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 49304)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-23_07:07:31
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 49297)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[2023-10-23 07:08:09,736] torch.distributed.run: [WARNING] 
[2023-10-23 07:08:09,736] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:08:09,736] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-10-23 07:08:09,736] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:08:14,404] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:08:14,482] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:08:14,489] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:08:14,517] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:08:14,538] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:08:14,592] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:08:14,594] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:08:14,615] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:08:15,042] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:08:15,042] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:08:15,140] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:08:15,140] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:08:15,143] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:08:15,143] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:08:15,159] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:08:15,160] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:08:15,219] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:08:15,219] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:08:15,326] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:08:15,326] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:08:15,328] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:08:15,328] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 265, in main
    model_args, data_args, training_args = parser.parse_args_into_dataclasses()
ValueError: too many values to unpack (expected 3)
[2023-10-23 07:08:15,342] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:08:15,342] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:08:15,342] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 265, in main
    model_args, data_args, training_args = parser.parse_args_into_dataclasses()
ValueError: too many values to unpack (expected 3)
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 265, in main
    model_args, data_args, training_args = parser.parse_args_into_dataclasses()
ValueError: too many values to unpack (expected 3)
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 265, in main
    model_args, data_args, training_args = parser.parse_args_into_dataclasses()
ValueError: too many values to unpack (expected 3)
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 265, in main
    model_args, data_args, training_args = parser.parse_args_into_dataclasses()
ValueError: too many values to unpack (expected 3)
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 265, in main
    model_args, data_args, training_args = parser.parse_args_into_dataclasses()
ValueError: too many values to unpack (expected 3)
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 265, in main
    model_args, data_args, training_args = parser.parse_args_into_dataclasses()
ValueError: too many values to unpack (expected 3)
Traceback (most recent call last):
  File "train/run_pt.py", line 457, in <module>
    main()
  File "train/run_pt.py", line 265, in main
    model_args, data_args, training_args = parser.parse_args_into_dataclasses()
ValueError: too many values to unpack (expected 3)
[2023-10-23 07:08:19,839] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 49804) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train/run_pt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-23_07:08:19
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 49805)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-10-23_07:08:19
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 49806)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-10-23_07:08:19
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 49807)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-10-23_07:08:19
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 49808)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-10-23_07:08:19
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 49809)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-10-23_07:08:19
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 49810)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-10-23_07:08:19
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 49811)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-23_07:08:19
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 49804)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[2023-10-23 07:09:27,535] torch.distributed.run: [WARNING] 
[2023-10-23 07:09:27,535] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:09:27,535] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-10-23 07:09:27,535] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:09:31,961] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:09:31,976] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:09:32,011] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:09:32,020] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:09:32,027] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:09:32,033] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:09:32,057] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:09:32,088] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:09:32,628] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:09:32,628] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:09:32,634] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:09:32,634] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:09:32,681] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:09:32,681] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:09:32,685] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:09:32,685] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:09:32,698] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:09:32,699] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:09:32,712] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:09:32,712] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:09:32,797] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:09:32,797] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:09:32,797] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:09:32,838] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:09:32,838] [INFO] [comm.py:616:init_distributed] cdb=None
10/23/2023 07:09:33 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[INFO|configuration_utils.py:713] 2023-10-23 07:09:33,095 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
[INFO|configuration_utils.py:713] 2023-10-23 07:09:33,112 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
[INFO|configuration_utils.py:775] 2023-10-23 07:09:33,113 >> Model config SkyworkConfig {
  "_name_or_path": "/data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base",
  "architectures": [
    "SkyworkForCausalLM"
  ],
  "attention_bias": false,
  "auto_map": {
    "AutoConfig": "configuration_skywork.SkyworkConfig",
    "AutoModelForCausalLM": "modeling_skywork.SkyworkForCausalLM"
  },
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4608,
  "initializer_range": 0.01,
  "intermediate_size": 12288,
  "max_position_embeddings": 4096,
  "model_type": "skywork",
  "num_attention_heads": 36,
  "num_hidden_layers": 52,
  "num_key_value_heads": 36,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.34.0",
  "use_cache": true,
  "use_flash_attention": false,
  "vocab_size": 65519
}

[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:09:33,137 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:09:33,137 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:09:33,137 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:09:33,137 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:09:33,137 >> loading file tokenizer.json
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
[INFO|tokenization_utils.py:493] 2023-10-23 07:09:33,368 >> Adding <s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:09:33,369 >> Adding </s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:09:33,369 >> Adding <unk> to the vocabulary
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 311, in main
    train_dataset = datasets.load_from_disk(data_args.train_cache_dir, keep_in_memory=False)["train"]
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2232, in load_from_disk
    raise FileNotFoundError(
FileNotFoundError: Directory data_cache/pt_train_demo is neither a `Dataset` directory nor a `DatasetDict` directory.
10/23/2023 07:09:33 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:09:33 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:09:33 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True
10/23/2023 07:09:33 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:09:33 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:09:33 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 311, in main
    train_dataset = datasets.load_from_disk(data_args.train_cache_dir, keep_in_memory=False)["train"]
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2232, in load_from_disk
    raise FileNotFoundError(
FileNotFoundError: Directory data_cache/pt_train_demo is neither a `Dataset` directory nor a `DatasetDict` directory.
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 311, in main
    train_dataset = datasets.load_from_disk(data_args.train_cache_dir, keep_in_memory=False)["train"]
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2232, in load_from_disk
    raise FileNotFoundError(
FileNotFoundError: Directory data_cache/pt_train_demo is neither a `Dataset` directory nor a `DatasetDict` directory.
10/23/2023 07:09:33 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 311, in main
    train_dataset = datasets.load_from_disk(data_args.train_cache_dir, keep_in_memory=False)["train"]
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2232, in load_from_disk
    raise FileNotFoundError(
FileNotFoundError: Directory data_cache/pt_train_demo is neither a `Dataset` directory nor a `DatasetDict` directory.
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 311, in main
    train_dataset = datasets.load_from_disk(data_args.train_cache_dir, keep_in_memory=False)["train"]
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2232, in load_from_disk
    raise FileNotFoundError(
FileNotFoundError: Directory data_cache/pt_train_demo is neither a `Dataset` directory nor a `DatasetDict` directory.
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 311, in main
    train_dataset = datasets.load_from_disk(data_args.train_cache_dir, keep_in_memory=False)["train"]
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2232, in load_from_disk
    raise FileNotFoundError(
FileNotFoundError: Directory data_cache/pt_train_demo is neither a `Dataset` directory nor a `DatasetDict` directory.
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 311, in main
    train_dataset = datasets.load_from_disk(data_args.train_cache_dir, keep_in_memory=False)["train"]
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2232, in load_from_disk
    raise FileNotFoundError(
FileNotFoundError: Directory data_cache/pt_train_demo is neither a `Dataset` directory nor a `DatasetDict` directory.
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 311, in main
    train_dataset = datasets.load_from_disk(data_args.train_cache_dir, keep_in_memory=False)["train"]
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2232, in load_from_disk
    raise FileNotFoundError(
FileNotFoundError: Directory data_cache/pt_train_demo is neither a `Dataset` directory nor a `DatasetDict` directory.
[2023-10-23 07:09:37,638] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 50413) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train/run_pt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-23_07:09:37
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 50414)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-10-23_07:09:37
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 50415)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-10-23_07:09:37
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 50416)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-10-23_07:09:37
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 50417)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-10-23_07:09:37
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 50418)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-10-23_07:09:37
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 50419)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-10-23_07:09:37
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 50420)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-23_07:09:37
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 50413)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[2023-10-23 07:09:55,642] torch.distributed.run: [WARNING] 
[2023-10-23 07:09:55,642] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:09:55,642] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-10-23 07:09:55,642] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:10:00,199] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:10:00,231] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:10:00,234] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:10:00,255] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:10:00,268] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:10:00,279] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:10:00,340] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:10:00,371] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:10:00,829] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:10:00,829] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:10:00,898] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:10:00,898] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:10:00,927] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:10:00,928] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:10:00,928] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-10-23 07:10:00,938] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:10:00,938] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:10:00,951] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:10:00,951] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:10:00,962] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:10:00,962] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:10:01,045] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:10:01,045] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:10:01,096] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:10:01,096] [INFO] [comm.py:616:init_distributed] cdb=None
10/23/2023 07:10:01 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[INFO|configuration_utils.py:713] 2023-10-23 07:10:01,752 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
[INFO|configuration_utils.py:713] 2023-10-23 07:10:01,754 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
[INFO|configuration_utils.py:775] 2023-10-23 07:10:01,755 >> Model config SkyworkConfig {
  "_name_or_path": "/data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base",
  "architectures": [
    "SkyworkForCausalLM"
  ],
  "attention_bias": false,
  "auto_map": {
    "AutoConfig": "configuration_skywork.SkyworkConfig",
    "AutoModelForCausalLM": "modeling_skywork.SkyworkForCausalLM"
  },
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4608,
  "initializer_range": 0.01,
  "intermediate_size": 12288,
  "max_position_embeddings": 4096,
  "model_type": "skywork",
  "num_attention_heads": 36,
  "num_hidden_layers": 52,
  "num_key_value_heads": 36,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.34.0",
  "use_cache": true,
  "use_flash_attention": false,
  "vocab_size": 65519
}

[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:10:01,755 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:10:01,755 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:10:01,755 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:10:01,755 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:10:01,755 >> loading file tokenizer.json
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:10:01 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
[INFO|tokenization_utils.py:493] 2023-10-23 07:10:01,904 >> Adding <s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:10:01,904 >> Adding </s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:10:01,904 >> Adding <unk> to the vocabulary
10/23/2023 07:10:02 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:10:02 - INFO - __main__ - Start shuffling training dataset.
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
Caching indices mapping at /data/user/liang.zhao/skywork-13b-opensource/data_cache/pt_train_demo/pt_train/train/cache-82bd44c04d4089ca.arrow
10/23/2023 07:10:02 - INFO - datasets.arrow_dataset - Caching indices mapping at /data/user/liang.zhao/skywork-13b-opensource/data_cache/pt_train_demo/pt_train/train/cache-82bd44c04d4089ca.arrow
10/23/2023 07:10:02 - INFO - __main__ - shuffle successively!
10/23/2023 07:10:02 - INFO - __main__ - Num train_samples  321
10/23/2023 07:10:02 - INFO - __main__ - Training example:
10/23/2023 07:10:02 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:10:02 - INFO - __main__ - subtract the combined number of speeding tickets from the total number of tickets to find the combined number of parking tickets: 24 - 12 = <<24-12=12>>12
Now express Mark's number of parking tickets in terms of the number of parking tickets Sarah got: m = <<2=2>>2s
We know that m + s = 12, so substitute in the value of m from the previous step to get 2s + s = 12
Combine like terms to get 3s = 12
Divide both sides of the equation to get s = <<4=4>>4
Now multiply the number of parking tickets Sarah got by 2 to find the number Mark got: 4 * 2 = <<4*2=8>>8
#### 8<s> Cooper makes 7 apple pies a day. He does this for 12 days. Ashley then eats 50 of his pies. How many apple pies remain with Cooper? The number of pies Cooper makes in 12 days is 7 pies/day * 12 days = <<7*12=84>>84 apple pies.
After Ashley eats 50 of them, there are 84 pies  50 pies = <<84-50=34>>34 apple pies.
#### 34<s> Lindsey bought 2 exercise bands to intensify her workout.  Each band adds an extra 5 pounds of resistance to her workout.  If she doubles up both sets of bands and places them around her legs and picks up a 10-pound dumbbell, how much weight will she squat? She has 2 exercise bands that are both 5 pounds of resistance so thats 2*5 = <<2*5=10>>10 pounds
She has a pair of 10-pound dumbbells so thats 2*10 = <<10*2=20>>20 pounds
With both the bands and dumbbells, she will squat 10+20 = <<10+20=30>>30 pounds
#### 30<s> Wendy just started working at an Italian restaurant. She polished 50 small glasses and 10 more large glasses than small glasses. How many glasses did she polish? She polished 50 + 10 = <<50+10=60>>60 large glasses.
Therefore, Wendy polished 50 + 60 = <<50+60=110>>110 glasses.
#### 110<s> Miss Darlington has a basket of 20 blueberries. She picked 9 more baskets with the same amount of berries. How many blueberries did Miss Darlington have in all? Miss Darlington picked 9 x 20 = <<9*20=180>>180 blueberries more.
So she had a total of 180 + 20 = <<180+20=200>>200 blueberries.
#### 200<s> In a basketball game, Jon scored 3 points. Jack scored 5 points more than Jon, and Tom scored 4 less than the points of Jon and Jack together. How many points did they score altogether? Jack scored 3 + 5 = <<3+5=8>>8 points.
Together, Jon and Jack scored 8 + 3 = <<8+3=11>>11 points.
So, Tom scored 11 - 4 = <<11-4=7>>7 points.
Thus, Jon, Jack, and Tom scored a total of 3 + 8 + 7 = <<3+8+7=18>>18 points.
#### 18<s> In a shipping container, there are 10 crates. Each crate is filled with 6 boxes and each box is filled with 4 washing machines. A worker removes 1 washing machine from each box. There are no other changes. How many washing machines were removed from the shipping container? Initially, there were 6 boxes * 4 washing machines per box = <<6*4=24>>24 washing machines in each crate.
So there were 24 washing machines per crate * 10 crates = <<24*10=240>>240 washing machines in the shipping container.
A worker removes 1 washing machine from each box so there are now 4 original washing machines - 1 removed washing machine = <<4-1=3>>3 washing machines in each box.
This means there are 6 boxes * 3 washing machines per box = <<6*3=18>>18 washing machines in each crate.
So there are now 18 washing machines per crate * 10 crates = <<18*10=180>>180 washing machines in the shipping container.
The difference is how many machine washing machines were removed which is 240 initial washing machines  180 current washing machines = <<240-180=60>>60 washing machines.
#### 60<s> Darnell has 1000 square feet of fabric that he's using to make mini flags. He makes square flags that are 4 feet by 4 feet, wide rectangular flags that are 5 feet by 3 feet, and tall rectangular flags that are 3 feet by 5 feet. He has already made 16 square flags, 20 wide flags, and 10 tall flags. How many square feet of fabric does he have left? The square flags use 16 square feet of fabric per flag because four times four equals <<4*4=16>>16
The wide flags each use 15 feet of fabric per flag because five times three equals <<5*3=15>>15
The tall flags each use 15 feet of fabric per flag because five times three equals <<5*3=15>>15
He has used 256 square feet for the square flags because 16 times 16 equals <<16*16=256>>256
He has used 300 square feet for the wide flags because 20 times 15 equals <<20*15=300>>300
He has used 150 square feet for the tall flags because ten times 15 equals 150.
He has used 706 square feet because 256 plus 300 plus 150 equals <<256+300+150=706>>706.
He has 294 square feet left because 1,000 minus 706 equals <<1000-706=294>>294
#### 294<s> Matthias has 40 soccer balls and 15 basketballs. 30 soccer balls and 7 basketballs have a hole in them. How many balls in total does Matthias have without holes in them? Matthias has 40-30 = <<40-30=10>>10 soccer balls without holes.
Matthias has 15-7 = <<15-7=8>>8 basketballs without holes.
A total of 10+8 = <<10+8=18>>18 balls do not have holes.
#### 18<s> Jenny is scraping gum off the bottom of the seats in a stadium with two sections. Section A has 1 subsection with 60 seats and 3 subsections with 80 seats each. Section B has 20 more seats than 3 times as many seats as Section A has total. How many seats does Section B have? First find how many total seats are in the 80-seat subsections: 80 seats/subsection * 3 subsections = 240 seats
Then add the number of seats in the 60-seat section to find the total number of seats in Section A: 240 seats + 60 seats = <<240+60=300>>300 seats
Then triple that number: 300 seats * 3 = <<300*3=900>>900 seats
Then add 20 seats to find the total number of seats in Section B: 900 seats + 20 seats = <<900+20=920>>920 seats
#### 920<s> The running time of Beast of War: Armoured Command is 10 minutes longer than that of Alpha Epsilon, which is 30 minutes shorter than that of Millennium. If Millennium runs for 2 hours, what is the running time of Beast of War: Armoured Command in minutes? One hour contains 60 minutes so 2 hours contain 60*2 = <<2*60=120>>120 minutes
Alpha Epsilon's running time is 30 minutes less than that of Millennium (which runs for 120 minutes) hence 120-30 = <<120-30=90>>90 minutes
Beast of War: Armoured Command runs for 10 minutes more than Alpha Epsilon hence 90+10 = <<10+90=100>>100 minutes
#### 100<s> A packet of candy sweets has 30 cherry-flavored sweets, 40 strawberry-flavored sweets, and 50 pineapple-flavored sweets. Aaron eats half of each of the flavored sweets and gives 5 cherry-flavored sweets to his friend. How many sweets are still in the packet of candy? Aaron eats 1/2*30 sweets + 1/2*40 sweets + 1/2*50 sweets = <<1/2*30+1/2*40+1/2*50=60>>60 candy sweets.
The packet of candy sweets still has 60 sweets - 5 sweets = <<60-5=55>>55 candy sweets.
#### 55<s> Oliver has two bags of vegetables. Each bag weighs 1/6 as much as Jamess bag, which weighs 18kg. What is the combined weight of both Olivers bags? Each of Olivers bags weighs 18 kg * 1/6 =<<18*1/6=3>>3 kg.
Combined, both his bags weigh 3 kg * 2 = <<3*2=6>>6 kg.
#### 6<s> Greg's PPO algorithm obtained 90% of the possible reward on the CoinRun environment. CoinRun's maximum reward is half as much as the maximum ProcGen reward of 240. How much reward did Greg's PPO algorithm get? Half of much as ProcGen's maximum reward is 240/2=<<240/2=120>>120 reward
90% of CoinRun's maximum reward is 120*.9=<<120*.9=108>>108 reward
#### 108<s> Julia has a parrot and a rabbit. She buys food for both of the animals for $30 in total a week. Julia has the rabbit for 5 weeks, and the parrot for 3 weeks. How much money did Julia already spend on food for her animals, if the weekly cost of the rabbit food is $12? If the rabbit food costs $12 a week, then the parrot food costs $30 - $12 = $18 a week.
Julia has the parrot for 3 weeks, so she spent 3 weeks * $18/week = $<<3*18=54>>54 on her.
The rabbit is her only for 5 weeks, so she spent 5 weeks * $12/week = $<<5*12=60>>60 on him.
In total, Julia spent $54 + $60 = $<<54+60=114>>114 on food for her animals.
#### 114<s> Janet has 60 less than four times as many siblings as Masud. Carlos has 3/4 times as many siblings as Masud. If Masud has 60 siblings, how many more siblings does Janet have more than Carlos? If Masud has 60 siblings, and Carlos has 3/4 times as many siblings as Masud, Carlos has 3/4*60=<<60*3/4=45>>45 siblings.
Four times as many siblings as Masud has is 4*60=<<4*60=240>>240
Janet has 60 less than four times as many siblings as Masud, a total of 240-60=<<240-60=180>>180 siblings.
The number of siblings Janet have more than Carlos is 180-45=<<180-45=135>>135
#### 135<s> A highway is being extended from its current length of 200 miles up to 650 miles. 50 miles are built on the first day, and three times this amount are built on the second day.  How many miles still need to be added to the highway to finish extending it? The length of the highway that needs to be constructed is 650  200 = <<650-200=450>>450 miles.
After the first day, there are still 450  50 = <<450-50=400>>400 miles that need to be constructed.
On the second day, 50 miles * 3 = <<50*3=150>>150 miles are added to the highway.
This means that 400  150 = <<400-150=250>>250 miles still need to be added to the highway.
#### 250<s> Susan is making jewelry with a repeating pattern that has 3 green beads, 5 purple beads, and twice as many red beads as green beads. If the pattern repeats three times per bracelet and 5 times per necklace, how many beads does she need to make 1 bracelets and 10 necklaces? First find the number of red beads per repeat: 3 green * 2 red/green = <<3*2=6>>6 red
Then add the number of beads of each color to find the total number of bead per repeat: 6 beads + 3 beads + 5 beads = <<6+3+5=14>>14 beads
Then multiply the number of beads per repeat by the number of repeats per bracelet to find the number of beads per bracelet: 14 beads/repeat * 3 repeats/bracelet = <<14*3=42>>42 beads/bracelet
Then multiply the number of beads per repeat by the number of repeats per necklace to find the number of beads per necklace: 14 beads/repeat * 5 repeats/necklace = <<14*5=70>>70 beads/necklace
Then multiply the number of beads per necklace by the number of necklaces to find the total number of beads used in the necklaces: 70 beads/necklace * 10 necklaces = <<70*10=700>>700 beads
Then add the number of beads used in a bracelet to the number of beads in the necklaces to find the total number of beads used: 700 beads + 42 beads = <<700+42=742>>742 beads
#### 742<s> Janet counts 30 crows on the powerlines and 60% more hawks than crows. How many birds does she count total? First find how many more hawks than crows there are: 60% * 30 crows = <<60*.01*30=18>>18 crows
Then add that number to the number of crows to find the total number of hawks: 18 crows + 30 crows = <<18+30=48>>48 crows
Then add the number of crows to the number of hawks to find the total number of birds: 48 crows + 30 crows = <<48+30=78>>78 crows
#### 78<s> Joan has 180 socks. Two thirds of the socks are white, and the rest of the socks are blue. How many blue socks does Joan have? Joan has (180/3)*2 = <<(180/3)*2=120>>120 white socks.
The number of blue socks Joan has is 180-120 = <<180-120=60>>60.
#### 60<s> Simon collected treasures on the beach during his summer vacation. He collected a bucket of pearly seashells, a jar full of smooth sea glass, and a bag of ten sand dollars. If the jar holds three times as many pieces of glass as the bag does sand dollars, and the bucket holds five times as many seashells as the jar holds pieces of glass, how many treasures did Simon find on the beach? The jar holds 
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    cache_dir=training_args.cache_dir,
AttributeError: 'TrainingArguments' object has no attribute 'cache_dir'
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    cache_dir=training_args.cache_dir,
AttributeError: 'TrainingArguments' object has no attribute 'cache_dir'
10/23/2023 07:10:02 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    cache_dir=training_args.cache_dir,
AttributeError: 'TrainingArguments' object has no attribute 'cache_dir'
10/23/2023 07:10:02 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True
10/23/2023 07:10:02 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    cache_dir=training_args.cache_dir,
AttributeError: 'TrainingArguments' object has no attribute 'cache_dir'
10/23/2023 07:10:02 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    cache_dir=training_args.cache_dir,
AttributeError: 'TrainingArguments' object has no attribute 'cache_dir'
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    cache_dir=training_args.cache_dir,
AttributeError: 'TrainingArguments' object has no attribute 'cache_dir'
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    cache_dir=training_args.cache_dir,
AttributeError: 'TrainingArguments' object has no attribute 'cache_dir'
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    cache_dir=training_args.cache_dir,
AttributeError: 'TrainingArguments' object has no attribute 'cache_dir'
[2023-10-23 07:10:05,736] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 50870) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train/run_pt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-23_07:10:05
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 50871)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-10-23_07:10:05
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 50872)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-10-23_07:10:05
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 50873)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-10-23_07:10:05
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 50874)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-10-23_07:10:05
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 50875)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-10-23_07:10:05
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 50876)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-10-23_07:10:05
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 50877)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-23_07:10:05
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 50870)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[2023-10-23 07:11:39,846] torch.distributed.run: [WARNING] 
[2023-10-23 07:11:39,846] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:11:39,846] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-10-23 07:11:39,846] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:11:44,447] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:11:44,486] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:11:44,514] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:11:44,522] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:11:44,532] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:11:44,542] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:11:44,560] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:11:44,564] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 243, in main
    parser = transformers.HfArgumentParser(
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 136, in __init__
    self._add_dataclass_arguments(dtype)
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 263, in _add_dataclass_arguments
    self._parse_dataclass_field(parser, field)
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 221, in _parse_dataclass_field
    parser.add_argument(field_name, *aliases, **kwargs)
  File "/usr/lib/python3.8/argparse.py", line 1398, in add_argument
    return self._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1761, in _add_action
    self._optionals._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1602, in _add_action
    action = super(_ArgumentGroup, self)._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1412, in _add_action
    self._check_conflict(action)
  File "/usr/lib/python3.8/argparse.py", line 1551, in _check_conflict
    conflict_handler(action, confl_optionals)
  File "/usr/lib/python3.8/argparse.py", line 1560, in _handle_conflict_error
    raise ArgumentError(action, message % conflict_string)
argparse.ArgumentError: argument --cache_dir: conflicting option string: --cache_dir
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 243, in main
    parser = transformers.HfArgumentParser(
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 136, in __init__
    self._add_dataclass_arguments(dtype)
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 263, in _add_dataclass_arguments
    self._parse_dataclass_field(parser, field)
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 221, in _parse_dataclass_field
    parser.add_argument(field_name, *aliases, **kwargs)
  File "/usr/lib/python3.8/argparse.py", line 1398, in add_argument
    return self._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1761, in _add_action
    self._optionals._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1602, in _add_action
    action = super(_ArgumentGroup, self)._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1412, in _add_action
    self._check_conflict(action)
  File "/usr/lib/python3.8/argparse.py", line 1551, in _check_conflict
    conflict_handler(action, confl_optionals)
  File "/usr/lib/python3.8/argparse.py", line 1560, in _handle_conflict_error
    raise ArgumentError(action, message % conflict_string)
argparse.ArgumentError: argument --cache_dir: conflicting option string: --cache_dir
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 243, in main
    parser = transformers.HfArgumentParser(
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 136, in __init__
    self._add_dataclass_arguments(dtype)
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 263, in _add_dataclass_arguments
    self._parse_dataclass_field(parser, field)
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 221, in _parse_dataclass_field
    parser.add_argument(field_name, *aliases, **kwargs)
  File "/usr/lib/python3.8/argparse.py", line 1398, in add_argument
    return self._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1761, in _add_action
    self._optionals._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1602, in _add_action
    action = super(_ArgumentGroup, self)._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1412, in _add_action
    self._check_conflict(action)
  File "/usr/lib/python3.8/argparse.py", line 1551, in _check_conflict
    conflict_handler(action, confl_optionals)
  File "/usr/lib/python3.8/argparse.py", line 1560, in _handle_conflict_error
    raise ArgumentError(action, message % conflict_string)
argparse.ArgumentError: argument --cache_dir: conflicting option string: --cache_dir
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 243, in main
    parser = transformers.HfArgumentParser(
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 136, in __init__
    self._add_dataclass_arguments(dtype)
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 263, in _add_dataclass_arguments
    self._parse_dataclass_field(parser, field)
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 221, in _parse_dataclass_field
    parser.add_argument(field_name, *aliases, **kwargs)
  File "/usr/lib/python3.8/argparse.py", line 1398, in add_argument
    return self._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1761, in _add_action
    self._optionals._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1602, in _add_action
    action = super(_ArgumentGroup, self)._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1412, in _add_action
    self._check_conflict(action)
  File "/usr/lib/python3.8/argparse.py", line 1551, in _check_conflict
    conflict_handler(action, confl_optionals)
  File "/usr/lib/python3.8/argparse.py", line 1560, in _handle_conflict_error
    raise ArgumentError(action, message % conflict_string)
argparse.ArgumentError: argument --cache_dir: conflicting option string: --cache_dir
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 243, in main
    parser = transformers.HfArgumentParser(
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 136, in __init__
    self._add_dataclass_arguments(dtype)
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 263, in _add_dataclass_arguments
    self._parse_dataclass_field(parser, field)
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 221, in _parse_dataclass_field
    parser.add_argument(field_name, *aliases, **kwargs)
  File "/usr/lib/python3.8/argparse.py", line 1398, in add_argument
    return self._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1761, in _add_action
    self._optionals._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1602, in _add_action
    action = super(_ArgumentGroup, self)._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1412, in _add_action
    self._check_conflict(action)
  File "/usr/lib/python3.8/argparse.py", line 1551, in _check_conflict
    conflict_handler(action, confl_optionals)
  File "/usr/lib/python3.8/argparse.py", line 1560, in _handle_conflict_error
    raise ArgumentError(action, message % conflict_string)
argparse.ArgumentError: argument --cache_dir: conflicting option string: --cache_dir
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 243, in main
    parser = transformers.HfArgumentParser(
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 136, in __init__
    self._add_dataclass_arguments(dtype)
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 263, in _add_dataclass_arguments
    self._parse_dataclass_field(parser, field)
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 221, in _parse_dataclass_field
    parser.add_argument(field_name, *aliases, **kwargs)
  File "/usr/lib/python3.8/argparse.py", line 1398, in add_argument
    return self._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1761, in _add_action
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    self._optionals._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1602, in _add_action
    main()
  File "train/run_pt.py", line 243, in main
    action = super(_ArgumentGroup, self)._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1412, in _add_action
    parser = transformers.HfArgumentParser(
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 136, in __init__
    self._add_dataclass_arguments(dtype)
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 263, in _add_dataclass_arguments
    self._parse_dataclass_field(parser, field)
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 221, in _parse_dataclass_field
    self._check_conflict(action)
  File "/usr/lib/python3.8/argparse.py", line 1551, in _check_conflict
    parser.add_argument(field_name, *aliases, **kwargs)
  File "/usr/lib/python3.8/argparse.py", line 1398, in add_argument
    conflict_handler(action, confl_optionals)
  File "/usr/lib/python3.8/argparse.py", line 1560, in _handle_conflict_error
    return self._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1761, in _add_action
    raise ArgumentError(action, message % conflict_string)
argparse.ArgumentError: argument --cache_dir: conflicting option string: --cache_dir
    self._optionals._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1602, in _add_action
    action = super(_ArgumentGroup, self)._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1412, in _add_action
    self._check_conflict(action)
  File "/usr/lib/python3.8/argparse.py", line 1551, in _check_conflict
    conflict_handler(action, confl_optionals)
  File "/usr/lib/python3.8/argparse.py", line 1560, in _handle_conflict_error
    raise ArgumentError(action, message % conflict_string)
argparse.ArgumentError: argument --cache_dir: conflicting option string: --cache_dir
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 243, in main
    parser = transformers.HfArgumentParser(
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 136, in __init__
    self._add_dataclass_arguments(dtype)
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 263, in _add_dataclass_arguments
    self._parse_dataclass_field(parser, field)
  File "/usr/local/lib/python3.8/dist-packages/transformers/hf_argparser.py", line 221, in _parse_dataclass_field
    parser.add_argument(field_name, *aliases, **kwargs)
  File "/usr/lib/python3.8/argparse.py", line 1398, in add_argument
    return self._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1761, in _add_action
    self._optionals._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1602, in _add_action
    action = super(_ArgumentGroup, self)._add_action(action)
  File "/usr/lib/python3.8/argparse.py", line 1412, in _add_action
    self._check_conflict(action)
  File "/usr/lib/python3.8/argparse.py", line 1551, in _check_conflict
    conflict_handler(action, confl_optionals)
  File "/usr/lib/python3.8/argparse.py", line 1560, in _handle_conflict_error
    raise ArgumentError(action, message % conflict_string)
argparse.ArgumentError: argument --cache_dir: conflicting option string: --cache_dir
[2023-10-23 07:11:49,943] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 51548) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train/run_pt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-23_07:11:49
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 51549)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-10-23_07:11:49
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 51550)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-10-23_07:11:49
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 51551)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-10-23_07:11:49
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 51552)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-10-23_07:11:49
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 51553)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-10-23_07:11:49
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 51554)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-10-23_07:11:49
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 51555)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-23_07:11:49
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 51548)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[2023-10-23 07:12:14,115] torch.distributed.run: [WARNING] 
[2023-10-23 07:12:14,115] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:12:14,115] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-10-23 07:12:14,115] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:12:18,938] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:12:18,988] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:12:19,085] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:12:19,089] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:12:19,102] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:12:19,149] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:12:19,209] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:12:19,218] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:12:19,599] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:12:19,599] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:12:19,649] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:12:19,649] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:12:19,761] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:12:19,761] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:12:19,762] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:12:19,763] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:12:19,769] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:12:19,769] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:12:19,769] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:12:19,902] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:12:19,902] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:12:19,905] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:12:19,905] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:12:19,913] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:12:19,913] [INFO] [comm.py:616:init_distributed] cdb=None
10/23/2023 07:12:20 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:12:20 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[INFO|configuration_utils.py:713] 2023-10-23 07:12:20,066 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
[INFO|configuration_utils.py:713] 2023-10-23 07:12:20,068 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
[INFO|configuration_utils.py:775] 2023-10-23 07:12:20,069 >> Model config SkyworkConfig {
  "_name_or_path": "/data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base",
  "architectures": [
    "SkyworkForCausalLM"
  ],
  "attention_bias": false,
  "auto_map": {
    "AutoConfig": "configuration_skywork.SkyworkConfig",
    "AutoModelForCausalLM": "modeling_skywork.SkyworkForCausalLM"
  },
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4608,
  "initializer_range": 0.01,
  "intermediate_size": 12288,
  "max_position_embeddings": 4096,
  "model_type": "skywork",
  "num_attention_heads": 36,
  "num_hidden_layers": 52,
  "num_key_value_heads": 36,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.34.0",
  "use_cache": true,
  "use_flash_attention": false,
  "vocab_size": 65519
}

[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:12:20,069 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:12:20,069 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:12:20,069 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:12:20,069 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:12:20,069 >> loading file tokenizer.json
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:12:20 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
[INFO|tokenization_utils.py:493] 2023-10-23 07:12:20,220 >> Adding <s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:12:20,220 >> Adding </s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:12:20,220 >> Adding <unk> to the vocabulary
10/23/2023 07:12:20 - INFO - __main__ - Start shuffling training dataset.
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
Loading cached shuffled indices for dataset at /data/user/liang.zhao/skywork-13b-opensource/data_cache/pt_train_demo/pt_train/train/cache-82bd44c04d4089ca.arrow
10/23/2023 07:12:20 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /data/user/liang.zhao/skywork-13b-opensource/data_cache/pt_train_demo/pt_train/train/cache-82bd44c04d4089ca.arrow
10/23/2023 07:12:20 - INFO - __main__ - shuffle successively!
10/23/2023 07:12:20 - INFO - __main__ - Num train_samples  321
10/23/2023 07:12:20 - INFO - __main__ - Training example:
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    cache_dir=training_args.cache_dir,
AttributeError: 'TrainingArguments' object has no attribute 'cache_dir'
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
10/23/2023 07:12:20 - INFO - __main__ - subtract the combined number of speeding tickets from the total number of tickets to find the combined number of parking tickets: 24 - 12 = <<24-12=12>>12
Now express Mark's number of parking tickets in terms of the number of parking tickets Sarah got: m = <<2=2>>2s
We know that m + s = 12, so substitute in the value of m from the previous step to get 2s + s = 12
Combine like terms to get 3s = 12
Divide both sides of the equation to get s = <<4=4>>4
Now multiply the number of parking tickets Sarah got by 2 to find the number Mark got: 4 * 2 = <<4*2=8>>8
#### 8<s> Cooper makes 7 apple pies a day. He does this for 12 days. Ashley then eats 50 of his pies. How many apple pies remain with Cooper? The number of pies Cooper makes in 12 days is 7 pies/day * 12 days = <<7*12=84>>84 apple pies.
After Ashley eats 50 of them, there are 84 pies  50 pies = <<84-50=34>>34 apple pies.
#### 34<s> Lindsey bought 2 exercise bands to intensify her workout.  Each band adds an extra 5 pounds of resistance to her workout.  If she doubles up both sets of bands and places them around her legs and picks up a 10-pound dumbbell, how much weight will she squat? She has 2 exercise bands that are both 5 pounds of resistance so thats 2*5 = <<2*5=10>>10 pounds
She has a pair of 10-pound dumbbells so thats 2*10 = <<10*2=20>>20 pounds
With both the bands and dumbbells, she will squat 10+20 = <<10+20=30>>30 pounds
#### 30<s> Wendy just started working at an Italian restaurant. She polished 50 small glasses and 10 more large glasses than small glasses. How many glasses did she polish? She polished 50 + 10 = <<50+10=60>>60 large glasses.
Therefore, Wendy polished 50 + 60 = <<50+60=110>>110 glasses.
#### 110<s> Miss Darlington has a basket of 20 blueberries. She picked 9 more baskets with the same amount of berries. How many blueberries did Miss Darlington have in all? Miss Darlington picked 9 x 20 = <<9*20=180>>180 blueberries more.
So she had a total of 180 + 20 = <<180+20=200>>200 blueberries.
#### 200<s> In a basketball game, Jon scored 3 points. Jack scored 5 points more than Jon, and Tom scored 4 less than the points of Jon and Jack together. How many points did they score altogether? Jack scored 3 + 5 = <<3+5=8>>8 points.
Together, Jon and Jack scored 8 + 3 = <<8+3=11>>11 points.
So, Tom scored 11 - 4 = <<11-4=7>>7 points.
Thus, Jon, Jack, and Tom scored a total of 3 + 8 + 7 = <<3+8+7=18>>18 points.
#### 18<s> In a shipping container, there are 10 crates. Each crate is filled with 6 boxes and each box is filled with 4 washing machines. A worker removes 1 washing machine from each box. There are no other changes. How many washing machines were removed from the shipping container? Initially, there were 6 boxes * 4 washing machines per box = <<6*4=24>>24 washing machines in each crate.
So there were 24 washing machines per crate * 10 crates = <<24*10=240>>240 washing machines in the shipping container.
A worker removes 1 washing machine from each box so there are now 4 original washing machines - 1 removed washing machine = <<4-1=3>>3 washing machines in each box.
This means there are 6 boxes * 3 washing machines per box = <<6*3=18>>18 washing machines in each crate.
So there are now 18 washing machines per crate * 10 crates = <<18*10=180>>180 washing machines in the shipping container.
The difference is how many machine washing machines were removed which is 240 initial washing machines  180 current washing machines = <<240-180=60>>60 washing machines.
#### 60<s> Darnell has 1000 square feet of fabric that he's using to make mini flags. He makes square flags that are 4 feet by 4 feet, wide rectangular flags that are 5 feet by 3 feet, and tall rectangular flags that are 3 feet by 5 feet. He has already made 16 square flags, 20 wide flags, and 10 tall flags. How many square feet of fabric does he have left? The square flags use 16 square feet of fabric per flag because four times four equals <<4*4=16>>16
The wide flags each use 15 feet of fabric per flag because five times three equals <<5*3=15>>15
The tall flags each use 15 feet of fabric per flag because five times three equals <<5*3=15>>15
He has used 256 square feet for the square flags because 16 times 16 equals <<16*16=256>>256
He has used 300 square feet for the wide flags because 20 times 15 equals <<20*15=300>>300
He has used 150 square feet for the tall flags because ten times 15 equals 150.
He has used 706 square feet because 256 plus 300 plus 150 equals <<256+300+150=706>>706.
He has 294 square feet left because 1,000 minus 706 equals <<1000-706=294>>294
#### 294<s> Matthias has 40 soccer balls and 15 basketballs. 30 soccer balls and 7 basketballs have a hole in them. How many balls in total does Matthias have without holes in them? Matthias has 40-30 = <<40-30=10>>10 soccer balls without holes.
Matthias has 15-7 = <<15-7=8>>8 basketballs without holes.
A total of 10+8 = <<10+8=18>>18 balls do not have holes.
#### 18<s> Jenny is scraping gum off the bottom of the seats in a stadium with two sections. Section A has 1 subsection with 60 seats and 3 subsections with 80 seats each. Section B has 20 more seats than 3 times as many seats as Section A has total. How many seats does Section B have? First find how many total seats are in the 80-seat subsections: 80 seats/subsection * 3 subsections = 240 seats
Then add the number of seats in the 60-seat section to find the total number of seats in Section A: 240 seats + 60 seats = <<240+60=300>>300 seats
Then triple that number: 300 seats * 3 = <<300*3=900>>900 seats
Then add 20 seats to find the total number of seats in Section B: 900 seats + 20 seats = <<900+20=920>>920 seats
#### 920<s> The running time of Beast of War: Armoured Command is 10 minutes longer than that of Alpha Epsilon, which is 30 minutes shorter than that of Millennium. If Millennium runs for 2 hours, what is the running time of Beast of War: Armoured Command in minutes? One hour contains 60 minutes so 2 hours contain 60*2 = <<2*60=120>>120 minutes
Alpha Epsilon's running time is 30 minutes less than that of Millennium (which runs for 120 minutes) hence 120-30 = <<120-30=90>>90 minutes
Beast of War: Armoured Command runs for 10 minutes more than Alpha Epsilon hence 90+10 = <<10+90=100>>100 minutes
#### 100<s> A packet of candy sweets has 30 cherry-flavored sweets, 40 strawberry-flavored sweets, and 50 pineapple-flavored sweets. Aaron eats half of each of the flavored sweets and gives 5 cherry-flavored sweets to his friend. How many sweets are still in the packet of candy? Aaron eats 1/2*30 sweets + 1/2*40 sweets + 1/2*50 sweets = <<1/2*30+1/2*40+1/2*50=60>>60 candy sweets.
The packet of candy sweets still has 60 sweets - 5 sweets = <<60-5=55>>55 candy sweets.
#### 55<s> Oliver has two bags of vegetables. Each bag weighs 1/6 as much as Jamess bag, which weighs 18kg. What is the combined weight of both Olivers bags? Each of Olivers bags weighs 18 kg * 1/6 =<<18*1/6=3>>3 kg.
Combined, both his bags weigh 3 kg * 2 = <<3*2=6>>6 kg.
#### 6<s> Greg's PPO algorithm obtained 90% of the possible reward on the CoinRun environment. CoinRun's maximum reward is half as much as the maximum ProcGen reward of 240. How much reward did Greg's PPO algorithm get? Half of much as ProcGen's maximum reward is 240/2=<<240/2=120>>120 reward
90% of CoinRun's maximum reward is 120*.9=<<120*.9=108>>108 reward
#### 108<s> Julia has a parrot and a rabbit. She buys food for both of the animals for $30 in total a week. Julia has the rabbit for 5 weeks, and the parrot for 3 weeks. How much money did Julia already spend on food for her animals, if the weekly cost of the rabbit food is $12? If the rabbit food costs $12 a week, then the parrot food costs $30 - $12 = $18 a week.
Julia has the parrot for 3 weeks, so she spent 3 weeks * $18/week = $<<3*18=54>>54 on her.
The rabbit is her only for 5 weeks, so she spent 5 weeks * $12/week = $<<5*12=60>>60 on him.
In total, Julia spent $54 + $60 = $<<54+60=114>>114 on food for her animals.
#### 114<s> Janet has 60 less than four times as many siblings as Masud. Carlos has 3/4 times as many siblings as Masud. If Masud has 60 siblings, how many more siblings does Janet have more than Carlos? If Masud has 60 siblings, and Carlos has 3/4 times as many siblings as Masud, Carlos has 3/4*60=<<60*3/4=45>>45 siblings.
Four times as many siblings as Masud has is 4*60=<<4*60=240>>240
Janet has 60 less than four times as many siblings as Masud, a total of 240-60=<<240-60=180>>180 siblings.
The number of siblings Janet have more than Carlos is 180-45=<<180-45=135>>135
#### 135<s> A highway is being extended from its current length of 200 miles up to 650 miles. 50 miles are built on the first day, and three times this amount are built on the second day.  How many miles still need to be added to the highway to finish extending it? The length of the highway that needs to be constructed is 650  200 = <<650-200=450>>450 miles.
After the first day, there are still 450  50 = <<450-50=400>>400 miles that need to be constructed.
On the second day, 50 miles * 3 = <<50*3=150>>150 miles are added to the highway.
This means that 400  150 = <<400-150=250>>250 miles still need to be added to the highway.
#### 250<s> Susan is making jewelry with a repeating pattern that has 3 green beads, 5 purple beads, and twice as many red beads as green beads. If the pattern repeats three times per bracelet and 5 times per necklace, how many beads does she need to make 1 bracelets and 10 necklaces? First find the number of red beads per repeat: 3 green * 2 red/green = <<3*2=6>>6 red
Then add the number of beads of each color to find the total number of bead per repeat: 6 beads + 3 beads + 5 beads = <<6+3+5=14>>14 beads
Then multiply the number of beads per repeat by the number of repeats per bracelet to find the number of beads per bracelet: 14 beads/repeat * 3 repeats/bracelet = <<14*3=42>>42 beads/bracelet
Then multiply the number of beads per repeat by the number of repeats per necklace to find the number of beads per necklace: 14 beads/repeat * 5 repeats/necklace = <<14*5=70>>70 beads/necklace
Then multiply the number of beads per necklace by the number of necklaces to find the total number of beads used in the necklaces: 70 beads/necklace * 10 necklaces = <<70*10=700>>700 beads
Then add the number of beads used in a bracelet to the number of beads in the necklaces to find the total number of beads used: 700 beads + 42 beads = <<700+42=742>>742 beads
#### 742<s> Janet counts 30 crows on the powerlines and 60% more hawks than crows. How many birds does she count total? First find how many more hawks than crows there are: 60% * 30 crows = <<60*.01*30=18>>18 crows
Then add that number to the number of crows to find the total number of hawks: 18 crows + 30 crows = <<18+30=48>>48 crows
Then add the number of crows to the number of hawks to find the total number of birds: 48 crows + 30 crows = <<48+30=78>>78 crows
#### 78<s> Joan has 180 socks. Two thirds of the socks are white, and the rest of the socks are blue. How many blue socks does Joan have? Joan has (180/3)*2 = <<(180/3)*2=120>>120 white socks.
The number of blue socks Joan has is 180-120 = <<180-120=60>>60.
#### 60<s> Simon collected treasures on the beach during his summer vacation. He collected a bucket of pearly seashells, a jar full of smooth sea glass, and a bag of ten sand dollars. If the jar holds three times as many pieces of glass as the bag does sand dollars, and the bucket holds five times as many seashells as the jar holds pieces of glass, how many treasures did Simon find on the beach? The jar holds 
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    cache_dir=training_args.cache_dir,
AttributeError: 'TrainingArguments' object has no attribute 'cache_dir'
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    cache_dir=training_args.cache_dir,
AttributeError: 'TrainingArguments' object has no attribute 'cache_dir'
10/23/2023 07:12:20 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:12:20 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
10/23/2023 07:12:20 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True
10/23/2023 07:12:20 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True
10/23/2023 07:12:20 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    cache_dir=training_args.cache_dir,
AttributeError: 'TrainingArguments' object has no attribute 'cache_dir'
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    cache_dir=training_args.cache_dir,
AttributeError: 'TrainingArguments' object has no attribute 'cache_dir'
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    cache_dir=training_args.cache_dir,
AttributeError: 'TrainingArguments' object has no attribute 'cache_dir'
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    cache_dir=training_args.cache_dir,
AttributeError: 'TrainingArguments' object has no attribute 'cache_dir'
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    cache_dir=training_args.cache_dir,
AttributeError: 'TrainingArguments' object has no attribute 'cache_dir'
[2023-10-23 07:12:24,215] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 51998) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train/run_pt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-23_07:12:24
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 51999)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-10-23_07:12:24
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 52000)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-10-23_07:12:24
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 52001)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-10-23_07:12:24
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 52002)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-10-23_07:12:24
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 52003)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-10-23_07:12:24
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 52004)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-10-23_07:12:24
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 52005)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-23_07:12:24
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 51998)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[2023-10-23 07:12:53,423] torch.distributed.run: [WARNING] 
[2023-10-23 07:12:53,423] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:12:53,423] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-10-23 07:12:53,423] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:12:58,124] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:12:58,199] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:12:58,207] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:12:58,212] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:12:58,251] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:12:58,272] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:12:58,289] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:12:58,303] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:12:58,777] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:12:58,777] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:12:58,867] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:12:58,867] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:12:58,899] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:12:58,899] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:12:58,925] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:12:58,925] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:12:58,925] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:12:58,946] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:12:58,946] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:12:58,950] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:12:58,950] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:12:59,000] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:12:59,001] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:12:59,089] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:12:59,089] [INFO] [comm.py:616:init_distributed] cdb=None
10/23/2023 07:12:59 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[INFO|configuration_utils.py:713] 2023-10-23 07:12:59,190 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
[INFO|configuration_utils.py:713] 2023-10-23 07:12:59,192 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
[INFO|configuration_utils.py:775] 2023-10-23 07:12:59,192 >> Model config SkyworkConfig {
  "_name_or_path": "/data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base",
  "architectures": [
    "SkyworkForCausalLM"
  ],
  "attention_bias": false,
  "auto_map": {
    "AutoConfig": "configuration_skywork.SkyworkConfig",
    "AutoModelForCausalLM": "modeling_skywork.SkyworkForCausalLM"
  },
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4608,
  "initializer_range": 0.01,
  "intermediate_size": 12288,
  "max_position_embeddings": 4096,
  "model_type": "skywork",
  "num_attention_heads": 36,
  "num_hidden_layers": 52,
  "num_key_value_heads": 36,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.34.0",
  "use_cache": true,
  "use_flash_attention": false,
  "vocab_size": 65519
}

[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:12:59,193 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:12:59,193 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:12:59,193 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:12:59,193 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:12:59,193 >> loading file tokenizer.json
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
[INFO|tokenization_utils.py:493] 2023-10-23 07:12:59,340 >> Adding <s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:12:59,340 >> Adding </s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:12:59,340 >> Adding <unk> to the vocabulary
10/23/2023 07:12:59 - INFO - __main__ - Start shuffling training dataset.
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
Loading cached shuffled indices for dataset at /data/user/liang.zhao/skywork-13b-opensource/data_cache/pt_train_demo/pt_train/train/cache-82bd44c04d4089ca.arrow
10/23/2023 07:12:59 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /data/user/liang.zhao/skywork-13b-opensource/data_cache/pt_train_demo/pt_train/train/cache-82bd44c04d4089ca.arrow
10/23/2023 07:12:59 - INFO - __main__ - shuffle successively!
10/23/2023 07:12:59 - INFO - __main__ - Num train_samples  321
10/23/2023 07:12:59 - INFO - __main__ - Training example:
10/23/2023 07:12:59 - INFO - __main__ - subtract the combined number of speeding tickets from the total number of tickets to find the combined number of parking tickets: 24 - 12 = <<24-12=12>>12
Now express Mark's number of parking tickets in terms of the number of parking tickets Sarah got: m = <<2=2>>2s
We know that m + s = 12, so substitute in the value of m from the previous step to get 2s + s = 12
Combine like terms to get 3s = 12
Divide both sides of the equation to get s = <<4=4>>4
Now multiply the number of parking tickets Sarah got by 2 to find the number Mark got: 4 * 2 = <<4*2=8>>8
#### 8<s> Cooper makes 7 apple pies a day. He does this for 12 days. Ashley then eats 50 of his pies. How many apple pies remain with Cooper? The number of pies Cooper makes in 12 days is 7 pies/day * 12 days = <<7*12=84>>84 apple pies.
After Ashley eats 50 of them, there are 84 pies  50 pies = <<84-50=34>>34 apple pies.
#### 34<s> Lindsey bought 2 exercise bands to intensify her workout.  Each band adds an extra 5 pounds of resistance to her workout.  If she doubles up both sets of bands and places them around her legs and picks up a 10-pound dumbbell, how much weight will she squat? She has 2 exercise bands that are both 5 pounds of resistance so thats 2*5 = <<2*5=10>>10 pounds
She has a pair of 10-pound dumbbells so thats 2*10 = <<10*2=20>>20 pounds
With both the bands and dumbbells, she will squat 10+20 = <<10+20=30>>30 pounds
#### 30<s> Wendy just started working at an Italian restaurant. She polished 50 small glasses and 10 more large glasses than small glasses. How many glasses did she polish? She polished 50 + 10 = <<50+10=60>>60 large glasses.
Therefore, Wendy polished 50 + 60 = <<50+60=110>>110 glasses.
#### 110<s> Miss Darlington has a basket of 20 blueberries. She picked 9 more baskets with the same amount of berries. How many blueberries did Miss Darlington have in all? Miss Darlington picked 9 x 20 = <<9*20=180>>180 blueberries more.
So she had a total of 180 + 20 = <<180+20=200>>200 blueberries.
#### 200<s> In a basketball game, Jon scored 3 points. Jack scored 5 points more than Jon, and Tom scored 4 less than the points of Jon and Jack together. How many points did they score altogether? Jack scored 3 + 5 = <<3+5=8>>8 points.
Together, Jon and Jack scored 8 + 3 = <<8+3=11>>11 points.
So, Tom scored 11 - 4 = <<11-4=7>>7 points.
Thus, Jon, Jack, and Tom scored a total of 3 + 8 + 7 = <<3+8+7=18>>18 points.
#### 18<s> In a shipping container, there are 10 crates. Each crate is filled with 6 boxes and each box is filled with 4 washing machines. A worker removes 1 washing machine from each box. There are no other changes. How many washing machines were removed from the shipping container? Initially, there were 6 boxes * 4 washing machines per box = <<6*4=24>>24 washing machines in each crate.
So there were 24 washing machines per crate * 10 crates = <<24*10=240>>240 washing machines in the shipping container.
A worker removes 1 washing machine from each box so there are now 4 original washing machines - 1 removed washing machine = <<4-1=3>>3 washing machines in each box.
This means there are 6 boxes * 3 washing machines per box = <<6*3=18>>18 washing machines in each crate.
So there are now 18 washing machines per crate * 10 crates = <<18*10=180>>180 washing machines in the shipping container.
The difference is how many machine washing machines were removed which is 240 initial washing machines  180 current washing machines = <<240-180=60>>60 washing machines.
#### 60<s> Darnell has 1000 square feet of fabric that he's using to make mini flags. He makes square flags that are 4 feet by 4 feet, wide rectangular flags that are 5 feet by 3 feet, and tall rectangular flags that are 3 feet by 5 feet. He has already made 16 square flags, 20 wide flags, and 10 tall flags. How many square feet of fabric does he have left? The square flags use 16 square feet of fabric per flag because four times four equals <<4*4=16>>16
The wide flags each use 15 feet of fabric per flag because five times three equals <<5*3=15>>15
The tall flags each use 15 feet of fabric per flag because five times three equals <<5*3=15>>15
He has used 256 square feet for the square flags because 16 times 16 equals <<16*16=256>>256
He has used 300 square feet for the wide flags because 20 times 15 equals <<20*15=300>>300
He has used 150 square feet for the tall flags because ten times 15 equals 150.
He has used 706 square feet because 256 plus 300 plus 150 equals <<256+300+150=706>>706.
He has 294 square feet left because 1,000 minus 706 equals <<1000-706=294>>294
#### 294<s> Matthias has 40 soccer balls and 15 basketballs. 30 soccer balls and 7 basketballs have a hole in them. How many balls in total does Matthias have without holes in them? Matthias has 40-30 = <<40-30=10>>10 soccer balls without holes.
Matthias has 15-7 = <<15-7=8>>8 basketballs without holes.
A total of 10+8 = <<10+8=18>>18 balls do not have holes.
#### 18<s> Jenny is scraping gum off the bottom of the seats in a stadium with two sections. Section A has 1 subsection with 60 seats and 3 subsections with 80 seats each. Section B has 20 more seats than 3 times as many seats as Section A has total. How many seats does Section B have? First find how many total seats are in the 80-seat subsections: 80 seats/subsection * 3 subsections = 240 seats
Then add the number of seats in the 60-seat section to find the total number of seats in Section A: 240 seats + 60 seats = <<240+60=300>>300 seats
Then triple that number: 300 seats * 3 = <<300*3=900>>900 seats
Then add 20 seats to find the total number of seats in Section B: 900 seats + 20 seats = <<900+20=920>>920 seats
#### 920<s> The running time of Beast of War: Armoured Command is 10 minutes longer than that of Alpha Epsilon, which is 30 minutes shorter than that of Millennium. If Millennium runs for 2 hours, what is the running time of Beast of War: Armoured Command in minutes? One hour contains 60 minutes so 2 hours contain 60*2 = <<2*60=120>>120 minutes
Alpha Epsilon's running time is 30 minutes less than that of Millennium (which runs for 120 minutes) hence 120-30 = <<120-30=90>>90 minutes
Beast of War: Armoured Command runs for 10 minutes more than Alpha Epsilon hence 90+10 = <<10+90=100>>100 minutes
#### 100<s> A packet of candy sweets has 30 cherry-flavored sweets, 40 strawberry-flavored sweets, and 50 pineapple-flavored sweets. Aaron eats half of each of the flavored sweets and gives 5 cherry-flavored sweets to his friend. How many sweets are still in the packet of candy? Aaron eats 1/2*30 sweets + 1/2*40 sweets + 1/2*50 sweets = <<1/2*30+1/2*40+1/2*50=60>>60 candy sweets.
The packet of candy sweets still has 60 sweets - 5 sweets = <<60-5=55>>55 candy sweets.
#### 55<s> Oliver has two bags of vegetables. Each bag weighs 1/6 as much as Jamess bag, which weighs 18kg. What is the combined weight of both Olivers bags? Each of Olivers bags weighs 18 kg * 1/6 =<<18*1/6=3>>3 kg.
Combined, both his bags weigh 3 kg * 2 = <<3*2=6>>6 kg.
#### 6<s> Greg's PPO algorithm obtained 90% of the possible reward on the CoinRun environment. CoinRun's maximum reward is half as much as the maximum ProcGen reward of 240. How much reward did Greg's PPO algorithm get? Half of much as ProcGen's maximum reward is 240/2=<<240/2=120>>120 reward
90% of CoinRun's maximum reward is 120*.9=<<120*.9=108>>108 reward
#### 108<s> Julia has a parrot and a rabbit. She buys food for both of the animals for $30 in total a week. Julia has the rabbit for 5 weeks, and the parrot for 3 weeks. How much money did Julia already spend on food for her animals, if the weekly cost of the rabbit food is $12? If the rabbit food costs $12 a week, then the parrot food costs $30 - $12 = $18 a week.
Julia has the parrot for 3 weeks, so she spent 3 weeks * $18/week = $<<3*18=54>>54 on her.
The rabbit is her only for 5 weeks, so she spent 5 weeks * $12/week = $<<5*12=60>>60 on him.
In total, Julia spent $54 + $60 = $<<54+60=114>>114 on food for her animals.
#### 114<s> Janet has 60 less than four times as many siblings as Masud. Carlos has 3/4 times as many siblings as Masud. If Masud has 60 siblings, how many more siblings does Janet have more than Carlos? If Masud has 60 siblings, and Carlos has 3/4 times as many siblings as Masud, Carlos has 3/4*60=<<60*3/4=45>>45 siblings.
Four times as many siblings as Masud has is 4*60=<<4*60=240>>240
Janet has 60 less than four times as many siblings as Masud, a total of 240-60=<<240-60=180>>180 siblings.
The number of siblings Janet have more than Carlos is 180-45=<<180-45=135>>135
#### 135<s> A highway is being extended from its current length of 200 miles up to 650 miles. 50 miles are built on the first day, and three times this amount are built on the second day.  How many miles still need to be added to the highway to finish extending it? The length of the highway that needs to be constructed is 650  200 = <<650-200=450>>450 miles.
After the first day, there are still 450  50 = <<450-50=400>>400 miles that need to be constructed.
On the second day, 50 miles * 3 = <<50*3=150>>150 miles are added to the highway.
This means that 400  150 = <<400-150=250>>250 miles still need to be added to the highway.
#### 250<s> Susan is making jewelry with a repeating pattern that has 3 green beads, 5 purple beads, and twice as many red beads as green beads. If the pattern repeats three times per bracelet and 5 times per necklace, how many beads does she need to make 1 bracelets and 10 necklaces? First find the number of red beads per repeat: 3 green * 2 red/green = <<3*2=6>>6 red
Then add the number of beads of each color to find the total number of bead per repeat: 6 beads + 3 beads + 5 beads = <<6+3+5=14>>14 beads
Then multiply the number of beads per repeat by the number of repeats per bracelet to find the number of beads per bracelet: 14 beads/repeat * 3 repeats/bracelet = <<14*3=42>>42 beads/bracelet
Then multiply the number of beads per repeat by the number of repeats per necklace to find the number of beads per necklace: 14 beads/repeat * 5 repeats/necklace = <<14*5=70>>70 beads/necklace
Then multiply the number of beads per necklace by the number of necklaces to find the total number of beads used in the necklaces: 70 beads/necklace * 10 necklaces = <<70*10=700>>700 beads
Then add the number of beads used in a bracelet to the number of beads in the necklaces to find the total number of beads used: 700 beads + 42 beads = <<700+42=742>>742 beads
#### 742<s> Janet counts 30 crows on the powerlines and 60% more hawks than crows. How many birds does she count total? First find how many more hawks than crows there are: 60% * 30 crows = <<60*.01*30=18>>18 crows
Then add that number to the number of crows to find the total number of hawks: 18 crows + 30 crows = <<18+30=48>>48 crows
Then add the number of crows to the number of hawks to find the total number of birds: 48 crows + 30 crows = <<48+30=78>>78 crows
#### 78<s> Joan has 180 socks. Two thirds of the socks are white, and the rest of the socks are blue. How many blue socks does Joan have? Joan has (180/3)*2 = <<(180/3)*2=120>>120 white socks.
The number of blue socks Joan has is 180-120 = <<180-120=60>>60.
#### 60<s> Simon collected treasures on the beach during his summer vacation. He collected a bucket of pearly seashells, a jar full of smooth sea glass, and a bag of ten sand dollars. If the jar holds three times as many pieces of glass as the bag does sand dollars, and the bucket holds five times as many seashells as the jar holds pieces of glass, how many treasures did Simon find on the beach? The jar holds 
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 359, in main
    device_map=device_map,
UnboundLocalError: local variable 'device_map' referenced before assignment
10/23/2023 07:12:59 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 359, in main
    device_map=device_map,
UnboundLocalError: local variable 'device_map' referenced before assignment
10/23/2023 07:12:59 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:12:59 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:12:59 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:12:59 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True
10/23/2023 07:12:59 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:12:59 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 359, in main
    device_map=device_map,
UnboundLocalError: local variable 'device_map' referenced before assignment
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 359, in main
    device_map=device_map,
UnboundLocalError: local variable 'device_map' referenced before assignment
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 359, in main
    device_map=device_map,
UnboundLocalError: local variable 'device_map' referenced before assignment
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 359, in main
    device_map=device_map,
UnboundLocalError: local variable 'device_map' referenced before assignment
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 359, in main
    device_map=device_map,
UnboundLocalError: local variable 'device_map' referenced before assignment
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 451, in <module>
    main()
  File "train/run_pt.py", line 359, in main
    device_map=device_map,
UnboundLocalError: local variable 'device_map' referenced before assignment
[2023-10-23 07:13:03,532] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 52498) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train/run_pt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-23_07:13:03
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 52499)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-10-23_07:13:03
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 52500)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-10-23_07:13:03
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 52501)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-10-23_07:13:03
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 52502)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-10-23_07:13:03
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 52503)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-10-23_07:13:03
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 52504)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-10-23_07:13:03
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 52505)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-23_07:13:03
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 52498)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[2023-10-23 07:14:10,821] torch.distributed.run: [WARNING] 
[2023-10-23 07:14:10,821] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:14:10,821] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-10-23 07:14:10,821] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:14:15,091] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:14:15,150] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:14:15,158] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:14:15,160] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:14:15,195] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:14:15,214] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:14:15,230] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:14:15,242] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:14:15,759] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:14:15,759] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:14:15,804] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:14:15,804] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:14:15,828] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:14:15,828] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:14:15,843] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:14:15,843] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:14:15,843] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 257, in main
    if lora_args.q_lora:
AttributeError: 'LoraArguments' object has no attribute 'q_lora'
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:14:15,867] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:14:15,868] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:14:15,916] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:14:15,916] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:14:15,919] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:14:15,920] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:14:16,018] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:14:16,018] [INFO] [comm.py:616:init_distributed] cdb=None
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 257, in main
    if lora_args.q_lora:
AttributeError: 'LoraArguments' object has no attribute 'q_lora'
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 257, in main
    if lora_args.q_lora:
AttributeError: 'LoraArguments' object has no attribute 'q_lora'
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 257, in main
    if lora_args.q_lora:
AttributeError: 'LoraArguments' object has no attribute 'q_lora'
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 257, in main
    if lora_args.q_lora:
AttributeError: 'LoraArguments' object has no attribute 'q_lora'
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 257, in main
    if lora_args.q_lora:
AttributeError: 'LoraArguments' object has no attribute 'q_lora'
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 257, in main
    if lora_args.q_lora:
AttributeError: 'LoraArguments' object has no attribute 'q_lora'
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 257, in main
    if lora_args.q_lora:
AttributeError: 'LoraArguments' object has no attribute 'q_lora'
[2023-10-23 07:14:20,922] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 53105) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train/run_pt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-23_07:14:20
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 53106)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-10-23_07:14:20
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 53107)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-10-23_07:14:20
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 53108)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-10-23_07:14:20
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 53109)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-10-23_07:14:20
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 53110)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-10-23_07:14:20
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 53111)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-10-23_07:14:20
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 53112)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-23_07:14:20
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 53105)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[2023-10-23 07:14:28,539] torch.distributed.run: [WARNING] 
[2023-10-23 07:14:28,539] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:14:28,539] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-10-23 07:14:28,539] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:14:33,118] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:14:33,144] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:14:33,147] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:14:33,166] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:14:33,191] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:14:33,199] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:14:33,220] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:14:33,226] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:14:33,771] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:14:33,771] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:14:33,814] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:14:33,814] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:14:33,818] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:14:33,819] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:14:33,823] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:14:33,823] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:14:33,823] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:14:33,868] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:14:33,868] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:14:33,901] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:14:33,902] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:14:33,952] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:14:33,952] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:14:33,986] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:14:33,986] [INFO] [comm.py:616:init_distributed] cdb=None
10/23/2023 07:14:34 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[INFO|configuration_utils.py:713] 2023-10-23 07:14:34,080 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
[INFO|configuration_utils.py:713] 2023-10-23 07:14:34,082 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
[INFO|configuration_utils.py:775] 2023-10-23 07:14:34,083 >> Model config SkyworkConfig {
  "_name_or_path": "/data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base",
  "architectures": [
    "SkyworkForCausalLM"
  ],
  "attention_bias": false,
  "auto_map": {
    "AutoConfig": "configuration_skywork.SkyworkConfig",
    "AutoModelForCausalLM": "modeling_skywork.SkyworkForCausalLM"
  },
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4608,
  "initializer_range": 0.01,
  "intermediate_size": 12288,
  "max_position_embeddings": 4096,
  "model_type": "skywork",
  "num_attention_heads": 36,
  "num_hidden_layers": 52,
  "num_key_value_heads": 36,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.34.0",
  "use_cache": true,
  "use_flash_attention": false,
  "vocab_size": 65519
}

[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:14:34,083 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:14:34,083 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:14:34,083 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:14:34,083 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:14:34,083 >> loading file tokenizer.json
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
[INFO|tokenization_utils.py:493] 2023-10-23 07:14:34,229 >> Adding <s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:14:34,229 >> Adding </s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:14:34,229 >> Adding <unk> to the vocabulary
10/23/2023 07:14:34 - INFO - __main__ - Start shuffling training dataset.
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
Loading cached shuffled indices for dataset at /data/user/liang.zhao/skywork-13b-opensource/data_cache/pt_train_demo/pt_train/train/cache-82bd44c04d4089ca.arrow
10/23/2023 07:14:34 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /data/user/liang.zhao/skywork-13b-opensource/data_cache/pt_train_demo/pt_train/train/cache-82bd44c04d4089ca.arrow
10/23/2023 07:14:34 - INFO - __main__ - shuffle successively!
10/23/2023 07:14:34 - INFO - __main__ - Num train_samples  321
10/23/2023 07:14:34 - INFO - __main__ - Training example:
10/23/2023 07:14:34 - INFO - __main__ - subtract the combined number of speeding tickets from the total number of tickets to find the combined number of parking tickets: 24 - 12 = <<24-12=12>>12
Now express Mark's number of parking tickets in terms of the number of parking tickets Sarah got: m = <<2=2>>2s
We know that m + s = 12, so substitute in the value of m from the previous step to get 2s + s = 12
Combine like terms to get 3s = 12
Divide both sides of the equation to get s = <<4=4>>4
Now multiply the number of parking tickets Sarah got by 2 to find the number Mark got: 4 * 2 = <<4*2=8>>8
#### 8<s> Cooper makes 7 apple pies a day. He does this for 12 days. Ashley then eats 50 of his pies. How many apple pies remain with Cooper? The number of pies Cooper makes in 12 days is 7 pies/day * 12 days = <<7*12=84>>84 apple pies.
After Ashley eats 50 of them, there are 84 pies  50 pies = <<84-50=34>>34 apple pies.
#### 34<s> Lindsey bought 2 exercise bands to intensify her workout.  Each band adds an extra 5 pounds of resistance to her workout.  If she doubles up both sets of bands and places them around her legs and picks up a 10-pound dumbbell, how much weight will she squat? She has 2 exercise bands that are both 5 pounds of resistance so thats 2*5 = <<2*5=10>>10 pounds
She has a pair of 10-pound dumbbells so thats 2*10 = <<10*2=20>>20 pounds
With both the bands and dumbbells, she will squat 10+20 = <<10+20=30>>30 pounds
#### 30<s> Wendy just started working at an Italian restaurant. She polished 50 small glasses and 10 more large glasses than small glasses. How many glasses did she polish? She polished 50 + 10 = <<50+10=60>>60 large glasses.
Therefore, Wendy polished 50 + 60 = <<50+60=110>>110 glasses.
#### 110<s> Miss Darlington has a basket of 20 blueberries. She picked 9 more baskets with the same amount of berries. How many blueberries did Miss Darlington have in all? Miss Darlington picked 9 x 20 = <<9*20=180>>180 blueberries more.
So she had a total of 180 + 20 = <<180+20=200>>200 blueberries.
#### 200<s> In a basketball game, Jon scored 3 points. Jack scored 5 points more than Jon, and Tom scored 4 less than the points of Jon and Jack together. How many points did they score altogether? Jack scored 3 + 5 = <<3+5=8>>8 points.
Together, Jon and Jack scored 8 + 3 = <<8+3=11>>11 points.
So, Tom scored 11 - 4 = <<11-4=7>>7 points.
Thus, Jon, Jack, and Tom scored a total of 3 + 8 + 7 = <<3+8+7=18>>18 points.
#### 18<s> In a shipping container, there are 10 crates. Each crate is filled with 6 boxes and each box is filled with 4 washing machines. A worker removes 1 washing machine from each box. There are no other changes. How many washing machines were removed from the shipping container? Initially, there were 6 boxes * 4 washing machines per box = <<6*4=24>>24 washing machines in each crate.
So there were 24 washing machines per crate * 10 crates = <<24*10=240>>240 washing machines in the shipping container.
A worker removes 1 washing machine from each box so there are now 4 original washing machines - 1 removed washing machine = <<4-1=3>>3 washing machines in each box.
This means there are 6 boxes * 3 washing machines per box = <<6*3=18>>18 washing machines in each crate.
So there are now 18 washing machines per crate * 10 crates = <<18*10=180>>180 washing machines in the shipping container.
The difference is how many machine washing machines were removed which is 240 initial washing machines  180 current washing machines = <<240-180=60>>60 washing machines.
#### 60<s> Darnell has 1000 square feet of fabric that he's using to make mini flags. He makes square flags that are 4 feet by 4 feet, wide rectangular flags that are 5 feet by 3 feet, and tall rectangular flags that are 3 feet by 5 feet. He has already made 16 square flags, 20 wide flags, and 10 tall flags. How many square feet of fabric does he have left? The square flags use 16 square feet of fabric per flag because four times four equals <<4*4=16>>16
The wide flags each use 15 feet of fabric per flag because five times three equals <<5*3=15>>15
The tall flags each use 15 feet of fabric per flag because five times three equals <<5*3=15>>15
He has used 256 square feet for the square flags because 16 times 16 equals <<16*16=256>>256
He has used 300 square feet for the wide flags because 20 times 15 equals <<20*15=300>>300
He has used 150 square feet for the tall flags because ten times 15 equals 150.
He has used 706 square feet because 256 plus 300 plus 150 equals <<256+300+150=706>>706.
He has 294 square feet left because 1,000 minus 706 equals <<1000-706=294>>294
#### 294<s> Matthias has 40 soccer balls and 15 basketballs. 30 soccer balls and 7 basketballs have a hole in them. How many balls in total does Matthias have without holes in them? Matthias has 40-30 = <<40-30=10>>10 soccer balls without holes.
Matthias has 15-7 = <<15-7=8>>8 basketballs without holes.
A total of 10+8 = <<10+8=18>>18 balls do not have holes.
#### 18<s> Jenny is scraping gum off the bottom of the seats in a stadium with two sections. Section A has 1 subsection with 60 seats and 3 subsections with 80 seats each. Section B has 20 more seats than 3 times as many seats as Section A has total. How many seats does Section B have? First find how many total seats are in the 80-seat subsections: 80 seats/subsection * 3 subsections = 240 seats
Then add the number of seats in the 60-seat section to find the total number of seats in Section A: 240 seats + 60 seats = <<240+60=300>>300 seats
Then triple that number: 300 seats * 3 = <<300*3=900>>900 seats
Then add 20 seats to find the total number of seats in Section B: 900 seats + 20 seats = <<900+20=920>>920 seats
#### 920<s> The running time of Beast of War: Armoured Command is 10 minutes longer than that of Alpha Epsilon, which is 30 minutes shorter than that of Millennium. If Millennium runs for 2 hours, what is the running time of Beast of War: Armoured Command in minutes? One hour contains 60 minutes so 2 hours contain 60*2 = <<2*60=120>>120 minutes
Alpha Epsilon's running time is 30 minutes less than that of Millennium (which runs for 120 minutes) hence 120-30 = <<120-30=90>>90 minutes
Beast of War: Armoured Command runs for 10 minutes more than Alpha Epsilon hence 90+10 = <<10+90=100>>100 minutes
#### 100<s> A packet of candy sweets has 30 cherry-flavored sweets, 40 strawberry-flavored sweets, and 50 pineapple-flavored sweets. Aaron eats half of each of the flavored sweets and gives 5 cherry-flavored sweets to his friend. How many sweets are still in the packet of candy? Aaron eats 1/2*30 sweets + 1/2*40 sweets + 1/2*50 sweets = <<1/2*30+1/2*40+1/2*50=60>>60 candy sweets.
The packet of candy sweets still has 60 sweets - 5 sweets = <<60-5=55>>55 candy sweets.
#### 55<s> Oliver has two bags of vegetables. Each bag weighs 1/6 as much as Jamess bag, which weighs 18kg. What is the combined weight of both Olivers bags? Each of Olivers bags weighs 18 kg * 1/6 =<<18*1/6=3>>3 kg.
Combined, both his bags weigh 3 kg * 2 = <<3*2=6>>6 kg.
#### 6<s> Greg's PPO algorithm obtained 90% of the possible reward on the CoinRun environment. CoinRun's maximum reward is half as much as the maximum ProcGen reward of 240. How much reward did Greg's PPO algorithm get? Half of much as ProcGen's maximum reward is 240/2=<<240/2=120>>120 reward
90% of CoinRun's maximum reward is 120*.9=<<120*.9=108>>108 reward
#### 108<s> Julia has a parrot and a rabbit. She buys food for both of the animals for $30 in total a week. Julia has the rabbit for 5 weeks, and the parrot for 3 weeks. How much money did Julia already spend on food for her animals, if the weekly cost of the rabbit food is $12? If the rabbit food costs $12 a week, then the parrot food costs $30 - $12 = $18 a week.
Julia has the parrot for 3 weeks, so she spent 3 weeks * $18/week = $<<3*18=54>>54 on her.
The rabbit is her only for 5 weeks, so she spent 5 weeks * $12/week = $<<5*12=60>>60 on him.
In total, Julia spent $54 + $60 = $<<54+60=114>>114 on food for her animals.
#### 114<s> Janet has 60 less than four times as many siblings as Masud. Carlos has 3/4 times as many siblings as Masud. If Masud has 60 siblings, how many more siblings does Janet have more than Carlos? If Masud has 60 siblings, and Carlos has 3/4 times as many siblings as Masud, Carlos has 3/4*60=<<60*3/4=45>>45 siblings.
Four times as many siblings as Masud has is 4*60=<<4*60=240>>240
Janet has 60 less than four times as many siblings as Masud, a total of 240-60=<<240-60=180>>180 siblings.
The number of siblings Janet have more than Carlos is 180-45=<<180-45=135>>135
#### 135<s> A highway is being extended from its current length of 200 miles up to 650 miles. 50 miles are built on the first day, and three times this amount are built on the second day.  How many miles still need to be added to the highway to finish extending it? The length of the highway that needs to be constructed is 650  200 = <<650-200=450>>450 miles.
After the first day, there are still 450  50 = <<450-50=400>>400 miles that need to be constructed.
On the second day, 50 miles * 3 = <<50*3=150>>150 miles are added to the highway.
This means that 400  150 = <<400-150=250>>250 miles still need to be added to the highway.
#### 250<s> Susan is making jewelry with a repeating pattern that has 3 green beads, 5 purple beads, and twice as many red beads as green beads. If the pattern repeats three times per bracelet and 5 times per necklace, how many beads does she need to make 1 bracelets and 10 necklaces? First find the number of red beads per repeat: 3 green * 2 red/green = <<3*2=6>>6 red
Then add the number of beads of each color to find the total number of bead per repeat: 6 beads + 3 beads + 5 beads = <<6+3+5=14>>14 beads
Then multiply the number of beads per repeat by the number of repeats per bracelet to find the number of beads per bracelet: 14 beads/repeat * 3 repeats/bracelet = <<14*3=42>>42 beads/bracelet
Then multiply the number of beads per repeat by the number of repeats per necklace to find the number of beads per necklace: 14 beads/repeat * 5 repeats/necklace = <<14*5=70>>70 beads/necklace
Then multiply the number of beads per necklace by the number of necklaces to find the total number of beads used in the necklaces: 70 beads/necklace * 10 necklaces = <<70*10=700>>700 beads
Then add the number of beads used in a bracelet to the number of beads in the necklaces to find the total number of beads used: 700 beads + 42 beads = <<700+42=742>>742 beads
#### 742<s> Janet counts 30 crows on the powerlines and 60% more hawks than crows. How many birds does she count total? First find how many more hawks than crows there are: 60% * 30 crows = <<60*.01*30=18>>18 crows
Then add that number to the number of crows to find the total number of hawks: 18 crows + 30 crows = <<18+30=48>>48 crows
Then add the number of crows to the number of hawks to find the total number of birds: 48 crows + 30 crows = <<48+30=78>>78 crows
#### 78<s> Joan has 180 socks. Two thirds of the socks are white, and the rest of the socks are blue. How many blue socks does Joan have? Joan has (180/3)*2 = <<(180/3)*2=120>>120 white socks.
The number of blue socks Joan has is 180-120 = <<180-120=60>>60.
#### 60<s> Simon collected treasures on the beach during his summer vacation. He collected a bucket of pearly seashells, a jar full of smooth sea glass, and a bag of ten sand dollars. If the jar holds three times as many pieces of glass as the bag does sand dollars, and the bucket holds five times as many seashells as the jar holds pieces of glass, how many treasures did Simon find on the beach? The jar holds 
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2569, in from_pretrained
    raise ValueError("Passing along a `device_map` requires `low_cpu_mem_usage=True`")
ValueError: Passing along a `device_map` requires `low_cpu_mem_usage=True`
10/23/2023 07:14:34 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:14:34 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True
10/23/2023 07:14:34 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True
10/23/2023 07:14:34 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True
10/23/2023 07:14:34 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
10/23/2023 07:14:34 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2569, in from_pretrained
    raise ValueError("Passing along a `device_map` requires `low_cpu_mem_usage=True`")
ValueError: Passing along a `device_map` requires `low_cpu_mem_usage=True`
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2569, in from_pretrained
    raise ValueError("Passing along a `device_map` requires `low_cpu_mem_usage=True`")
ValueError: Passing along a `device_map` requires `low_cpu_mem_usage=True`
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2569, in from_pretrained
    raise ValueError("Passing along a `device_map` requires `low_cpu_mem_usage=True`")
ValueError: Passing along a `device_map` requires `low_cpu_mem_usage=True`
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2569, in from_pretrained
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    raise ValueError("Passing along a `device_map` requires `low_cpu_mem_usage=True`")
ValueError: Passing along a `device_map` requires `low_cpu_mem_usage=True`
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2569, in from_pretrained
    raise ValueError("Passing along a `device_map` requires `low_cpu_mem_usage=True`")
ValueError: Passing along a `device_map` requires `low_cpu_mem_usage=True`
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2569, in from_pretrained
    raise ValueError("Passing along a `device_map` requires `low_cpu_mem_usage=True`")
ValueError: Passing along a `device_map` requires `low_cpu_mem_usage=True`
10/23/2023 07:14:35 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2569, in from_pretrained
    raise ValueError("Passing along a `device_map` requires `low_cpu_mem_usage=True`")
ValueError: Passing along a `device_map` requires `low_cpu_mem_usage=True`
[2023-10-23 07:14:38,639] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 53499) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train/run_pt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-23_07:14:38
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 53500)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-10-23_07:14:38
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 53501)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-10-23_07:14:38
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 53502)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-10-23_07:14:38
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 53503)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-10-23_07:14:38
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 53504)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-10-23_07:14:38
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 53505)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-10-23_07:14:38
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 53506)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-23_07:14:38
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 53499)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[2023-10-23 07:15:20,851] torch.distributed.run: [WARNING] 
[2023-10-23 07:15:20,851] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:15:20,851] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-10-23 07:15:20,851] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:15:25,366] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:15:25,383] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:15:25,443] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:15:25,454] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:15:25,513] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:15:25,541] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:15:25,541] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:15:25,548] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:15:26,022] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:15:26,022] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:15:26,095] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:15:26,095] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:15:26,130] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:15:26,130] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:15:26,214] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:15:26,214] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:15:26,229] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:15:26,229] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:15:26,229] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-10-23 07:15:26,229] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:15:26,229] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:15:26,243] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:15:26,243] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:15:26,310] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:15:26,310] [INFO] [comm.py:616:init_distributed] cdb=None
10/23/2023 07:15:26 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[INFO|configuration_utils.py:713] 2023-10-23 07:15:26,516 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
10/23/2023 07:15:26 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True
[INFO|configuration_utils.py:713] 2023-10-23 07:15:26,517 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
[INFO|configuration_utils.py:775] 2023-10-23 07:15:26,518 >> Model config SkyworkConfig {
  "_name_or_path": "/data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base",
  "architectures": [
    "SkyworkForCausalLM"
  ],
  "attention_bias": false,
  "auto_map": {
    "AutoConfig": "configuration_skywork.SkyworkConfig",
    "AutoModelForCausalLM": "modeling_skywork.SkyworkForCausalLM"
  },
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4608,
  "initializer_range": 0.01,
  "intermediate_size": 12288,
  "max_position_embeddings": 4096,
  "model_type": "skywork",
  "num_attention_heads": 36,
  "num_hidden_layers": 52,
  "num_key_value_heads": 36,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.34.0",
  "use_cache": true,
  "use_flash_attention": false,
  "vocab_size": 65519
}

[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:15:26,519 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:15:26,519 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:15:26,519 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:15:26,519 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:15:26,519 >> loading file tokenizer.json
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
[INFO|tokenization_utils.py:493] 2023-10-23 07:15:26,667 >> Adding <s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:15:26,667 >> Adding </s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:15:26,667 >> Adding <unk> to the vocabulary
10/23/2023 07:15:26 - INFO - __main__ - Start shuffling training dataset.
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
Loading cached shuffled indices for dataset at /data/user/liang.zhao/skywork-13b-opensource/data_cache/pt_train_demo/pt_train/train/cache-82bd44c04d4089ca.arrow
10/23/2023 07:15:26 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /data/user/liang.zhao/skywork-13b-opensource/data_cache/pt_train_demo/pt_train/train/cache-82bd44c04d4089ca.arrow
10/23/2023 07:15:26 - INFO - __main__ - shuffle successively!
10/23/2023 07:15:26 - INFO - __main__ - Num train_samples  321
10/23/2023 07:15:26 - INFO - __main__ - Training example:
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
10/23/2023 07:15:26 - INFO - __main__ - subtract the combined number of speeding tickets from the total number of tickets to find the combined number of parking tickets: 24 - 12 = <<24-12=12>>12
Now express Mark's number of parking tickets in terms of the number of parking tickets Sarah got: m = <<2=2>>2s
We know that m + s = 12, so substitute in the value of m from the previous step to get 2s + s = 12
Combine like terms to get 3s = 12
Divide both sides of the equation to get s = <<4=4>>4
Now multiply the number of parking tickets Sarah got by 2 to find the number Mark got: 4 * 2 = <<4*2=8>>8
#### 8<s> Cooper makes 7 apple pies a day. He does this for 12 days. Ashley then eats 50 of his pies. How many apple pies remain with Cooper? The number of pies Cooper makes in 12 days is 7 pies/day * 12 days = <<7*12=84>>84 apple pies.
After Ashley eats 50 of them, there are 84 pies  50 pies = <<84-50=34>>34 apple pies.
#### 34<s> Lindsey bought 2 exercise bands to intensify her workout.  Each band adds an extra 5 pounds of resistance to her workout.  If she doubles up both sets of bands and places them around her legs and picks up a 10-pound dumbbell, how much weight will she squat? She has 2 exercise bands that are both 5 pounds of resistance so thats 2*5 = <<2*5=10>>10 pounds
She has a pair of 10-pound dumbbells so thats 2*10 = <<10*2=20>>20 pounds
With both the bands and dumbbells, she will squat 10+20 = <<10+20=30>>30 pounds
#### 30<s> Wendy just started working at an Italian restaurant. She polished 50 small glasses and 10 more large glasses than small glasses. How many glasses did she polish? She polished 50 + 10 = <<50+10=60>>60 large glasses.
Therefore, Wendy polished 50 + 60 = <<50+60=110>>110 glasses.
#### 110<s> Miss Darlington has a basket of 20 blueberries. She picked 9 more baskets with the same amount of berries. How many blueberries did Miss Darlington have in all? Miss Darlington picked 9 x 20 = <<9*20=180>>180 blueberries more.
So she had a total of 180 + 20 = <<180+20=200>>200 blueberries.
#### 200<s> In a basketball game, Jon scored 3 points. Jack scored 5 points more than Jon, and Tom scored 4 less than the points of Jon and Jack together. How many points did they score altogether? Jack scored 3 + 5 = <<3+5=8>>8 points.
Together, Jon and Jack scored 8 + 3 = <<8+3=11>>11 points.
So, Tom scored 11 - 4 = <<11-4=7>>7 points.
Thus, Jon, Jack, and Tom scored a total of 3 + 8 + 7 = <<3+8+7=18>>18 points.
#### 18<s> In a shipping container, there are 10 crates. Each crate is filled with 6 boxes and each box is filled with 4 washing machines. A worker removes 1 washing machine from each box. There are no other changes. How many washing machines were removed from the shipping container? Initially, there were 6 boxes * 4 washing machines per box = <<6*4=24>>24 washing machines in each crate.
So there were 24 washing machines per crate * 10 crates = <<24*10=240>>240 washing machines in the shipping container.
A worker removes 1 washing machine from each box so there are now 4 original washing machines - 1 removed washing machine = <<4-1=3>>3 washing machines in each box.
This means there are 6 boxes * 3 washing machines per box = <<6*3=18>>18 washing machines in each crate.
So there are now 18 washing machines per crate * 10 crates = <<18*10=180>>180 washing machines in the shipping container.
The difference is how many machine washing machines were removed which is 240 initial washing machines  180 current washing machines = <<240-180=60>>60 washing machines.
#### 60<s> Darnell has 1000 square feet of fabric that he's using to make mini flags. He makes square flags that are 4 feet by 4 feet, wide rectangular flags that are 5 feet by 3 feet, and tall rectangular flags that are 3 feet by 5 feet. He has already made 16 square flags, 20 wide flags, and 10 tall flags. How many square feet of fabric does he have left? The square flags use 16 square feet of fabric per flag because four times four equals <<4*4=16>>16
The wide flags each use 15 feet of fabric per flag because five times three equals <<5*3=15>>15
The tall flags each use 15 feet of fabric per flag because five times three equals <<5*3=15>>15
He has used 256 square feet for the square flags because 16 times 16 equals <<16*16=256>>256
He has used 300 square feet for the wide flags because 20 times 15 equals <<20*15=300>>300
He has used 150 square feet for the tall flags because ten times 15 equals 150.
He has used 706 square feet because 256 plus 300 plus 150 equals <<256+300+150=706>>706.
He has 294 square feet left because 1,000 minus 706 equals <<1000-706=294>>294
#### 294<s> Matthias has 40 soccer balls and 15 basketballs. 30 soccer balls and 7 basketballs have a hole in them. How many balls in total does Matthias have without holes in them? Matthias has 40-30 = <<40-30=10>>10 soccer balls without holes.
Matthias has 15-7 = <<15-7=8>>8 basketballs without holes.
A total of 10+8 = <<10+8=18>>18 balls do not have holes.
#### 18<s> Jenny is scraping gum off the bottom of the seats in a stadium with two sections. Section A has 1 subsection with 60 seats and 3 subsections with 80 seats each. Section B has 20 more seats than 3 times as many seats as Section A has total. How many seats does Section B have? First find how many total seats are in the 80-seat subsections: 80 seats/subsection * 3 subsections = 240 seats
Then add the number of seats in the 60-seat section to find the total number of seats in Section A: 240 seats + 60 seats = <<240+60=300>>300 seats
Then triple that number: 300 seats * 3 = <<300*3=900>>900 seats
Then add 20 seats to find the total number of seats in Section B: 900 seats + 20 seats = <<900+20=920>>920 seats
#### 920<s> The running time of Beast of War: Armoured Command is 10 minutes longer than that of Alpha Epsilon, which is 30 minutes shorter than that of Millennium. If Millennium runs for 2 hours, what is the running time of Beast of War: Armoured Command in minutes? One hour contains 60 minutes so 2 hours contain 60*2 = <<2*60=120>>120 minutes
Alpha Epsilon's running time is 30 minutes less than that of Millennium (which runs for 120 minutes) hence 120-30 = <<120-30=90>>90 minutes
Beast of War: Armoured Command runs for 10 minutes more than Alpha Epsilon hence 90+10 = <<10+90=100>>100 minutes
#### 100<s> A packet of candy sweets has 30 cherry-flavored sweets, 40 strawberry-flavored sweets, and 50 pineapple-flavored sweets. Aaron eats half of each of the flavored sweets and gives 5 cherry-flavored sweets to his friend. How many sweets are still in the packet of candy? Aaron eats 1/2*30 sweets + 1/2*40 sweets + 1/2*50 sweets = <<1/2*30+1/2*40+1/2*50=60>>60 candy sweets.
The packet of candy sweets still has 60 sweets - 5 sweets = <<60-5=55>>55 candy sweets.
#### 55<s> Oliver has two bags of vegetables. Each bag weighs 1/6 as much as Jamess bag, which weighs 18kg. What is the combined weight of both Olivers bags? Each of Olivers bags weighs 18 kg * 1/6 =<<18*1/6=3>>3 kg.
Combined, both his bags weigh 3 kg * 2 = <<3*2=6>>6 kg.
#### 6<s> Greg's PPO algorithm obtained 90% of the possible reward on the CoinRun environment. CoinRun's maximum reward is half as much as the maximum ProcGen reward of 240. How much reward did Greg's PPO algorithm get? Half of much as ProcGen's maximum reward is 240/2=<<240/2=120>>120 reward
90% of CoinRun's maximum reward is 120*.9=<<120*.9=108>>108 reward
#### 108<s> Julia has a parrot and a rabbit. She buys food for both of the animals for $30 in total a week. Julia has the rabbit for 5 weeks, and the parrot for 3 weeks. How much money did Julia already spend on food for her animals, if the weekly cost of the rabbit food is $12? If the rabbit food costs $12 a week, then the parrot food costs $30 - $12 = $18 a week.
Julia has the parrot for 3 weeks, so she spent 3 weeks * $18/week = $<<3*18=54>>54 on her.
The rabbit is her only for 5 weeks, so she spent 5 weeks * $12/week = $<<5*12=60>>60 on him.
In total, Julia spent $54 + $60 = $<<54+60=114>>114 on food for her animals.
#### 114<s> Janet has 60 less than four times as many siblings as Masud. Carlos has 3/4 times as many siblings as Masud. If Masud has 60 siblings, how many more siblings does Janet have more than Carlos? If Masud has 60 siblings, and Carlos has 3/4 times as many siblings as Masud, Carlos has 3/4*60=<<60*3/4=45>>45 siblings.
Four times as many siblings as Masud has is 4*60=<<4*60=240>>240
Janet has 60 less than four times as many siblings as Masud, a total of 240-60=<<240-60=180>>180 siblings.
The number of siblings Janet have more than Carlos is 180-45=<<180-45=135>>135
#### 135<s> A highway is being extended from its current length of 200 miles up to 650 miles. 50 miles are built on the first day, and three times this amount are built on the second day.  How many miles still need to be added to the highway to finish extending it? The length of the highway that needs to be constructed is 650  200 = <<650-200=450>>450 miles.
After the first day, there are still 450  50 = <<450-50=400>>400 miles that need to be constructed.
On the second day, 50 miles * 3 = <<50*3=150>>150 miles are added to the highway.
This means that 400  150 = <<400-150=250>>250 miles still need to be added to the highway.
#### 250<s> Susan is making jewelry with a repeating pattern that has 3 green beads, 5 purple beads, and twice as many red beads as green beads. If the pattern repeats three times per bracelet and 5 times per necklace, how many beads does she need to make 1 bracelets and 10 necklaces? First find the number of red beads per repeat: 3 green * 2 red/green = <<3*2=6>>6 red
Then add the number of beads of each color to find the total number of bead per repeat: 6 beads + 3 beads + 5 beads = <<6+3+5=14>>14 beads
Then multiply the number of beads per repeat by the number of repeats per bracelet to find the number of beads per bracelet: 14 beads/repeat * 3 repeats/bracelet = <<14*3=42>>42 beads/bracelet
Then multiply the number of beads per repeat by the number of repeats per necklace to find the number of beads per necklace: 14 beads/repeat * 5 repeats/necklace = <<14*5=70>>70 beads/necklace
Then multiply the number of beads per necklace by the number of necklaces to find the total number of beads used in the necklaces: 70 beads/necklace * 10 necklaces = <<70*10=700>>700 beads
Then add the number of beads used in a bracelet to the number of beads in the necklaces to find the total number of beads used: 700 beads + 42 beads = <<700+42=742>>742 beads
#### 742<s> Janet counts 30 crows on the powerlines and 60% more hawks than crows. How many birds does she count total? First find how many more hawks than crows there are: 60% * 30 crows = <<60*.01*30=18>>18 crows
Then add that number to the number of crows to find the total number of hawks: 18 crows + 30 crows = <<18+30=48>>48 crows
Then add the number of crows to the number of hawks to find the total number of birds: 48 crows + 30 crows = <<48+30=78>>78 crows
#### 78<s> Joan has 180 socks. Two thirds of the socks are white, and the rest of the socks are blue. How many blue socks does Joan have? Joan has (180/3)*2 = <<(180/3)*2=120>>120 white socks.
The number of blue socks Joan has is 180-120 = <<180-120=60>>60.
#### 60<s> Simon collected treasures on the beach during his summer vacation. He collected a bucket of pearly seashells, a jar full of smooth sea glass, and a bag of ten sand dollars. If the jar holds three times as many pieces of glass as the bag does sand dollars, and the bucket holds five times as many seashells as the jar holds pieces of glass, how many treasures did Simon find on the beach? The jar holds 
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2569, in from_pretrained
    raise ValueError("Passing along a `device_map` requires `low_cpu_mem_usage=True`")
ValueError: Passing along a `device_map` requires `low_cpu_mem_usage=True`
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2569, in from_pretrained
    raise ValueError("Passing along a `device_map` requires `low_cpu_mem_usage=True`")
ValueError: Passing along a `device_map` requires `low_cpu_mem_usage=True`
10/23/2023 07:15:26 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:15:26 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
10/23/2023 07:15:26 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:15:26 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True
10/23/2023 07:15:26 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:15:26 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2569, in from_pretrained
    raise ValueError("Passing along a `device_map` requires `low_cpu_mem_usage=True`")
ValueError: Passing along a `device_map` requires `low_cpu_mem_usage=True`
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2569, in from_pretrained
    raise ValueError("Passing along a `device_map` requires `low_cpu_mem_usage=True`")
ValueError: Passing along a `device_map` requires `low_cpu_mem_usage=True`
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2569, in from_pretrained
    raise ValueError("Passing along a `device_map` requires `low_cpu_mem_usage=True`")
ValueError: Passing along a `device_map` requires `low_cpu_mem_usage=True`
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2569, in from_pretrained
    raise ValueError("Passing along a `device_map` requires `low_cpu_mem_usage=True`")
ValueError: Passing along a `device_map` requires `low_cpu_mem_usage=True`
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2569, in from_pretrained
    raise ValueError("Passing along a `device_map` requires `low_cpu_mem_usage=True`")
ValueError: Passing along a `device_map` requires `low_cpu_mem_usage=True`
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2569, in from_pretrained
    raise ValueError("Passing along a `device_map` requires `low_cpu_mem_usage=True`")
ValueError: Passing along a `device_map` requires `low_cpu_mem_usage=True`
[2023-10-23 07:15:30,961] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 54003) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train/run_pt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-23_07:15:30
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 54004)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-10-23_07:15:30
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 54005)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-10-23_07:15:30
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 54006)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-10-23_07:15:30
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 54007)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-10-23_07:15:30
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 54008)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-10-23_07:15:30
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 54009)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-10-23_07:15:30
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 54010)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-23_07:15:30
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 54003)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[2023-10-23 07:18:41,435] torch.distributed.run: [WARNING] 
[2023-10-23 07:18:41,435] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:18:41,435] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-10-23 07:18:41,435] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:18:45,669] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:18:45,721] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:18:45,755] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:18:45,761] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:18:45,877] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:18:45,930] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:18:46,066] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:18:46,088] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:18:46,323] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:18:46,323] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:18:46,385] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:18:46,385] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:18:46,385] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:18:46,425] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:18:46,425] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:18:46,426] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:18:46,426] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:18:46,555] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:18:46,555] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:18:46,610] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:18:46,610] [INFO] [comm.py:616:init_distributed] cdb=None
10/23/2023 07:18:46 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[INFO|configuration_utils.py:713] 2023-10-23 07:18:46,639 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
[INFO|configuration_utils.py:713] 2023-10-23 07:18:46,640 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
[INFO|configuration_utils.py:775] 2023-10-23 07:18:46,641 >> Model config SkyworkConfig {
  "_name_or_path": "/data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base",
  "architectures": [
    "SkyworkForCausalLM"
  ],
  "attention_bias": false,
  "auto_map": {
    "AutoConfig": "configuration_skywork.SkyworkConfig",
    "AutoModelForCausalLM": "modeling_skywork.SkyworkForCausalLM"
  },
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4608,
  "initializer_range": 0.01,
  "intermediate_size": 12288,
  "max_position_embeddings": 4096,
  "model_type": "skywork",
  "num_attention_heads": 36,
  "num_hidden_layers": 52,
  "num_key_value_heads": 36,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.34.0",
  "use_cache": true,
  "use_flash_attention": false,
  "vocab_size": 65519
}

[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:18:46,642 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:18:46,642 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:18:46,642 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:18:46,642 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:18:46,642 >> loading file tokenizer.json
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:18:46,771] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:18:46,771] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:18:46,793] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:18:46,793] [INFO] [comm.py:616:init_distributed] cdb=None
[INFO|tokenization_utils.py:493] 2023-10-23 07:18:46,796 >> Adding <s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:18:46,797 >> Adding </s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:18:46,797 >> Adding <unk> to the vocabulary
10/23/2023 07:18:46 - INFO - __main__ - Start shuffling training dataset.
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
Loading cached shuffled indices for dataset at /data/user/liang.zhao/skywork-13b-opensource/data_cache/pt_train_demo/pt_train/train/cache-82bd44c04d4089ca.arrow
10/23/2023 07:18:46 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /data/user/liang.zhao/skywork-13b-opensource/data_cache/pt_train_demo/pt_train/train/cache-82bd44c04d4089ca.arrow
10/23/2023 07:18:46 - INFO - __main__ - shuffle successively!
10/23/2023 07:18:46 - INFO - __main__ - Num train_samples  321
10/23/2023 07:18:46 - INFO - __main__ - Training example:
10/23/2023 07:18:46 - INFO - __main__ - subtract the combined number of speeding tickets from the total number of tickets to find the combined number of parking tickets: 24 - 12 = <<24-12=12>>12
Now express Mark's number of parking tickets in terms of the number of parking tickets Sarah got: m = <<2=2>>2s
We know that m + s = 12, so substitute in the value of m from the previous step to get 2s + s = 12
Combine like terms to get 3s = 12
Divide both sides of the equation to get s = <<4=4>>4
Now multiply the number of parking tickets Sarah got by 2 to find the number Mark got: 4 * 2 = <<4*2=8>>8
#### 8<s> Cooper makes 7 apple pies a day. He does this for 12 days. Ashley then eats 50 of his pies. How many apple pies remain with Cooper? The number of pies Cooper makes in 12 days is 7 pies/day * 12 days = <<7*12=84>>84 apple pies.
After Ashley eats 50 of them, there are 84 pies  50 pies = <<84-50=34>>34 apple pies.
#### 34<s> Lindsey bought 2 exercise bands to intensify her workout.  Each band adds an extra 5 pounds of resistance to her workout.  If she doubles up both sets of bands and places them around her legs and picks up a 10-pound dumbbell, how much weight will she squat? She has 2 exercise bands that are both 5 pounds of resistance so thats 2*5 = <<2*5=10>>10 pounds
She has a pair of 10-pound dumbbells so thats 2*10 = <<10*2=20>>20 pounds
With both the bands and dumbbells, she will squat 10+20 = <<10+20=30>>30 pounds
#### 30<s> Wendy just started working at an Italian restaurant. She polished 50 small glasses and 10 more large glasses than small glasses. How many glasses did she polish? She polished 50 + 10 = <<50+10=60>>60 large glasses.
Therefore, Wendy polished 50 + 60 = <<50+60=110>>110 glasses.
#### 110<s> Miss Darlington has a basket of 20 blueberries. She picked 9 more baskets with the same amount of berries. How many blueberries did Miss Darlington have in all? Miss Darlington picked 9 x 20 = <<9*20=180>>180 blueberries more.
So she had a total of 180 + 20 = <<180+20=200>>200 blueberries.
#### 200<s> In a basketball game, Jon scored 3 points. Jack scored 5 points more than Jon, and Tom scored 4 less than the points of Jon and Jack together. How many points did they score altogether? Jack scored 3 + 5 = <<3+5=8>>8 points.
Together, Jon and Jack scored 8 + 3 = <<8+3=11>>11 points.
So, Tom scored 11 - 4 = <<11-4=7>>7 points.
Thus, Jon, Jack, and Tom scored a total of 3 + 8 + 7 = <<3+8+7=18>>18 points.
#### 18<s> In a shipping container, there are 10 crates. Each crate is filled with 6 boxes and each box is filled with 4 washing machines. A worker removes 1 washing machine from each box. There are no other changes. How many washing machines were removed from the shipping container? Initially, there were 6 boxes * 4 washing machines per box = <<6*4=24>>24 washing machines in each crate.
So there were 24 washing machines per crate * 10 crates = <<24*10=240>>240 washing machines in the shipping container.
A worker removes 1 washing machine from each box so there are now 4 original washing machines - 1 removed washing machine = <<4-1=3>>3 washing machines in each box.
This means there are 6 boxes * 3 washing machines per box = <<6*3=18>>18 washing machines in each crate.
So there are now 18 washing machines per crate * 10 crates = <<18*10=180>>180 washing machines in the shipping container.
The difference is how many machine washing machines were removed which is 240 initial washing machines  180 current washing machines = <<240-180=60>>60 washing machines.
#### 60<s> Darnell has 1000 square feet of fabric that he's using to make mini flags. He makes square flags that are 4 feet by 4 feet, wide rectangular flags that are 5 feet by 3 feet, and tall rectangular flags that are 3 feet by 5 feet. He has already made 16 square flags, 20 wide flags, and 10 tall flags. How many square feet of fabric does he have left? The square flags use 16 square feet of fabric per flag because four times four equals <<4*4=16>>16
The wide flags each use 15 feet of fabric per flag because five times three equals <<5*3=15>>15
The tall flags each use 15 feet of fabric per flag because five times three equals <<5*3=15>>15
He has used 256 square feet for the square flags because 16 times 16 equals <<16*16=256>>256
He has used 300 square feet for the wide flags because 20 times 15 equals <<20*15=300>>300
He has used 150 square feet for the tall flags because ten times 15 equals 150.
He has used 706 square feet because 256 plus 300 plus 150 equals <<256+300+150=706>>706.
He has 294 square feet left because 1,000 minus 706 equals <<1000-706=294>>294
#### 294<s> Matthias has 40 soccer balls and 15 basketballs. 30 soccer balls and 7 basketballs have a hole in them. How many balls in total does Matthias have without holes in them? Matthias has 40-30 = <<40-30=10>>10 soccer balls without holes.
Matthias has 15-7 = <<15-7=8>>8 basketballs without holes.
A total of 10+8 = <<10+8=18>>18 balls do not have holes.
#### 18<s> Jenny is scraping gum off the bottom of the seats in a stadium with two sections. Section A has 1 subsection with 60 seats and 3 subsections with 80 seats each. Section B has 20 more seats than 3 times as many seats as Section A has total. How many seats does Section B have? First find how many total seats are in the 80-seat subsections: 80 seats/subsection * 3 subsections = 240 seats
Then add the number of seats in the 60-seat section to find the total number of seats in Section A: 240 seats + 60 seats = <<240+60=300>>300 seats
Then triple that number: 300 seats * 3 = <<300*3=900>>900 seats
Then add 20 seats to find the total number of seats in Section B: 900 seats + 20 seats = <<900+20=920>>920 seats
#### 920<s> The running time of Beast of War: Armoured Command is 10 minutes longer than that of Alpha Epsilon, which is 30 minutes shorter than that of Millennium. If Millennium runs for 2 hours, what is the running time of Beast of War: Armoured Command in minutes? One hour contains 60 minutes so 2 hours contain 60*2 = <<2*60=120>>120 minutes
Alpha Epsilon's running time is 30 minutes less than that of Millennium (which runs for 120 minutes) hence 120-30 = <<120-30=90>>90 minutes
Beast of War: Armoured Command runs for 10 minutes more than Alpha Epsilon hence 90+10 = <<10+90=100>>100 minutes
#### 100<s> A packet of candy sweets has 30 cherry-flavored sweets, 40 strawberry-flavored sweets, and 50 pineapple-flavored sweets. Aaron eats half of each of the flavored sweets and gives 5 cherry-flavored sweets to his friend. How many sweets are still in the packet of candy? Aaron eats 1/2*30 sweets + 1/2*40 sweets + 1/2*50 sweets = <<1/2*30+1/2*40+1/2*50=60>>60 candy sweets.
The packet of candy sweets still has 60 sweets - 5 sweets = <<60-5=55>>55 candy sweets.
#### 55<s> Oliver has two bags of vegetables. Each bag weighs 1/6 as much as Jamess bag, which weighs 18kg. What is the combined weight of both Olivers bags? Each of Olivers bags weighs 18 kg * 1/6 =<<18*1/6=3>>3 kg.
Combined, both his bags weigh 3 kg * 2 = <<3*2=6>>6 kg.
#### 6<s> Greg's PPO algorithm obtained 90% of the possible reward on the CoinRun environment. CoinRun's maximum reward is half as much as the maximum ProcGen reward of 240. How much reward did Greg's PPO algorithm get? Half of much as ProcGen's maximum reward is 240/2=<<240/2=120>>120 reward
90% of CoinRun's maximum reward is 120*.9=<<120*.9=108>>108 reward
#### 108<s> Julia has a parrot and a rabbit. She buys food for both of the animals for $30 in total a week. Julia has the rabbit for 5 weeks, and the parrot for 3 weeks. How much money did Julia already spend on food for her animals, if the weekly cost of the rabbit food is $12? If the rabbit food costs $12 a week, then the parrot food costs $30 - $12 = $18 a week.
Julia has the parrot for 3 weeks, so she spent 3 weeks * $18/week = $<<3*18=54>>54 on her.
The rabbit is her only for 5 weeks, so she spent 5 weeks * $12/week = $<<5*12=60>>60 on him.
In total, Julia spent $54 + $60 = $<<54+60=114>>114 on food for her animals.
#### 114<s> Janet has 60 less than four times as many siblings as Masud. Carlos has 3/4 times as many siblings as Masud. If Masud has 60 siblings, how many more siblings does Janet have more than Carlos? If Masud has 60 siblings, and Carlos has 3/4 times as many siblings as Masud, Carlos has 3/4*60=<<60*3/4=45>>45 siblings.
Four times as many siblings as Masud has is 4*60=<<4*60=240>>240
Janet has 60 less than four times as many siblings as Masud, a total of 240-60=<<240-60=180>>180 siblings.
The number of siblings Janet have more than Carlos is 180-45=<<180-45=135>>135
#### 135<s> A highway is being extended from its current length of 200 miles up to 650 miles. 50 miles are built on the first day, and three times this amount are built on the second day.  How many miles still need to be added to the highway to finish extending it? The length of the highway that needs to be constructed is 650  200 = <<650-200=450>>450 miles.
After the first day, there are still 450  50 = <<450-50=400>>400 miles that need to be constructed.
On the second day, 50 miles * 3 = <<50*3=150>>150 miles are added to the highway.
This means that 400  150 = <<400-150=250>>250 miles still need to be added to the highway.
#### 250<s> Susan is making jewelry with a repeating pattern that has 3 green beads, 5 purple beads, and twice as many red beads as green beads. If the pattern repeats three times per bracelet and 5 times per necklace, how many beads does she need to make 1 bracelets and 10 necklaces? First find the number of red beads per repeat: 3 green * 2 red/green = <<3*2=6>>6 red
Then add the number of beads of each color to find the total number of bead per repeat: 6 beads + 3 beads + 5 beads = <<6+3+5=14>>14 beads
Then multiply the number of beads per repeat by the number of repeats per bracelet to find the number of beads per bracelet: 14 beads/repeat * 3 repeats/bracelet = <<14*3=42>>42 beads/bracelet
Then multiply the number of beads per repeat by the number of repeats per necklace to find the number of beads per necklace: 14 beads/repeat * 5 repeats/necklace = <<14*5=70>>70 beads/necklace
Then multiply the number of beads per necklace by the number of necklaces to find the total number of beads used in the necklaces: 70 beads/necklace * 10 necklaces = <<70*10=700>>700 beads
Then add the number of beads used in a bracelet to the number of beads in the necklaces to find the total number of beads used: 700 beads + 42 beads = <<700+42=742>>742 beads
#### 742<s> Janet counts 30 crows on the powerlines and 60% more hawks than crows. How many birds does she count total? First find how many more hawks than crows there are: 60% * 30 crows = <<60*.01*30=18>>18 crows
Then add that number to the number of crows to find the total number of hawks: 18 crows + 30 crows = <<18+30=48>>48 crows
Then add the number of crows to the number of hawks to find the total number of birds: 48 crows + 30 crows = <<48+30=78>>78 crows
#### 78<s> Joan has 180 socks. Two thirds of the socks are white, and the rest of the socks are blue. How many blue socks does Joan have? Joan has (180/3)*2 = <<(180/3)*2=120>>120 white socks.
The number of blue socks Joan has is 180-120 = <<180-120=60>>60.
#### 60<s> Simon collected treasures on the beach during his summer vacation. He collected a bucket of pearly seashells, a jar full of smooth sea glass, and a bag of ten sand dollars. If the jar holds three times as many pieces of glass as the bag does sand dollars, and the bucket holds five times as many seashells as the jar holds pieces of glass, how many treasures did Simon find on the beach? The jar holds 
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
[INFO|modeling_utils.py:2990] 2023-10-23 07:18:46,896 >> loading weights file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/pytorch_model.bin.index.json
[INFO|configuration_utils.py:770] 2023-10-23 07:18:46,916 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "pad_token_id": 0
}

10/23/2023 07:18:46 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:18:47 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:18:47 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
10/23/2023 07:18:47 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:18:47 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
10/23/2023 07:18:47 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:18:47 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   2%|         | 1/53 [00:02<01:59,  2.30s/it]Loading checkpoint shards:   2%|         | 1/53 [00:01<01:42,  1.97s/it]Loading checkpoint shards:   2%|         | 1/53 [00:01<01:43,  2.00s/it]Loading checkpoint shards:   2%|         | 1/53 [00:02<02:11,  2.53s/it]Loading checkpoint shards:   2%|         | 1/53 [00:02<01:49,  2.11s/it]Loading checkpoint shards:   2%|         | 1/53 [00:02<02:10,  2.52s/it]Loading checkpoint shards:   2%|         | 1/53 [00:02<02:11,  2.52s/it]Loading checkpoint shards:   2%|         | 1/53 [00:02<01:52,  2.16s/it]Loading checkpoint shards:   4%|         | 2/53 [00:05<02:20,  2.75s/it]Loading checkpoint shards:   4%|         | 2/53 [00:05<02:14,  2.63s/it]Loading checkpoint shards:   4%|         | 2/53 [00:05<02:15,  2.67s/it]Loading checkpoint shards:   4%|         | 2/53 [00:05<02:24,  2.83s/it]Loading checkpoint shards:   4%|         | 2/53 [00:05<02:15,  2.66s/it]Loading checkpoint shards:   4%|         | 2/53 [00:05<02:25,  2.86s/it]Loading checkpoint shards:   4%|         | 2/53 [00:05<02:16,  2.68s/it]Loading checkpoint shards:   4%|         | 2/53 [00:05<02:25,  2.86s/it]Loading checkpoint shards:   6%|         | 3/53 [00:08<02:16,  2.74s/it]Loading checkpoint shards:   6%|         | 3/53 [00:08<02:17,  2.76s/it]Loading checkpoint shards:   6%|         | 3/53 [00:07<02:14,  2.68s/it]Loading checkpoint shards:   6%|         | 3/53 [00:07<02:14,  2.70s/it]Loading checkpoint shards:   6%|         | 3/53 [00:08<02:19,  2.79s/it]Loading checkpoint shards:   6%|         | 3/53 [00:07<02:15,  2.71s/it]Loading checkpoint shards:   6%|         | 3/53 [00:07<02:15,  2.72s/it]Loading checkpoint shards:   6%|         | 3/53 [00:08<02:21,  2.82s/it]Loading checkpoint shards:   8%|         | 4/53 [00:09<02:00,  2.46s/it]Loading checkpoint shards:   8%|         | 4/53 [00:10<02:03,  2.52s/it]Loading checkpoint shards:   8%|         | 4/53 [00:10<02:04,  2.54s/it]Loading checkpoint shards:   8%|         | 4/53 [00:10<02:02,  2.50s/it]Loading checkpoint shards:   8%|         | 4/53 [00:10<02:06,  2.58s/it]Loading checkpoint shards:   8%|         | 4/53 [00:10<02:03,  2.51s/it]Loading checkpoint shards:   8%|         | 4/53 [00:10<02:02,  2.50s/it]Loading checkpoint shards:   8%|         | 4/53 [00:10<02:07,  2.59s/it]Loading checkpoint shards:   9%|         | 5/53 [00:12<01:54,  2.38s/it]Loading checkpoint shards:   9%|         | 5/53 [00:12<01:53,  2.36s/it]Loading checkpoint shards:   9%|         | 5/53 [00:12<01:52,  2.34s/it]Loading checkpoint shards:   9%|         | 5/53 [00:12<01:55,  2.40s/it]Loading checkpoint shards:   9%|         | 5/53 [00:12<01:53,  2.37s/it]Loading checkpoint shards:   9%|         | 5/53 [00:12<01:53,  2.36s/it]Loading checkpoint shards:   9%|         | 5/53 [00:12<01:55,  2.41s/it]Loading checkpoint shards:   9%|         | 5/53 [00:12<01:58,  2.47s/it]Loading checkpoint shards:  11%|        | 6/53 [00:15<02:04,  2.65s/it]Loading checkpoint shards:  11%|        | 6/53 [00:15<02:05,  2.67s/it]Loading checkpoint shards:  11%|        | 6/53 [00:15<02:04,  2.64s/it]Loading checkpoint shards:  11%|        | 6/53 [00:15<02:05,  2.67s/it]Loading checkpoint shards:  11%|        | 6/53 [00:15<02:05,  2.67s/it]Loading checkpoint shards:  11%|        | 6/53 [00:15<02:06,  2.69s/it]Loading checkpoint shards:  11%|        | 6/53 [00:15<02:06,  2.69s/it]Loading checkpoint shards:  11%|        | 6/53 [00:15<02:08,  2.73s/it]Loading checkpoint shards:  13%|        | 7/53 [00:18<02:04,  2.70s/it]Loading checkpoint shards:  13%|        | 7/53 [00:18<02:04,  2.71s/it]Loading checkpoint shards:  13%|        | 7/53 [00:18<02:04,  2.71s/it]Loading checkpoint shards:  13%|        | 7/53 [00:18<02:04,  2.70s/it]Loading checkpoint shards:  13%|        | 7/53 [00:18<02:05,  2.72s/it]Loading checkpoint shards:  13%|        | 7/53 [00:18<02:06,  2.75s/it]Loading checkpoint shards:  13%|        | 7/53 [00:18<02:07,  2.77s/it]Loading checkpoint shards:  13%|        | 7/53 [00:18<02:07,  2.78s/it]Loading checkpoint shards:  15%|        | 8/53 [00:21<02:05,  2.79s/it]Loading checkpoint shards:  15%|        | 8/53 [00:21<02:06,  2.82s/it]Loading checkpoint shards:  15%|        | 8/53 [00:21<02:07,  2.83s/it]Loading checkpoint shards:  15%|        | 8/53 [00:21<02:07,  2.83s/it]Loading checkpoint shards:  15%|        | 8/53 [00:21<02:08,  2.85s/it]Loading checkpoint shards:  15%|        | 8/53 [00:21<02:08,  2.85s/it]Loading checkpoint shards:  15%|        | 8/53 [00:21<02:08,  2.85s/it]Loading checkpoint shards:  15%|        | 8/53 [00:21<02:08,  2.85s/it]Loading checkpoint shards:  17%|        | 9/53 [00:23<01:58,  2.69s/it]Loading checkpoint shards:  17%|        | 9/53 [00:24<01:58,  2.69s/it]Loading checkpoint shards:  17%|        | 9/53 [00:23<01:58,  2.69s/it]Loading checkpoint shards:  17%|        | 9/53 [00:23<01:59,  2.71s/it]Loading checkpoint shards:  17%|        | 9/53 [00:23<02:00,  2.74s/it]Loading checkpoint shards:  17%|        | 9/53 [00:24<02:00,  2.73s/it]Loading checkpoint shards:  17%|        | 9/53 [00:24<01:59,  2.72s/it]Loading checkpoint shards:  17%|        | 9/53 [00:24<02:00,  2.73s/it]Loading checkpoint shards:  19%|        | 10/53 [00:26<01:51,  2.59s/it]Loading checkpoint shards:  19%|        | 10/53 [00:26<01:52,  2.61s/it]Loading checkpoint shards:  19%|        | 10/53 [00:26<01:52,  2.61s/it]Loading checkpoint shards:  19%|        | 10/53 [00:26<01:52,  2.62s/it]Loading checkpoint shards:  19%|        | 10/53 [00:26<01:52,  2.62s/it]Loading checkpoint shards:  19%|        | 10/53 [00:26<01:51,  2.60s/it]Loading checkpoint shards:  19%|        | 10/53 [00:26<01:51,  2.60s/it]Loading checkpoint shards:  19%|        | 10/53 [00:26<01:52,  2.61s/it]Loading checkpoint shards:  21%|        | 11/53 [00:29<01:54,  2.72s/it]Loading checkpoint shards:  21%|        | 11/53 [00:29<01:55,  2.75s/it]Loading checkpoint shards:  21%|        | 11/53 [00:29<01:55,  2.76s/it]Loading checkpoint shards:  21%|        | 11/53 [00:29<01:55,  2.75s/it]Loading checkpoint shards:  21%|        | 11/53 [00:29<01:55,  2.74s/it]Loading checkpoint shards:  21%|        | 11/53 [00:29<01:55,  2.74s/it]Loading checkpoint shards:  21%|        | 11/53 [00:29<01:55,  2.74s/it]Loading checkpoint shards:  21%|        | 11/53 [00:29<01:55,  2.75s/it]Loading checkpoint shards:  23%|       | 12/53 [00:31<01:50,  2.70s/it]Loading checkpoint shards:  23%|       | 12/53 [00:31<01:50,  2.69s/it]Loading checkpoint shards:  23%|       | 12/53 [00:31<01:51,  2.72s/it]Loading checkpoint shards:  23%|       | 12/53 [00:31<01:51,  2.72s/it]Loading checkpoint shards:  23%|       | 12/53 [00:32<01:51,  2.72s/it]Loading checkpoint shards:  23%|       | 12/53 [00:32<01:52,  2.74s/it]Loading checkpoint shards:  23%|       | 12/53 [00:32<01:51,  2.72s/it]Loading checkpoint shards:  23%|       | 12/53 [00:32<01:51,  2.72s/it]Loading checkpoint shards:  25%|       | 13/53 [00:34<01:46,  2.66s/it]Loading checkpoint shards:  25%|       | 13/53 [00:34<01:47,  2.68s/it]Loading checkpoint shards:  25%|       | 13/53 [00:34<01:47,  2.69s/it]Loading checkpoint shards:  25%|       | 13/53 [00:34<01:48,  2.72s/it]Loading checkpoint shards:  25%|       | 13/53 [00:35<01:48,  2.72s/it]Loading checkpoint shards:  25%|       | 13/53 [00:34<01:48,  2.72s/it]Loading checkpoint shards:  25%|       | 13/53 [00:34<01:48,  2.71s/it]Loading checkpoint shards:  25%|       | 13/53 [00:34<01:48,  2.72s/it]Loading checkpoint shards:  26%|       | 14/53 [00:37<01:49,  2.81s/it]Loading checkpoint shards:  26%|       | 14/53 [00:37<01:49,  2.82s/it]Loading checkpoint shards:  26%|       | 14/53 [00:37<01:50,  2.83s/it]Loading checkpoint shards:  26%|       | 14/53 [00:38<01:50,  2.82s/it]Loading checkpoint shards:  26%|       | 14/53 [00:38<01:50,  2.83s/it]Loading checkpoint shards:  26%|       | 14/53 [00:37<01:50,  2.84s/it]Loading checkpoint shards:  26%|       | 14/53 [00:38<01:50,  2.84s/it]Loading checkpoint shards:  26%|       | 14/53 [00:38<01:51,  2.85s/it]Loading checkpoint shards:  28%|       | 15/53 [00:39<01:40,  2.64s/it]Loading checkpoint shards:  28%|       | 15/53 [00:40<01:39,  2.63s/it]Loading checkpoint shards:  28%|       | 15/53 [00:39<01:40,  2.64s/it]Loading checkpoint shards:  28%|       | 15/53 [00:39<01:40,  2.65s/it]Loading checkpoint shards:  28%|       | 15/53 [00:40<01:40,  2.65s/it]Loading checkpoint shards:  28%|       | 15/53 [00:39<01:40,  2.65s/it]Loading checkpoint shards:  28%|       | 15/53 [00:40<01:40,  2.65s/it]Loading checkpoint shards:  28%|       | 15/53 [00:40<01:40,  2.66s/it]Loading checkpoint shards:  30%|       | 16/53 [00:41<01:30,  2.45s/it]Loading checkpoint shards:  30%|       | 16/53 [00:41<01:30,  2.44s/it]Loading checkpoint shards:  30%|       | 16/53 [00:42<01:29,  2.43s/it]Loading checkpoint shards:  30%|       | 16/53 [00:41<01:30,  2.45s/it]Loading checkpoint shards:  30%|       | 16/53 [00:42<01:30,  2.44s/it]Loading checkpoint shards:  30%|       | 16/53 [00:42<01:30,  2.45s/it]Loading checkpoint shards:  30%|       | 16/53 [00:41<01:30,  2.45s/it]Loading checkpoint shards:  30%|       | 16/53 [00:42<01:30,  2.45s/it]Loading checkpoint shards:  32%|      | 17/53 [00:44<01:32,  2.58s/it]Loading checkpoint shards:  32%|      | 17/53 [00:44<01:34,  2.61s/it]Loading checkpoint shards:  32%|      | 17/53 [00:44<01:32,  2.58s/it]Loading checkpoint shards:  32%|      | 17/53 [00:45<01:33,  2.59s/it]Loading checkpoint shards:  32%|      | 17/53 [00:45<01:33,  2.59s/it]Loading checkpoint shards:  32%|      | 17/53 [00:45<01:33,  2.59s/it]Loading checkpoint shards:  32%|      | 17/53 [00:44<01:33,  2.60s/it]Loading checkpoint shards:  32%|      | 17/53 [00:45<01:33,  2.59s/it]Loading checkpoint shards:  34%|      | 18/53 [00:47<01:33,  2.67s/it]Loading checkpoint shards:  34%|      | 18/53 [00:47<01:34,  2.70s/it]Loading checkpoint shards:  34%|      | 18/53 [00:47<01:34,  2.69s/it]Loading checkpoint shards:  34%|      | 18/53 [00:48<01:34,  2.69s/it]Loading checkpoint shards:  34%|      | 18/53 [00:48<01:34,  2.69s/it]Loading checkpoint shards:  34%|      | 18/53 [00:48<01:34,  2.69s/it]Loading checkpoint shards:  34%|      | 18/53 [00:47<01:34,  2.70s/it]Loading checkpoint shards:  34%|      | 18/53 [00:48<01:34,  2.69s/it]Loading checkpoint shards:  36%|      | 19/53 [00:50<01:30,  2.67s/it]Loading checkpoint shards:  36%|      | 19/53 [00:50<01:30,  2.67s/it]Loading checkpoint shards:  36%|      | 19/53 [00:50<01:30,  2.66s/it]Loading checkpoint shards:  36%|      | 19/53 [00:50<01:30,  2.66s/it]Loading checkpoint shards:  36%|      | 19/53 [00:50<01:31,  2.68s/it]Loading checkpoint shards:  36%|      | 19/53 [00:50<01:31,  2.68s/it]Loading checkpoint shards:  36%|      | 19/53 [00:50<01:31,  2.69s/it]Loading checkpoint shards:  36%|      | 19/53 [00:50<01:31,  2.68s/it]Loading checkpoint shards:  38%|      | 20/53 [00:53<01:29,  2.73s/it]Loading checkpoint shards:  38%|      | 20/53 [00:53<01:30,  2.75s/it]Loading checkpoint shards:  38%|      | 20/53 [00:53<01:29,  2.71s/it]Loading checkpoint shards:  38%|      | 20/53 [00:53<01:29,  2.71s/it]Loading checkpoint shards:  38%|      | 20/53 [00:53<01:30,  2.74s/it]Loading checkpoint shards:  38%|      | 20/53 [00:53<01:30,  2.74s/it]Loading checkpoint shards:  38%|      | 20/53 [00:53<01:29,  2.72s/it]Loading checkpoint shards:  38%|      | 20/53 [00:53<01:30,  2.74s/it]Loading checkpoint shards:  40%|      | 21/53 [00:55<01:22,  2.57s/it]Loading checkpoint shards:  40%|      | 21/53 [00:55<01:21,  2.56s/it]Loading checkpoint shards:  40%|      | 21/53 [00:55<01:22,  2.57s/it]Loading checkpoint shards:  40%|      | 21/53 [00:55<01:23,  2.59s/it]Loading checkpoint shards:  40%|      | 21/53 [00:55<01:23,  2.61s/it]Loading checkpoint shards:  40%|      | 21/53 [00:55<01:22,  2.59s/it]Loading checkpoint shards:  40%|      | 21/53 [00:55<01:22,  2.59s/it]Loading checkpoint shards:  40%|      | 21/53 [00:55<01:22,  2.58s/it]Loading checkpoint shards:  42%|     | 22/53 [00:57<01:16,  2.48s/it]Loading checkpoint shards:  42%|     | 22/53 [00:58<01:16,  2.48s/it]Loading checkpoint shards:  42%|     | 22/53 [00:57<01:17,  2.49s/it]Loading checkpoint shards:  42%|     | 22/53 [00:58<01:17,  2.48s/it]Loading checkpoint shards:  42%|     | 22/53 [00:57<01:17,  2.50s/it]Loading checkpoint shards:  42%|     | 22/53 [00:58<01:17,  2.49s/it]Loading checkpoint shards:  42%|     | 22/53 [00:58<01:17,  2.51s/it]Loading checkpoint shards:  42%|     | 22/53 [00:57<01:18,  2.53s/it]Loading checkpoint shards:  43%|     | 23/53 [01:01<01:25,  2.84s/it]Loading checkpoint shards:  43%|     | 23/53 [01:01<01:25,  2.83s/it]Loading checkpoint shards:  43%|     | 23/53 [01:01<01:25,  2.84s/it]Loading checkpoint shards:  43%|     | 23/53 [01:01<01:25,  2.85s/it]Loading checkpoint shards:  43%|     | 23/53 [01:01<01:25,  2.85s/it]Loading checkpoint shards:  43%|     | 23/53 [01:01<01:25,  2.84s/it]Loading checkpoint shards:  43%|     | 23/53 [01:01<01:25,  2.86s/it]Loading checkpoint shards:  43%|     | 23/53 [01:01<01:25,  2.86s/it]Loading checkpoint shards:  45%|     | 24/53 [01:03<01:18,  2.72s/it]Loading checkpoint shards:  45%|     | 24/53 [01:04<01:18,  2.71s/it]Loading checkpoint shards:  45%|     | 24/53 [01:04<01:19,  2.74s/it]Loading checkpoint shards:  45%|     | 24/53 [01:03<01:19,  2.75s/it]Loading checkpoint shards:  45%|     | 24/53 [01:04<01:19,  2.74s/it]Loading checkpoint shards:  45%|     | 24/53 [01:03<01:19,  2.75s/it]Loading checkpoint shards:  45%|     | 24/53 [01:03<01:19,  2.75s/it]Loading checkpoint shards:  45%|     | 24/53 [01:04<01:19,  2.74s/it]Loading checkpoint shards:  47%|     | 25/53 [01:06<01:16,  2.73s/it]Loading checkpoint shards:  47%|     | 25/53 [01:06<01:16,  2.72s/it]Loading checkpoint shards:  47%|     | 25/53 [01:07<01:16,  2.73s/it]Loading checkpoint shards:  47%|     | 25/53 [01:07<01:16,  2.74s/it]Loading checkpoint shards:  47%|     | 25/53 [01:06<01:17,  2.76s/it]Loading checkpoint shards:  47%|     | 25/53 [01:07<01:16,  2.74s/it]Loading checkpoint shards:  47%|     | 25/53 [01:06<01:17,  2.75s/it]Loading checkpoint shards:  47%|     | 25/53 [01:06<01:17,  2.75s/it]Loading checkpoint shards:  49%|     | 26/53 [01:09<01:16,  2.84s/it]Loading checkpoint shards:  49%|     | 26/53 [01:10<01:16,  2.84s/it]Loading checkpoint shards:  49%|     | 26/53 [01:09<01:16,  2.84s/it]Loading checkpoint shards:  49%|     | 26/53 [01:09<01:16,  2.84s/it]Loading checkpoint shards:  49%|     | 26/53 [01:10<01:16,  2.85s/it]Loading checkpoint shards:  49%|     | 26/53 [01:10<01:16,  2.85s/it]Loading checkpoint shards:  49%|     | 26/53 [01:09<01:17,  2.86s/it]Loading checkpoint shards:  49%|     | 26/53 [01:10<01:17,  2.86s/it]Loading checkpoint shards:  51%|     | 27/53 [01:11<01:07,  2.60s/it]Loading checkpoint shards:  51%|     | 27/53 [01:12<01:08,  2.63s/it]Loading checkpoint shards:  51%|     | 27/53 [01:12<01:09,  2.66s/it]Loading checkpoint shards:  51%|     | 27/53 [01:11<01:09,  2.67s/it]Loading checkpoint shards:  51%|     | 27/53 [01:11<01:09,  2.67s/it]Loading checkpoint shards:  51%|     | 27/53 [01:12<01:09,  2.66s/it]Loading checkpoint shards:  51%|     | 27/53 [01:12<01:09,  2.67s/it]Loading checkpoint shards:  51%|     | 27/53 [01:11<01:09,  2.67s/it]Loading checkpoint shards:  53%|    | 28/53 [01:13<01:01,  2.45s/it]Loading checkpoint shards:  53%|    | 28/53 [01:14<01:01,  2.47s/it]Loading checkpoint shards:  53%|    | 28/53 [01:14<01:02,  2.50s/it]Loading checkpoint shards:  53%|    | 28/53 [01:14<01:02,  2.50s/it]Loading checkpoint shards:  53%|    | 28/53 [01:14<01:02,  2.50s/it]Loading checkpoint shards:  53%|    | 28/53 [01:14<01:02,  2.50s/it]Loading checkpoint shards:  53%|    | 28/53 [01:14<01:02,  2.51s/it]Loading checkpoint shards:  53%|    | 28/53 [01:14<01:02,  2.50s/it]Loading checkpoint shards:  55%|    | 29/53 [01:17<01:04,  2.67s/it]Loading checkpoint shards:  55%|    | 29/53 [01:17<01:04,  2.67s/it]Loading checkpoint shards:  55%|    | 29/53 [01:17<01:04,  2.70s/it]Loading checkpoint shards:  55%|    | 29/53 [01:17<01:04,  2.68s/it]Loading checkpoint shards:  55%|    | 29/53 [01:17<01:04,  2.69s/it]Loading checkpoint shards:  55%|    | 29/53 [01:17<01:04,  2.69s/it]Loading checkpoint shards:  55%|    | 29/53 [01:17<01:04,  2.70s/it]Loading checkpoint shards:  55%|    | 29/53 [01:17<01:05,  2.74s/it]Loading checkpoint shards:  57%|    | 30/53 [01:19<01:02,  2.70s/it]Loading checkpoint shards:  57%|    | 30/53 [01:20<01:02,  2.71s/it]Loading checkpoint shards:  57%|    | 30/53 [01:19<01:02,  2.70s/it]Loading checkpoint shards:  57%|    | 30/53 [01:19<01:02,  2.71s/it]Loading checkpoint shards:  57%|    | 30/53 [01:20<01:02,  2.72s/it]Loading checkpoint shards:  57%|    | 30/53 [01:20<01:02,  2.73s/it]Loading checkpoint shards:  57%|    | 30/53 [01:20<01:02,  2.72s/it]Loading checkpoint shards:  57%|    | 30/53 [01:20<01:03,  2.76s/it]Loading checkpoint shards:  58%|    | 31/53 [01:22<01:00,  2.77s/it]Loading checkpoint shards:  58%|    | 31/53 [01:23<01:00,  2.76s/it]Loading checkpoint shards:  58%|    | 31/53 [01:23<01:01,  2.78s/it]Loading checkpoint shards:  58%|    | 31/53 [01:22<01:01,  2.77s/it]Loading checkpoint shards:  58%|    | 31/53 [01:22<01:01,  2.79s/it]Loading checkpoint shards:  58%|    | 31/53 [01:23<01:01,  2.78s/it]Loading checkpoint shards:  58%|    | 31/53 [01:23<01:01,  2.78s/it]Loading checkpoint shards:  58%|    | 31/53 [01:22<01:01,  2.78s/it]Loading checkpoint shards:  60%|    | 32/53 [01:25<00:56,  2.69s/it]Loading checkpoint shards:  60%|    | 32/53 [01:25<00:56,  2.70s/it]Loading checkpoint shards:  60%|    | 32/53 [01:25<00:56,  2.69s/it]Loading checkpoint shards:  60%|    | 32/53 [01:25<00:56,  2.71s/it]Loading checkpoint shards:  60%|    | 32/53 [01:25<00:56,  2.71s/it]Loading checkpoint shards:  60%|    | 32/53 [01:25<00:57,  2.72s/it]Loading checkpoint shards:  60%|    | 32/53 [01:25<00:57,  2.72s/it]Loading checkpoint shards:  60%|    | 32/53 [01:25<00:57,  2.73s/it]Loading checkpoint shards:  62%|   | 33/53 [01:27<00:51,  2.56s/it]Loading checkpoint shards:  62%|   | 33/53 [01:27<00:51,  2.57s/it]Loading checkpoint shards:  62%|   | 33/53 [01:28<00:51,  2.56s/it]Loading checkpoint shards:  62%|   | 33/53 [01:27<00:51,  2.58s/it]Loading checkpoint shards:  62%|   | 33/53 [01:28<00:51,  2.58s/it]Loading checkpoint shards:  62%|   | 33/53 [01:28<00:51,  2.58s/it]Loading checkpoint shards:  62%|   | 33/53 [01:28<00:51,  2.58s/it]Loading checkpoint shards:  62%|   | 33/53 [01:27<00:52,  2.60s/it]Loading checkpoint shards:  64%|   | 34/53 [01:31<00:53,  2.82s/it]Loading checkpoint shards:  64%|   | 34/53 [01:31<00:53,  2.82s/it]Loading checkpoint shards:  64%|   | 34/53 [01:31<00:54,  2.85s/it]Loading checkpoint shards:  64%|   | 34/53 [01:31<00:54,  2.85s/it]Loading checkpoint shards:  64%|   | 34/53 [01:31<00:54,  2.84s/it]Loading checkpoint shards:  64%|   | 34/53 [01:31<00:54,  2.85s/it]Loading checkpoint shards:  64%|   | 34/53 [01:31<00:54,  2.85s/it]Loading checkpoint shards:  64%|   | 34/53 [01:31<00:54,  2.84s/it]Loading checkpoint shards:  66%|   | 35/53 [01:33<00:50,  2.81s/it]Loading checkpoint shards:  66%|   | 35/53 [01:33<00:50,  2.82s/it]Loading checkpoint shards:  66%|   | 35/53 [01:33<00:50,  2.83s/it]Loading checkpoint shards:  66%|   | 35/53 [01:34<00:50,  2.83s/it]Loading checkpoint shards:  66%|   | 35/53 [01:34<00:50,  2.83s/it]Loading checkpoint shards:  66%|   | 35/53 [01:34<00:51,  2.85s/it]Loading checkpoint shards:  66%|   | 35/53 [01:34<00:51,  2.86s/it]Loading checkpoint shards:  66%|   | 35/53 [01:34<00:51,  2.87s/it]Loading checkpoint shards:  68%|   | 36/53 [01:36<00:46,  2.73s/it]Loading checkpoint shards:  68%|   | 36/53 [01:36<00:46,  2.71s/it]Loading checkpoint shards:  68%|   | 36/53 [01:36<00:46,  2.74s/it]Loading checkpoint shards:  68%|   | 36/53 [01:36<00:46,  2.73s/it]Loading checkpoint shards:  68%|   | 36/53 [01:36<00:46,  2.74s/it]Loading checkpoint shards:  68%|   | 36/53 [01:36<00:46,  2.73s/it]Loading checkpoint shards:  68%|   | 36/53 [01:36<00:46,  2.73s/it]Loading checkpoint shards:  68%|   | 36/53 [01:36<00:46,  2.72s/it]Loading checkpoint shards:  70%|   | 37/53 [01:39<00:43,  2.69s/it]Loading checkpoint shards:  70%|   | 37/53 [01:39<00:43,  2.70s/it]Loading checkpoint shards:  70%|   | 37/53 [01:39<00:42,  2.68s/it]Loading checkpoint shards:  70%|   | 37/53 [01:39<00:43,  2.70s/it]Loading checkpoint shards:  70%|   | 37/53 [01:39<00:43,  2.71s/it]Loading checkpoint shards:  70%|   | 37/53 [01:39<00:43,  2.70s/it]Loading checkpoint shards:  70%|   | 37/53 [01:39<00:43,  2.69s/it]Loading checkpoint shards:  70%|   | 37/53 [01:39<00:43,  2.71s/it]Loading checkpoint shards:  72%|  | 38/53 [01:41<00:37,  2.50s/it]Loading checkpoint shards:  72%|  | 38/53 [01:41<00:37,  2.53s/it]Loading checkpoint shards:  72%|  | 38/53 [01:41<00:38,  2.56s/it]Loading checkpoint shards:  72%|  | 38/53 [01:41<00:38,  2.54s/it]Loading checkpoint shards:  72%|  | 38/53 [01:41<00:38,  2.55s/it]Loading checkpoint shards:  72%|  | 38/53 [01:41<00:38,  2.55s/it]Loading checkpoint shards:  72%|  | 38/53 [01:41<00:38,  2.57s/it]Loading checkpoint shards:  72%|  | 38/53 [01:41<00:38,  2.57s/it]Loading checkpoint shards:  74%|  | 39/53 [01:43<00:33,  2.42s/it]Loading checkpoint shards:  74%|  | 39/53 [01:43<00:33,  2.42s/it]Loading checkpoint shards:  74%|  | 39/53 [01:43<00:33,  2.42s/it]Loading checkpoint shards:  74%|  | 39/53 [01:43<00:33,  2.43s/it]Loading checkpoint shards:  74%|  | 39/53 [01:43<00:34,  2.44s/it]Loading checkpoint shards:  74%|  | 39/53 [01:43<00:34,  2.43s/it]Loading checkpoint shards:  74%|  | 39/53 [01:43<00:34,  2.44s/it]Loading checkpoint shards:  74%|  | 39/53 [01:43<00:34,  2.45s/it]Loading checkpoint shards:  75%|  | 40/53 [01:47<00:35,  2.74s/it]Loading checkpoint shards:  75%|  | 40/53 [01:47<00:35,  2.72s/it]Loading checkpoint shards:  75%|  | 40/53 [01:47<00:35,  2.73s/it]Loading checkpoint shards:  75%|  | 40/53 [01:46<00:35,  2.74s/it]Loading checkpoint shards:  75%|  | 40/53 [01:46<00:35,  2.76s/it]Loading checkpoint shards:  75%|  | 40/53 [01:47<00:35,  2.74s/it]Loading checkpoint shards:  75%|  | 40/53 [01:46<00:35,  2.75s/it]Loading checkpoint shards:  75%|  | 40/53 [01:47<00:35,  2.76s/it]Loading checkpoint shards:  77%|  | 41/53 [01:50<00:32,  2.72s/it]Loading checkpoint shards:  77%|  | 41/53 [01:50<00:32,  2.74s/it]Loading checkpoint shards:  77%|  | 41/53 [01:49<00:32,  2.74s/it]Loading checkpoint shards:  77%|  | 41/53 [01:50<00:33,  2.75s/it]Loading checkpoint shards:  77%|  | 41/53 [01:50<00:33,  2.76s/it]Loading checkpoint shards:  77%|  | 41/53 [01:49<00:33,  2.76s/it]Loading checkpoint shards:  77%|  | 41/53 [01:49<00:32,  2.75s/it]Loading checkpoint shards:  77%|  | 41/53 [01:49<00:33,  2.77s/it]Loading checkpoint shards:  79%|  | 42/53 [01:52<00:31,  2.89s/it]Loading checkpoint shards:  79%|  | 42/53 [01:53<00:32,  2.91s/it]Loading checkpoint shards:  79%|  | 42/53 [01:52<00:31,  2.90s/it]Loading checkpoint shards:  79%|  | 42/53 [01:53<00:32,  2.92s/it]Loading checkpoint shards:  79%|  | 42/53 [01:53<00:32,  2.91s/it]Loading checkpoint shards:  79%|  | 42/53 [01:53<00:32,  2.93s/it]Loading checkpoint shards:  79%|  | 42/53 [01:53<00:32,  2.92s/it]Loading checkpoint shards:  79%|  | 42/53 [01:53<00:32,  2.93s/it]Loading checkpoint shards:  81%|  | 43/53 [01:55<00:27,  2.72s/it]Loading checkpoint shards:  81%|  | 43/53 [01:55<00:27,  2.72s/it]Loading checkpoint shards:  81%|  | 43/53 [01:55<00:27,  2.72s/it]Loading checkpoint shards:  81%|  | 43/53 [01:55<00:27,  2.73s/it]Loading checkpoint shards:  81%|  | 43/53 [01:55<00:27,  2.73s/it]Loading checkpoint shards:  81%|  | 43/53 [01:55<00:27,  2.74s/it]Loading checkpoint shards:  81%|  | 43/53 [01:55<00:27,  2.75s/it]Loading checkpoint shards:  81%|  | 43/53 [01:55<00:27,  2.76s/it]Loading checkpoint shards:  83%| | 44/53 [01:57<00:23,  2.60s/it]Loading checkpoint shards:  83%| | 44/53 [01:58<00:23,  2.59s/it]Loading checkpoint shards:  83%| | 44/53 [01:57<00:23,  2.59s/it]Loading checkpoint shards:  83%| | 44/53 [01:57<00:23,  2.61s/it]Loading checkpoint shards:  83%| | 44/53 [01:58<00:23,  2.62s/it]Loading checkpoint shards:  83%| | 44/53 [01:57<00:23,  2.62s/it]Loading checkpoint shards:  83%| | 44/53 [01:57<00:23,  2.63s/it]Loading checkpoint shards:  83%| | 44/53 [01:57<00:23,  2.63s/it]Loading checkpoint shards:  85%| | 45/53 [02:01<00:23,  2.91s/it]Loading checkpoint shards:  85%| | 45/53 [02:01<00:23,  2.91s/it]Loading checkpoint shards:  85%| | 45/53 [02:01<00:23,  2.90s/it]Loading checkpoint shards:  85%| | 45/53 [02:01<00:23,  2.93s/it]Loading checkpoint shards:  85%| | 45/53 [02:01<00:23,  2.92s/it]Loading checkpoint shards:  85%| | 45/53 [02:01<00:23,  2.93s/it]Loading checkpoint shards:  85%| | 45/53 [02:01<00:23,  2.93s/it]Loading checkpoint shards:  85%| | 45/53 [02:01<00:23,  2.94s/it]Loading checkpoint shards:  87%| | 46/53 [02:04<00:20,  2.97s/it]Loading checkpoint shards:  87%| | 46/53 [02:04<00:21,  3.04s/it]Loading checkpoint shards:  87%| | 46/53 [02:04<00:21,  3.02s/it]Loading checkpoint shards:  87%| | 46/53 [02:04<00:21,  3.03s/it]Loading checkpoint shards:  87%| | 46/53 [02:04<00:21,  3.03s/it]Loading checkpoint shards:  87%| | 46/53 [02:04<00:21,  3.02s/it]Loading checkpoint shards:  87%| | 46/53 [02:04<00:21,  3.02s/it]Loading checkpoint shards:  87%| | 46/53 [02:04<00:21,  3.04s/it]Loading checkpoint shards:  89%| | 47/53 [02:07<00:17,  2.94s/it]Loading checkpoint shards:  89%| | 47/53 [02:07<00:17,  2.96s/it]Loading checkpoint shards:  89%| | 47/53 [02:07<00:17,  2.95s/it]Loading checkpoint shards:  89%| | 47/53 [02:07<00:17,  2.95s/it]Loading checkpoint shards:  89%| | 47/53 [02:07<00:17,  2.95s/it]Loading checkpoint shards:  89%| | 47/53 [02:07<00:17,  2.95s/it]Loading checkpoint shards:  89%| | 47/53 [02:07<00:17,  2.96s/it]Loading checkpoint shards:  89%| | 47/53 [02:07<00:17,  2.99s/it]Loading checkpoint shards:  91%| | 48/53 [02:10<00:14,  2.88s/it]Loading checkpoint shards:  91%| | 48/53 [02:10<00:14,  2.87s/it]Loading checkpoint shards:  91%| | 48/53 [02:10<00:14,  2.89s/it]Loading checkpoint shards:  91%| | 48/53 [02:10<00:14,  2.90s/it]Loading checkpoint shards:  91%| | 48/53 [02:10<00:14,  2.88s/it]Loading checkpoint shards:  91%| | 48/53 [02:10<00:14,  2.90s/it]Loading checkpoint shards:  91%| | 48/53 [02:10<00:14,  2.89s/it]Loading checkpoint shards:  91%| | 48/53 [02:10<00:14,  2.90s/it]Loading checkpoint shards:  92%|| 49/53 [02:12<00:10,  2.63s/it]Loading checkpoint shards:  92%|| 49/53 [02:12<00:10,  2.67s/it]Loading checkpoint shards:  92%|| 49/53 [02:12<00:10,  2.66s/it]Loading checkpoint shards:  92%|| 49/53 [02:12<00:10,  2.66s/it]Loading checkpoint shards:  92%|| 49/53 [02:12<00:10,  2.68s/it]Loading checkpoint shards:  92%|| 49/53 [02:12<00:10,  2.68s/it]Loading checkpoint shards:  92%|| 49/53 [02:12<00:10,  2.70s/it]Loading checkpoint shards:  92%|| 49/53 [02:12<00:10,  2.68s/it]Loading checkpoint shards:  94%|| 50/53 [02:14<00:07,  2.58s/it]Loading checkpoint shards:  94%|| 50/53 [02:14<00:07,  2.62s/it]Loading checkpoint shards:  94%|| 50/53 [02:15<00:07,  2.63s/it]Loading checkpoint shards:  94%|| 50/53 [02:15<00:07,  2.64s/it]Loading checkpoint shards:  94%|| 50/53 [02:15<00:07,  2.63s/it]Loading checkpoint shards:  94%|| 50/53 [02:14<00:07,  2.63s/it]Loading checkpoint shards:  94%|| 50/53 [02:15<00:07,  2.64s/it]Loading checkpoint shards:  94%|| 50/53 [02:14<00:07,  2.62s/it]Loading checkpoint shards:  96%|| 51/53 [02:17<00:05,  2.63s/it]Loading checkpoint shards:  96%|| 51/53 [02:17<00:05,  2.67s/it]Loading checkpoint shards:  96%|| 51/53 [02:17<00:05,  2.66s/it]Loading checkpoint shards:  96%|| 51/53 [02:17<00:05,  2.66s/it]Loading checkpoint shards:  96%|| 51/53 [02:17<00:05,  2.66s/it]Loading checkpoint shards:  96%|| 51/53 [02:17<00:05,  2.65s/it]Loading checkpoint shards:  96%|| 51/53 [02:17<00:05,  2.66s/it]Loading checkpoint shards:  96%|| 51/53 [02:17<00:05,  2.67s/it]Loading checkpoint shards:  98%|| 52/53 [02:20<00:02,  2.79s/it]Loading checkpoint shards:  98%|| 52/53 [02:21<00:02,  2.79s/it]Loading checkpoint shards:  98%|| 52/53 [02:20<00:02,  2.80s/it]Loading checkpoint shards:  98%|| 52/53 [02:21<00:02,  2.82s/it]Loading checkpoint shards:  98%|| 52/53 [02:20<00:02,  2.80s/it]Loading checkpoint shards:  98%|| 52/53 [02:20<00:02,  2.81s/it]Loading checkpoint shards:  98%|| 52/53 [02:21<00:02,  2.81s/it]Loading checkpoint shards:  98%|| 52/53 [02:20<00:02,  2.81s/it]Loading checkpoint shards: 100%|| 53/53 [02:26<00:00,  3.69s/it]Loading checkpoint shards: 100%|| 53/53 [02:26<00:00,  2.76s/it]
Loading checkpoint shards: 100%|| 53/53 [02:27<00:00,  3.82s/it]Loading checkpoint shards: 100%|| 53/53 [02:27<00:00,  2.78s/it]
Loading checkpoint shards: 100%|| 53/53 [02:27<00:00,  3.85s/it]Loading checkpoint shards: 100%|| 53/53 [02:27<00:00,  2.78s/it]
Loading checkpoint shards: 100%|| 53/53 [02:26<00:00,  3.85s/it]Loading checkpoint shards: 100%|| 53/53 [02:26<00:00,  2.77s/it]
Loading checkpoint shards: 100%|| 53/53 [02:27<00:00,  3.86s/it]Loading checkpoint shards: 100%|| 53/53 [02:27<00:00,  2.78s/it]
Loading checkpoint shards: 100%|| 53/53 [02:27<00:00,  3.85s/it]Loading checkpoint shards: 100%|| 53/53 [02:27<00:00,  2.78s/it]
[INFO|modeling_utils.py:3775] 2023-10-23 07:21:20,044 >> All model checkpoint weights were used when initializing SkyworkForCausalLM.

[INFO|modeling_utils.py:3783] 2023-10-23 07:21:20,044 >> All the weights of SkyworkForCausalLM were initialized from the model checkpoint at /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base.
If your task is similar to the task the model of the checkpoint was trained on, you can already use SkyworkForCausalLM for predictions without further training.
[INFO|configuration_utils.py:728] 2023-10-23 07:21:20,048 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/generation_config.json
[INFO|configuration_utils.py:770] 2023-10-23 07:21:20,049 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "do_sample": true,
  "eos_token_id": 2,
  "max_length": 4096,
  "pad_token_id": 0,
  "temperature": 0.6,
  "top_p": 0.9
}

Loading checkpoint shards: 100%|| 53/53 [02:26<00:00,  3.85s/it]Loading checkpoint shards: 100%|| 53/53 [02:26<00:00,  2.77s/it]
Loading checkpoint shards: 100%|| 53/53 [02:26<00:00,  3.85s/it]Loading checkpoint shards: 100%|| 53/53 [02:26<00:00,  2.77s/it]
10/23/2023 07:21:20 - INFO - __main__ - Model vocab size: 65519
10/23/2023 07:21:20 - INFO - __main__ - len(tokenizer):65519
[INFO|trainer.py:400] 2023-10-23 07:21:20,439 >> You have loaded a model on multiple GPUs. `is_model_parallel` attribute will be force-set to `True` to avoid any unexpected behavior such as device placement mismatching.
[INFO|trainer.py:576] 2023-10-23 07:21:20,440 >> max_steps is given, it will override any value given in num_train_epochs
10/23/2023 07:21:20 - INFO - accelerate.accelerator - Updating DeepSpeed's gradient accumulation steps to 4 from 1.
[2023-10-23 07:21:20,558] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 426, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1591, in train
    return inner_training_loop(
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1726, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1198, in prepare
    result = self._prepare_deepspeed(*args)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1537, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/__init__.py", line 171, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 268, in __init__
    self._configure_distributed_model(model)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 1069, in _configure_distributed_model
    self.module.to(self.device)
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2179, in to
    return super().to(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1160, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 833, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1158, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 108.00 MiB. GPU 4 has a total capacty of 79.35 GiB of which 2.19 MiB is free. Process 19632 has 8.31 GiB memory in use. Process 19630 has 8.31 GiB memory in use. Process 19635 has 8.31 GiB memory in use. Process 19636 has 8.31 GiB memory in use. Process 19633 has 8.31 GiB memory in use. Process 19631 has 8.31 GiB memory in use. Process 19637 has 8.31 GiB memory in use. Process 19634 has 21.16 GiB memory in use. Of the allocated memory 20.50 GiB is allocated by PyTorch, and 181.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 426, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1591, in train
    return inner_training_loop(
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1726, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1198, in prepare
    result = self._prepare_deepspeed(*args)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1537, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/__init__.py", line 171, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 268, in __init__
    self._configure_distributed_model(model)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 1069, in _configure_distributed_model
    self.module.to(self.device)
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2179, in to
    return super().to(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1160, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 833, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1158, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 108.00 MiB. GPU 2 has a total capacty of 79.35 GiB of which 2.19 MiB is free. Process 19632 has 21.16 GiB memory in use. Process 19630 has 8.31 GiB memory in use. Process 19635 has 8.31 GiB memory in use. Process 19636 has 8.31 GiB memory in use. Process 19633 has 8.31 GiB memory in use. Process 19631 has 8.31 GiB memory in use. Process 19637 has 8.31 GiB memory in use. Process 19634 has 8.31 GiB memory in use. Of the allocated memory 20.50 GiB is allocated by PyTorch, and 181.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 426, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1591, in train
    return inner_training_loop(
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1726, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1198, in prepare
    result = self._prepare_deepspeed(*args)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1537, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/__init__.py", line 171, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 268, in __init__
    self._configure_distributed_model(model)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 1069, in _configure_distributed_model
    self.module.to(self.device)
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2179, in to
    return super().to(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1160, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 833, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1158, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 108.00 MiB. GPU 1 has a total capacty of 79.35 GiB of which 2.19 MiB is free. Process 19632 has 8.31 GiB memory in use. Process 19630 has 8.31 GiB memory in use. Process 19635 has 8.31 GiB memory in use. Process 19636 has 8.31 GiB memory in use. Process 19633 has 8.31 GiB memory in use. Process 19631 has 21.16 GiB memory in use. Process 19637 has 8.31 GiB memory in use. Process 19634 has 8.31 GiB memory in use. Of the allocated memory 20.50 GiB is allocated by PyTorch, and 181.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 426, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1591, in train
    return inner_training_loop(
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1726, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1198, in prepare
    result = self._prepare_deepspeed(*args)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1537, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/__init__.py", line 171, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 268, in __init__
    self._configure_distributed_model(model)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 1069, in _configure_distributed_model
    self.module.to(self.device)
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2179, in to
    return super().to(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1160, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 833, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1158, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 108.00 MiB. GPU 3 has a total capacty of 79.35 GiB of which 2.19 MiB is free. Process 19632 has 8.31 GiB memory in use. Process 19630 has 8.31 GiB memory in use. Process 19635 has 8.31 GiB memory in use. Process 19636 has 8.31 GiB memory in use. Process 19633 has 21.16 GiB memory in use. Process 19631 has 8.31 GiB memory in use. Process 19637 has 8.31 GiB memory in use. Process 19634 has 8.31 GiB memory in use. Of the allocated memory 20.50 GiB is allocated by PyTorch, and 181.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 426, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1591, in train
    return inner_training_loop(
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1726, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1198, in prepare
    result = self._prepare_deepspeed(*args)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1537, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/__init__.py", line 171, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 268, in __init__
    self._configure_distributed_model(model)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 1069, in _configure_distributed_model
    self.module.to(self.device)
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2179, in to
    return super().to(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1160, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 833, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1158, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 108.00 MiB. GPU 5 has a total capacty of 79.35 GiB of which 2.19 MiB is free. Process 19632 has 8.31 GiB memory in use. Process 19630 has 8.31 GiB memory in use. Process 19635 has 21.16 GiB memory in use. Process 19636 has 8.31 GiB memory in use. Process 19633 has 8.31 GiB memory in use. Process 19631 has 8.31 GiB memory in use. Process 19637 has 8.31 GiB memory in use. Process 19634 has 8.31 GiB memory in use. Of the allocated memory 20.50 GiB is allocated by PyTorch, and 181.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2023-10-23 07:21:26,668] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 54947 closing signal SIGTERM
[2023-10-23 07:21:26,668] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 54948 closing signal SIGTERM
[2023-10-23 07:21:26,668] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 54949 closing signal SIGTERM
[2023-10-23 07:21:26,668] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 54950 closing signal SIGTERM
[2023-10-23 07:21:26,668] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 54952 closing signal SIGTERM
[2023-10-23 07:21:26,668] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 54953 closing signal SIGTERM
[2023-10-23 07:21:26,668] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 54954 closing signal SIGTERM
[2023-10-23 07:21:31,556] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 4 (pid: 54951) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train/run_pt.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-23_07:21:26
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 54951)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[2023-10-23 07:22:59,154] torch.distributed.run: [WARNING] 
[2023-10-23 07:22:59,154] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:22:59,154] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-10-23 07:22:59,154] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:23:03,555] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:23:03,558] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:23:03,687] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:23:03,695] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:23:03,705] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:23:03,727] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:23:03,730] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:23:03,740] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:23:04,187] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:23:04,187] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:23:04,256] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:23:04,256] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:23:04,375] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:23:04,375] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:23:04,375] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-10-23 07:23:04,379] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:23:04,379] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:23:04,398] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:23:04,398] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:23:04,416] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:23:04,416] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:23:04,451] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:23:04,451] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:23:04,461] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:23:04,461] [INFO] [comm.py:616:init_distributed] cdb=None
10/23/2023 07:23:05 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:23:05 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[INFO|configuration_utils.py:713] 2023-10-23 07:23:05,153 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
[INFO|configuration_utils.py:713] 2023-10-23 07:23:05,155 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
[INFO|configuration_utils.py:775] 2023-10-23 07:23:05,155 >> Model config SkyworkConfig {
  "_name_or_path": "/data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base",
  "architectures": [
    "SkyworkForCausalLM"
  ],
  "attention_bias": false,
  "auto_map": {
    "AutoConfig": "configuration_skywork.SkyworkConfig",
    "AutoModelForCausalLM": "modeling_skywork.SkyworkForCausalLM"
  },
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4608,
  "initializer_range": 0.01,
  "intermediate_size": 12288,
  "max_position_embeddings": 4096,
  "model_type": "skywork",
  "num_attention_heads": 36,
  "num_hidden_layers": 52,
  "num_key_value_heads": 36,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.34.0",
  "use_cache": true,
  "use_flash_attention": false,
  "vocab_size": 65519
}

[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:23:05,156 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:23:05,156 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:23:05,156 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:23:05,156 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:23:05,156 >> loading file tokenizer.json
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
[INFO|tokenization_utils.py:493] 2023-10-23 07:23:05,307 >> Adding <s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:23:05,307 >> Adding </s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:23:05,307 >> Adding <unk> to the vocabulary
10/23/2023 07:23:05 - INFO - __main__ - Start shuffling training dataset.
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
Loading cached shuffled indices for dataset at /data/user/liang.zhao/skywork-13b-opensource/data_cache/pt_train_demo/pt_train/train/cache-82bd44c04d4089ca.arrow
10/23/2023 07:23:05 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /data/user/liang.zhao/skywork-13b-opensource/data_cache/pt_train_demo/pt_train/train/cache-82bd44c04d4089ca.arrow
10/23/2023 07:23:05 - INFO - __main__ - shuffle successively!
10/23/2023 07:23:05 - INFO - __main__ - Num train_samples  321
10/23/2023 07:23:05 - INFO - __main__ - Training example:
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
10/23/2023 07:23:05 - INFO - __main__ - subtract the combined number of speeding tickets from the total number of tickets to find the combined number of parking tickets: 24 - 12 = <<24-12=12>>12
Now express Mark's number of parking tickets in terms of the number of parking tickets Sarah got: m = <<2=2>>2s
We know that m + s = 12, so substitute in the value of m from the previous step to get 2s + s = 12
Combine like terms to get 3s = 12
Divide both sides of the equation to get s = <<4=4>>4
Now multiply the number of parking tickets Sarah got by 2 to find the number Mark got: 4 * 2 = <<4*2=8>>8
#### 8<s> Cooper makes 7 apple pies a day. He does this for 12 days. Ashley then eats 50 of his pies. How many apple pies remain with Cooper? The number of pies Cooper makes in 12 days is 7 pies/day * 12 days = <<7*12=84>>84 apple pies.
After Ashley eats 50 of them, there are 84 pies  50 pies = <<84-50=34>>34 apple pies.
#### 34<s> Lindsey bought 2 exercise bands to intensify her workout.  Each band adds an extra 5 pounds of resistance to her workout.  If she doubles up both sets of bands and places them around her legs and picks up a 10-pound dumbbell, how much weight will she squat? She has 2 exercise bands that are both 5 pounds of resistance so thats 2*5 = <<2*5=10>>10 pounds
She has a pair of 10-pound dumbbells so thats 2*10 = <<10*2=20>>20 pounds
With both the bands and dumbbells, she will squat 10+20 = <<10+20=30>>30 pounds
#### 30<s> Wendy just started working at an Italian restaurant. She polished 50 small glasses and 10 more large glasses than small glasses. How many glasses did she polish? She polished 50 + 10 = <<50+10=60>>60 large glasses.
Therefore, Wendy polished 50 + 60 = <<50+60=110>>110 glasses.
#### 110<s> Miss Darlington has a basket of 20 blueberries. She picked 9 more baskets with the same amount of berries. How many blueberries did Miss Darlington have in all? Miss Darlington picked 9 x 20 = <<9*20=180>>180 blueberries more.
So she had a total of 180 + 20 = <<180+20=200>>200 blueberries.
#### 200<s> In a basketball game, Jon scored 3 points. Jack scored 5 points more than Jon, and Tom scored 4 less than the points of Jon and Jack together. How many points did they score altogether? Jack scored 3 + 5 = <<3+5=8>>8 points.
Together, Jon and Jack scored 8 + 3 = <<8+3=11>>11 points.
So, Tom scored 11 - 4 = <<11-4=7>>7 points.
Thus, Jon, Jack, and Tom scored a total of 3 + 8 + 7 = <<3+8+7=18>>18 points.
#### 18<s> In a shipping container, there are 10 crates. Each crate is filled with 6 boxes and each box is filled with 4 washing machines. A worker removes 1 washing machine from each box. There are no other changes. How many washing machines were removed from the shipping container? Initially, there were 6 boxes * 4 washing machines per box = <<6*4=24>>24 washing machines in each crate.
So there were 24 washing machines per crate * 10 crates = <<24*10=240>>240 washing machines in the shipping container.
A worker removes 1 washing machine from each box so there are now 4 original washing machines - 1 removed washing machine = <<4-1=3>>3 washing machines in each box.
This means there are 6 boxes * 3 washing machines per box = <<6*3=18>>18 washing machines in each crate.
So there are now 18 washing machines per crate * 10 crates = <<18*10=180>>180 washing machines in the shipping container.
The difference is how many machine washing machines were removed which is 240 initial washing machines  180 current washing machines = <<240-180=60>>60 washing machines.
#### 60<s> Darnell has 1000 square feet of fabric that he's using to make mini flags. He makes square flags that are 4 feet by 4 feet, wide rectangular flags that are 5 feet by 3 feet, and tall rectangular flags that are 3 feet by 5 feet. He has already made 16 square flags, 20 wide flags, and 10 tall flags. How many square feet of fabric does he have left? The square flags use 16 square feet of fabric per flag because four times four equals <<4*4=16>>16
The wide flags each use 15 feet of fabric per flag because five times three equals <<5*3=15>>15
The tall flags each use 15 feet of fabric per flag because five times three equals <<5*3=15>>15
He has used 256 square feet for the square flags because 16 times 16 equals <<16*16=256>>256
He has used 300 square feet for the wide flags because 20 times 15 equals <<20*15=300>>300
He has used 150 square feet for the tall flags because ten times 15 equals 150.
He has used 706 square feet because 256 plus 300 plus 150 equals <<256+300+150=706>>706.
He has 294 square feet left because 1,000 minus 706 equals <<1000-706=294>>294
#### 294<s> Matthias has 40 soccer balls and 15 basketballs. 30 soccer balls and 7 basketballs have a hole in them. How many balls in total does Matthias have without holes in them? Matthias has 40-30 = <<40-30=10>>10 soccer balls without holes.
Matthias has 15-7 = <<15-7=8>>8 basketballs without holes.
A total of 10+8 = <<10+8=18>>18 balls do not have holes.
#### 18<s> Jenny is scraping gum off the bottom of the seats in a stadium with two sections. Section A has 1 subsection with 60 seats and 3 subsections with 80 seats each. Section B has 20 more seats than 3 times as many seats as Section A has total. How many seats does Section B have? First find how many total seats are in the 80-seat subsections: 80 seats/subsection * 3 subsections = 240 seats
Then add the number of seats in the 60-seat section to find the total number of seats in Section A: 240 seats + 60 seats = <<240+60=300>>300 seats
Then triple that number: 300 seats * 3 = <<300*3=900>>900 seats
Then add 20 seats to find the total number of seats in Section B: 900 seats + 20 seats = <<900+20=920>>920 seats
#### 920<s> The running time of Beast of War: Armoured Command is 10 minutes longer than that of Alpha Epsilon, which is 30 minutes shorter than that of Millennium. If Millennium runs for 2 hours, what is the running time of Beast of War: Armoured Command in minutes? One hour contains 60 minutes so 2 hours contain 60*2 = <<2*60=120>>120 minutes
Alpha Epsilon's running time is 30 minutes less than that of Millennium (which runs for 120 minutes) hence 120-30 = <<120-30=90>>90 minutes
Beast of War: Armoured Command runs for 10 minutes more than Alpha Epsilon hence 90+10 = <<10+90=100>>100 minutes
#### 100<s> A packet of candy sweets has 30 cherry-flavored sweets, 40 strawberry-flavored sweets, and 50 pineapple-flavored sweets. Aaron eats half of each of the flavored sweets and gives 5 cherry-flavored sweets to his friend. How many sweets are still in the packet of candy? Aaron eats 1/2*30 sweets + 1/2*40 sweets + 1/2*50 sweets = <<1/2*30+1/2*40+1/2*50=60>>60 candy sweets.
The packet of candy sweets still has 60 sweets - 5 sweets = <<60-5=55>>55 candy sweets.
#### 55<s> Oliver has two bags of vegetables. Each bag weighs 1/6 as much as Jamess bag, which weighs 18kg. What is the combined weight of both Olivers bags? Each of Olivers bags weighs 18 kg * 1/6 =<<18*1/6=3>>3 kg.
Combined, both his bags weigh 3 kg * 2 = <<3*2=6>>6 kg.
#### 6<s> Greg's PPO algorithm obtained 90% of the possible reward on the CoinRun environment. CoinRun's maximum reward is half as much as the maximum ProcGen reward of 240. How much reward did Greg's PPO algorithm get? Half of much as ProcGen's maximum reward is 240/2=<<240/2=120>>120 reward
90% of CoinRun's maximum reward is 120*.9=<<120*.9=108>>108 reward
#### 108<s> Julia has a parrot and a rabbit. She buys food for both of the animals for $30 in total a week. Julia has the rabbit for 5 weeks, and the parrot for 3 weeks. How much money did Julia already spend on food for her animals, if the weekly cost of the rabbit food is $12? If the rabbit food costs $12 a week, then the parrot food costs $30 - $12 = $18 a week.
Julia has the parrot for 3 weeks, so she spent 3 weeks * $18/week = $<<3*18=54>>54 on her.
The rabbit is her only for 5 weeks, so she spent 5 weeks * $12/week = $<<5*12=60>>60 on him.
In total, Julia spent $54 + $60 = $<<54+60=114>>114 on food for her animals.
#### 114<s> Janet has 60 less than four times as many siblings as Masud. Carlos has 3/4 times as many siblings as Masud. If Masud has 60 siblings, how many more siblings does Janet have more than Carlos? If Masud has 60 siblings, and Carlos has 3/4 times as many siblings as Masud, Carlos has 3/4*60=<<60*3/4=45>>45 siblings.
Four times as many siblings as Masud has is 4*60=<<4*60=240>>240
Janet has 60 less than four times as many siblings as Masud, a total of 240-60=<<240-60=180>>180 siblings.
The number of siblings Janet have more than Carlos is 180-45=<<180-45=135>>135
#### 135<s> A highway is being extended from its current length of 200 miles up to 650 miles. 50 miles are built on the first day, and three times this amount are built on the second day.  How many miles still need to be added to the highway to finish extending it? The length of the highway that needs to be constructed is 650  200 = <<650-200=450>>450 miles.
After the first day, there are still 450  50 = <<450-50=400>>400 miles that need to be constructed.
On the second day, 50 miles * 3 = <<50*3=150>>150 miles are added to the highway.
This means that 400  150 = <<400-150=250>>250 miles still need to be added to the highway.
#### 250<s> Susan is making jewelry with a repeating pattern that has 3 green beads, 5 purple beads, and twice as many red beads as green beads. If the pattern repeats three times per bracelet and 5 times per necklace, how many beads does she need to make 1 bracelets and 10 necklaces? First find the number of red beads per repeat: 3 green * 2 red/green = <<3*2=6>>6 red
Then add the number of beads of each color to find the total number of bead per repeat: 6 beads + 3 beads + 5 beads = <<6+3+5=14>>14 beads
Then multiply the number of beads per repeat by the number of repeats per bracelet to find the number of beads per bracelet: 14 beads/repeat * 3 repeats/bracelet = <<14*3=42>>42 beads/bracelet
Then multiply the number of beads per repeat by the number of repeats per necklace to find the number of beads per necklace: 14 beads/repeat * 5 repeats/necklace = <<14*5=70>>70 beads/necklace
Then multiply the number of beads per necklace by the number of necklaces to find the total number of beads used in the necklaces: 70 beads/necklace * 10 necklaces = <<70*10=700>>700 beads
Then add the number of beads used in a bracelet to the number of beads in the necklaces to find the total number of beads used: 700 beads + 42 beads = <<700+42=742>>742 beads
#### 742<s> Janet counts 30 crows on the powerlines and 60% more hawks than crows. How many birds does she count total? First find how many more hawks than crows there are: 60% * 30 crows = <<60*.01*30=18>>18 crows
Then add that number to the number of crows to find the total number of hawks: 18 crows + 30 crows = <<18+30=48>>48 crows
Then add the number of crows to the number of hawks to find the total number of birds: 48 crows + 30 crows = <<48+30=78>>78 crows
#### 78<s> Joan has 180 socks. Two thirds of the socks are white, and the rest of the socks are blue. How many blue socks does Joan have? Joan has (180/3)*2 = <<(180/3)*2=120>>120 white socks.
The number of blue socks Joan has is 180-120 = <<180-120=60>>60.
#### 60<s> Simon collected treasures on the beach during his summer vacation. He collected a bucket of pearly seashells, a jar full of smooth sea glass, and a bag of ten sand dollars. If the jar holds three times as many pieces of glass as the bag does sand dollars, and the bucket holds five times as many seashells as the jar holds pieces of glass, how many treasures did Simon find on the beach? The jar holds 
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
[INFO|modeling_utils.py:2990] 2023-10-23 07:23:05,395 >> loading weights file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/pytorch_model.bin.index.json
[INFO|configuration_utils.py:770] 2023-10-23 07:23:05,396 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "pad_token_id": 0
}

10/23/2023 07:23:05 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:23:05 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:23:05 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
10/23/2023 07:23:05 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
10/23/2023 07:23:06 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
10/23/2023 07:23:06 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   2%|         | 1/53 [00:00<00:36,  1.43it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   2%|         | 1/53 [00:00<00:35,  1.47it/s]Loading checkpoint shards:   4%|         | 2/53 [00:01<00:34,  1.46it/s]Loading checkpoint shards:   2%|         | 1/53 [00:00<00:38,  1.37it/s]Loading checkpoint shards:   2%|         | 1/53 [00:00<00:38,  1.34it/s]Loading checkpoint shards:   2%|         | 1/53 [00:00<00:38,  1.34it/s]Loading checkpoint shards:   2%|         | 1/53 [00:00<00:36,  1.44it/s]Loading checkpoint shards:   2%|         | 1/53 [00:00<00:37,  1.38it/s]Loading checkpoint shards:   2%|         | 1/53 [00:00<00:39,  1.31it/s]Loading checkpoint shards:   4%|         | 2/53 [00:01<00:34,  1.48it/s]Loading checkpoint shards:   6%|         | 3/53 [00:02<00:34,  1.45it/s]Loading checkpoint shards:   4%|         | 2/53 [00:01<00:38,  1.34it/s]Loading checkpoint shards:   4%|         | 2/53 [00:01<00:36,  1.38it/s]Loading checkpoint shards:   4%|         | 2/53 [00:01<00:34,  1.47it/s]Loading checkpoint shards:   4%|         | 2/53 [00:01<00:38,  1.34it/s]Loading checkpoint shards:   4%|         | 2/53 [00:01<00:36,  1.41it/s]Loading checkpoint shards:   4%|         | 2/53 [00:01<00:36,  1.41it/s]Loading checkpoint shards:   6%|         | 3/53 [00:02<00:34,  1.47it/s]Loading checkpoint shards:   8%|         | 4/53 [00:02<00:32,  1.50it/s]Loading checkpoint shards:   6%|         | 3/53 [00:02<00:36,  1.36it/s]Loading checkpoint shards:   6%|         | 3/53 [00:02<00:35,  1.42it/s]Loading checkpoint shards:   6%|         | 3/53 [00:02<00:33,  1.48it/s]Loading checkpoint shards:   6%|         | 3/53 [00:02<00:35,  1.43it/s]Loading checkpoint shards:   6%|         | 3/53 [00:02<00:36,  1.37it/s]Loading checkpoint shards:   6%|         | 3/53 [00:02<00:35,  1.40it/s]Loading checkpoint shards:   8%|         | 4/53 [00:02<00:34,  1.43it/s]Loading checkpoint shards:   9%|         | 5/53 [00:03<00:32,  1.46it/s]Loading checkpoint shards:   8%|         | 4/53 [00:02<00:35,  1.39it/s]Loading checkpoint shards:   8%|         | 4/53 [00:02<00:33,  1.48it/s]Loading checkpoint shards:   8%|         | 4/53 [00:02<00:34,  1.41it/s]Loading checkpoint shards:   8%|         | 4/53 [00:02<00:34,  1.41it/s]Loading checkpoint shards:   8%|         | 4/53 [00:02<00:35,  1.39it/s]Loading checkpoint shards:   8%|         | 4/53 [00:02<00:35,  1.36it/s]Loading checkpoint shards:   9%|         | 5/53 [00:03<00:33,  1.44it/s]Loading checkpoint shards:  11%|        | 6/53 [00:04<00:32,  1.43it/s]Loading checkpoint shards:   9%|         | 5/53 [00:03<00:33,  1.42it/s]Loading checkpoint shards:   9%|         | 5/53 [00:03<00:32,  1.47it/s]Loading checkpoint shards:   9%|         | 5/53 [00:03<00:32,  1.47it/s]Loading checkpoint shards:   9%|         | 5/53 [00:03<00:33,  1.45it/s]Loading checkpoint shards:   9%|         | 5/53 [00:03<00:34,  1.41it/s]Loading checkpoint shards:  11%|        | 6/53 [00:04<00:32,  1.46it/s]Loading checkpoint shards:   9%|         | 5/53 [00:03<00:35,  1.34it/s]Loading checkpoint shards:  13%|        | 7/53 [00:04<00:31,  1.45it/s]Loading checkpoint shards:  11%|        | 6/53 [00:04<00:31,  1.48it/s]Loading checkpoint shards:  11%|        | 6/53 [00:04<00:33,  1.40it/s]Loading checkpoint shards:  11%|        | 6/53 [00:04<00:32,  1.47it/s]Loading checkpoint shards:  11%|        | 6/53 [00:04<00:32,  1.45it/s]Loading checkpoint shards:  13%|        | 7/53 [00:04<00:32,  1.43it/s]Loading checkpoint shards:  11%|        | 6/53 [00:04<00:35,  1.33it/s]Loading checkpoint shards:  11%|        | 6/53 [00:04<00:35,  1.32it/s]Loading checkpoint shards:  15%|        | 8/53 [00:05<00:31,  1.42it/s]Loading checkpoint shards:  13%|        | 7/53 [00:04<00:30,  1.49it/s]Loading checkpoint shards:  13%|        | 7/53 [00:04<00:30,  1.50it/s]Loading checkpoint shards:  13%|        | 7/53 [00:05<00:32,  1.41it/s]Loading checkpoint shards:  13%|        | 7/53 [00:04<00:30,  1.53it/s]Loading checkpoint shards:  15%|        | 8/53 [00:05<00:31,  1.42it/s]Loading checkpoint shards:  13%|        | 7/53 [00:05<00:34,  1.33it/s]Loading checkpoint shards:  13%|        | 7/53 [00:05<00:34,  1.34it/s]Loading checkpoint shards:  17%|        | 9/53 [00:06<00:31,  1.39it/s]Loading checkpoint shards:  15%|        | 8/53 [00:05<00:29,  1.52it/s]Loading checkpoint shards:  15%|        | 8/53 [00:05<00:30,  1.48it/s]Loading checkpoint shards:  15%|        | 8/53 [00:05<00:31,  1.42it/s]Loading checkpoint shards:  15%|        | 8/53 [00:05<00:31,  1.41it/s]Loading checkpoint shards:  17%|        | 9/53 [00:06<00:32,  1.35it/s]Loading checkpoint shards:  15%|        | 8/53 [00:05<00:33,  1.33it/s]Loading checkpoint shards:  15%|        | 8/53 [00:06<00:34,  1.30it/s]Loading checkpoint shards:  19%|        | 10/53 [00:07<00:31,  1.38it/s]Loading checkpoint shards:  17%|        | 9/53 [00:06<00:31,  1.39it/s]Loading checkpoint shards:  17%|        | 9/53 [00:06<00:31,  1.40it/s]Loading checkpoint shards:  17%|        | 9/53 [00:06<00:32,  1.37it/s]Loading checkpoint shards:  17%|        | 9/53 [00:06<00:33,  1.30it/s]Loading checkpoint shards:  19%|        | 10/53 [00:07<00:30,  1.40it/s]Loading checkpoint shards:  17%|        | 9/53 [00:06<00:32,  1.36it/s]Loading checkpoint shards:  21%|        | 11/53 [00:07<00:29,  1.43it/s]Loading checkpoint shards:  17%|        | 9/53 [00:06<00:35,  1.24it/s]Loading checkpoint shards:  19%|        | 10/53 [00:06<00:30,  1.41it/s]Loading checkpoint shards:  19%|        | 10/53 [00:07<00:30,  1.41it/s]Loading checkpoint shards:  19%|        | 10/53 [00:06<00:30,  1.42it/s]Loading checkpoint shards:  19%|        | 10/53 [00:07<00:32,  1.31it/s]Loading checkpoint shards:  21%|        | 11/53 [00:07<00:29,  1.42it/s]Loading checkpoint shards:  19%|        | 10/53 [00:07<00:32,  1.34it/s]Loading checkpoint shards:  23%|       | 12/53 [00:08<00:28,  1.45it/s]Loading checkpoint shards:  21%|        | 11/53 [00:07<00:28,  1.46it/s]Loading checkpoint shards:  19%|        | 10/53 [00:07<00:34,  1.25it/s]Loading checkpoint shards:  21%|        | 11/53 [00:07<00:29,  1.42it/s]Loading checkpoint shards:  21%|        | 11/53 [00:07<00:29,  1.43it/s]Loading checkpoint shards:  23%|       | 12/53 [00:08<00:27,  1.48it/s]Loading checkpoint shards:  21%|        | 11/53 [00:08<00:31,  1.34it/s]Loading checkpoint shards:  25%|       | 13/53 [00:08<00:26,  1.50it/s]Loading checkpoint shards:  21%|        | 11/53 [00:08<00:30,  1.37it/s]Loading checkpoint shards:  23%|       | 12/53 [00:08<00:27,  1.48it/s]Loading checkpoint shards:  23%|       | 12/53 [00:08<00:29,  1.39it/s]Loading checkpoint shards:  23%|       | 12/53 [00:08<00:29,  1.37it/s]Loading checkpoint shards:  21%|        | 11/53 [00:08<00:33,  1.25it/s]Loading checkpoint shards:  25%|       | 13/53 [00:09<00:28,  1.42it/s]Loading checkpoint shards:  23%|       | 12/53 [00:08<00:30,  1.33it/s]Loading checkpoint shards:  26%|       | 14/53 [00:09<00:25,  1.53it/s]Loading checkpoint shards:  23%|       | 12/53 [00:08<00:29,  1.38it/s]Loading checkpoint shards:  25%|       | 13/53 [00:08<00:26,  1.53it/s]Loading checkpoint shards:  25%|       | 13/53 [00:09<00:27,  1.44it/s]Loading checkpoint shards:  25%|       | 13/53 [00:09<00:28,  1.40it/s]Loading checkpoint shards:  23%|       | 12/53 [00:09<00:32,  1.28it/s]Loading checkpoint shards:  26%|       | 14/53 [00:09<00:26,  1.46it/s]Loading checkpoint shards:  25%|       | 13/53 [00:09<00:29,  1.36it/s]Loading checkpoint shards:  28%|       | 15/53 [00:10<00:25,  1.52it/s]Loading checkpoint shards:  26%|       | 14/53 [00:09<00:25,  1.55it/s]Loading checkpoint shards:  25%|       | 13/53 [00:09<00:29,  1.36it/s]Loading checkpoint shards:  26%|       | 14/53 [00:09<00:26,  1.47it/s]Loading checkpoint shards:  26%|       | 14/53 [00:09<00:26,  1.45it/s]Loading checkpoint shards:  28%|       | 15/53 [00:10<00:25,  1.51it/s]Loading checkpoint shards:  25%|       | 13/53 [00:09<00:30,  1.32it/s]Loading checkpoint shards:  30%|       | 16/53 [00:10<00:24,  1.52it/s]Loading checkpoint shards:  26%|       | 14/53 [00:10<00:28,  1.37it/s]Loading checkpoint shards:  28%|       | 15/53 [00:10<00:24,  1.57it/s]Loading checkpoint shards:  26%|       | 14/53 [00:10<00:28,  1.37it/s]Loading checkpoint shards:  28%|       | 15/53 [00:10<00:26,  1.45it/s]Loading checkpoint shards:  28%|       | 15/53 [00:10<00:26,  1.44it/s]Loading checkpoint shards:  30%|       | 16/53 [00:11<00:24,  1.51it/s]Loading checkpoint shards:  32%|      | 17/53 [00:11<00:23,  1.55it/s]Loading checkpoint shards:  26%|       | 14/53 [00:10<00:28,  1.35it/s]Loading checkpoint shards:  30%|       | 16/53 [00:10<00:23,  1.59it/s]Loading checkpoint shards:  28%|       | 15/53 [00:10<00:27,  1.37it/s]Loading checkpoint shards:  28%|       | 15/53 [00:10<00:27,  1.38it/s]Loading checkpoint shards:  30%|       | 16/53 [00:11<00:24,  1.48it/s]Loading checkpoint shards:  32%|      | 17/53 [00:11<00:23,  1.54it/s]Loading checkpoint shards:  30%|       | 16/53 [00:11<00:25,  1.46it/s]Loading checkpoint shards:  34%|      | 18/53 [00:12<00:22,  1.54it/s]Loading checkpoint shards:  28%|       | 15/53 [00:11<00:28,  1.34it/s]Loading checkpoint shards:  32%|      | 17/53 [00:11<00:23,  1.56it/s]Loading checkpoint shards:  30%|       | 16/53 [00:11<00:26,  1.38it/s]Loading checkpoint shards:  30%|       | 16/53 [00:11<00:25,  1.42it/s]Loading checkpoint shards:  32%|      | 17/53 [00:11<00:24,  1.49it/s]Loading checkpoint shards:  32%|      | 17/53 [00:11<00:24,  1.46it/s]Loading checkpoint shards:  34%|      | 18/53 [00:12<00:22,  1.52it/s]Loading checkpoint shards:  36%|      | 19/53 [00:12<00:21,  1.55it/s]Loading checkpoint shards:  30%|       | 16/53 [00:12<00:26,  1.41it/s]Loading checkpoint shards:  34%|      | 18/53 [00:12<00:22,  1.57it/s]Loading checkpoint shards:  32%|      | 17/53 [00:12<00:26,  1.38it/s]Loading checkpoint shards:  34%|      | 18/53 [00:12<00:23,  1.52it/s]Loading checkpoint shards:  32%|      | 17/53 [00:12<00:26,  1.38it/s]Loading checkpoint shards:  36%|      | 19/53 [00:12<00:22,  1.52it/s]Loading checkpoint shards:  34%|      | 18/53 [00:12<00:24,  1.45it/s]Loading checkpoint shards:  38%|      | 20/53 [00:13<00:21,  1.54it/s]Loading checkpoint shards:  36%|      | 19/53 [00:12<00:21,  1.57it/s]Loading checkpoint shards:  32%|      | 17/53 [00:12<00:25,  1.44it/s]Loading checkpoint shards:  34%|      | 18/53 [00:13<00:25,  1.35it/s]Loading checkpoint shards:  36%|      | 19/53 [00:12<00:22,  1.54it/s]Loading checkpoint shards:  38%|      | 20/53 [00:13<00:21,  1.53it/s]Loading checkpoint shards:  34%|      | 18/53 [00:13<00:25,  1.38it/s]Loading checkpoint shards:  36%|      | 19/53 [00:13<00:23,  1.43it/s]Loading checkpoint shards:  40%|      | 21/53 [00:14<00:21,  1.51it/s]Loading checkpoint shards:  38%|      | 20/53 [00:13<00:21,  1.55it/s]Loading checkpoint shards:  34%|      | 18/53 [00:13<00:24,  1.44it/s]Loading checkpoint shards:  38%|      | 20/53 [00:13<00:20,  1.57it/s]Loading checkpoint shards:  36%|      | 19/53 [00:13<00:25,  1.33it/s]Loading checkpoint shards:  40%|      | 21/53 [00:14<00:20,  1.53it/s]Loading checkpoint shards:  36%|      | 19/53 [00:13<00:24,  1.40it/s]Loading checkpoint shards:  38%|      | 20/53 [00:13<00:22,  1.46it/s]Loading checkpoint shards:  42%|     | 22/53 [00:14<00:20,  1.52it/s]Loading checkpoint shards:  40%|      | 21/53 [00:14<00:20,  1.56it/s]Loading checkpoint shards:  36%|      | 19/53 [00:14<00:23,  1.47it/s]Loading checkpoint shards:  40%|      | 21/53 [00:14<00:20,  1.58it/s]Loading checkpoint shards:  38%|      | 20/53 [00:14<00:24,  1.36it/s]Loading checkpoint shards:  42%|     | 22/53 [00:14<00:20,  1.50it/s]Loading checkpoint shards:  40%|      | 21/53 [00:14<00:21,  1.48it/s]Loading checkpoint shards:  43%|     | 23/53 [00:15<00:19,  1.51it/s]Loading checkpoint shards:  38%|      | 20/53 [00:14<00:24,  1.36it/s]Loading checkpoint shards:  38%|      | 20/53 [00:14<00:21,  1.51it/s]Loading checkpoint shards:  42%|     | 22/53 [00:14<00:20,  1.54it/s]Loading checkpoint shards:  42%|     | 22/53 [00:14<00:19,  1.59it/s]Loading checkpoint shards:  40%|      | 21/53 [00:15<00:22,  1.41it/s]Loading checkpoint shards:  43%|     | 23/53 [00:15<00:19,  1.51it/s]Loading checkpoint shards:  42%|     | 22/53 [00:15<00:20,  1.49it/s]Loading checkpoint shards:  40%|      | 21/53 [00:15<00:20,  1.54it/s]Loading checkpoint shards:  45%|     | 24/53 [00:16<00:19,  1.49it/s]Loading checkpoint shards:  40%|      | 21/53 [00:15<00:22,  1.40it/s]Loading checkpoint shards:  43%|     | 23/53 [00:15<00:19,  1.51it/s]Loading checkpoint shards:  43%|     | 23/53 [00:15<00:19,  1.55it/s]Loading checkpoint shards:  45%|     | 24/53 [00:16<00:19,  1.47it/s]Loading checkpoint shards:  42%|     | 22/53 [00:16<00:22,  1.39it/s]Loading checkpoint shards:  43%|     | 23/53 [00:15<00:20,  1.44it/s]Loading checkpoint shards:  47%|     | 25/53 [00:16<00:19,  1.45it/s]Loading checkpoint shards:  42%|     | 22/53 [00:16<00:21,  1.45it/s]Loading checkpoint shards:  42%|     | 22/53 [00:16<00:22,  1.38it/s]Loading checkpoint shards:  45%|     | 24/53 [00:16<00:20,  1.41it/s]Loading checkpoint shards:  45%|     | 24/53 [00:16<00:19,  1.50it/s]Loading checkpoint shards:  47%|     | 25/53 [00:16<00:18,  1.49it/s]Loading checkpoint shards:  45%|     | 24/53 [00:16<00:20,  1.44it/s]Loading checkpoint shards:  43%|     | 23/53 [00:16<00:22,  1.36it/s]Loading checkpoint shards:  49%|     | 26/53 [00:17<00:18,  1.45it/s]Loading checkpoint shards:  43%|     | 23/53 [00:16<00:21,  1.39it/s]Loading checkpoint shards:  43%|     | 23/53 [00:16<00:21,  1.42it/s]Loading checkpoint shards:  47%|     | 25/53 [00:16<00:19,  1.45it/s]Loading checkpoint shards:  47%|     | 25/53 [00:16<00:18,  1.52it/s]Loading checkpoint shards:  49%|     | 26/53 [00:17<00:17,  1.52it/s]Loading checkpoint shards:  47%|     | 25/53 [00:17<00:19,  1.46it/s]Loading checkpoint shards:  51%|     | 27/53 [00:18<00:17,  1.50it/s]Loading checkpoint shards:  45%|     | 24/53 [00:17<00:20,  1.39it/s]Loading checkpoint shards:  45%|     | 24/53 [00:17<00:20,  1.42it/s]Loading checkpoint shards:  45%|     | 24/53 [00:17<00:20,  1.42it/s]Loading checkpoint shards:  49%|     | 26/53 [00:17<00:18,  1.45it/s]Loading checkpoint shards:  49%|     | 26/53 [00:17<00:17,  1.51it/s]Loading checkpoint shards:  51%|     | 27/53 [00:18<00:17,  1.52it/s]Loading checkpoint shards:  49%|     | 26/53 [00:17<00:18,  1.49it/s]Loading checkpoint shards:  47%|     | 25/53 [00:18<00:19,  1.44it/s]Loading checkpoint shards:  53%|    | 28/53 [00:18<00:16,  1.51it/s]Loading checkpoint shards:  47%|     | 25/53 [00:18<00:19,  1.45it/s]Loading checkpoint shards:  51%|     | 27/53 [00:18<00:17,  1.47it/s]Loading checkpoint shards:  47%|     | 25/53 [00:18<00:19,  1.44it/s]Loading checkpoint shards:  51%|     | 27/53 [00:18<00:16,  1.53it/s]Loading checkpoint shards:  53%|    | 28/53 [00:18<00:16,  1.50it/s]Loading checkpoint shards:  55%|    | 29/53 [00:19<00:15,  1.51it/s]Loading checkpoint shards:  49%|     | 26/53 [00:18<00:18,  1.45it/s]Loading checkpoint shards:  51%|     | 27/53 [00:18<00:17,  1.46it/s]Loading checkpoint shards:  49%|     | 26/53 [00:18<00:18,  1.43it/s]Loading checkpoint shards:  53%|    | 28/53 [00:18<00:16,  1.48it/s]Loading checkpoint shards:  49%|     | 26/53 [00:18<00:18,  1.43it/s]Loading checkpoint shards:  53%|    | 28/53 [00:18<00:16,  1.52it/s]Loading checkpoint shards:  55%|    | 29/53 [00:19<00:15,  1.51it/s]Loading checkpoint shards:  57%|    | 30/53 [00:20<00:14,  1.55it/s]Loading checkpoint shards:  51%|     | 27/53 [00:19<00:17,  1.49it/s]Loading checkpoint shards:  53%|    | 28/53 [00:19<00:16,  1.49it/s]Loading checkpoint shards:  51%|     | 27/53 [00:19<00:17,  1.45it/s]Loading checkpoint shards:  55%|    | 29/53 [00:19<00:16,  1.49it/s]Loading checkpoint shards:  51%|     | 27/53 [00:19<00:17,  1.45it/s]Loading checkpoint shards:  55%|    | 29/53 [00:19<00:16,  1.49it/s]Loading checkpoint shards:  57%|    | 30/53 [00:20<00:15,  1.50it/s]Loading checkpoint shards:  58%|    | 31/53 [00:20<00:13,  1.58it/s]Loading checkpoint shards:  55%|    | 29/53 [00:19<00:15,  1.50it/s]Loading checkpoint shards:  53%|    | 28/53 [00:20<00:17,  1.41it/s]Loading checkpoint shards:  57%|    | 30/53 [00:20<00:15,  1.53it/s]Loading checkpoint shards:  53%|    | 28/53 [00:20<00:16,  1.48it/s]Loading checkpoint shards:  53%|    | 28/53 [00:20<00:16,  1.48it/s]Loading checkpoint shards:  57%|    | 30/53 [00:20<00:15,  1.51it/s]Loading checkpoint shards:  58%|    | 31/53 [00:20<00:14,  1.52it/s]Loading checkpoint shards:  60%|    | 32/53 [00:21<00:13,  1.60it/s]Loading checkpoint shards:  57%|    | 30/53 [00:20<00:15,  1.51it/s]Loading checkpoint shards:  58%|    | 31/53 [00:20<00:14,  1.54it/s]Loading checkpoint shards:  55%|    | 29/53 [00:20<00:17,  1.40it/s]Loading checkpoint shards:  55%|    | 29/53 [00:20<00:16,  1.47it/s]Loading checkpoint shards:  55%|    | 29/53 [00:20<00:16,  1.47it/s]Loading checkpoint shards:  58%|    | 31/53 [00:20<00:14,  1.50it/s]Loading checkpoint shards:  60%|    | 32/53 [00:21<00:13,  1.54it/s]Loading checkpoint shards:  62%|   | 33/53 [00:21<00:12,  1.59it/s]Loading checkpoint shards:  58%|    | 31/53 [00:21<00:14,  1.53it/s]Loading checkpoint shards:  60%|    | 32/53 [00:21<00:13,  1.57it/s]Loading checkpoint shards:  57%|    | 30/53 [00:21<00:15,  1.47it/s]Loading checkpoint shards:  57%|    | 30/53 [00:21<00:16,  1.40it/s]Loading checkpoint shards:  57%|    | 30/53 [00:21<00:15,  1.46it/s]Loading checkpoint shards:  60%|    | 32/53 [00:21<00:14,  1.48it/s]Loading checkpoint shards:  64%|   | 34/53 [00:22<00:12,  1.55it/s]Loading checkpoint shards:  62%|   | 33/53 [00:22<00:13,  1.51it/s]Loading checkpoint shards:  60%|    | 32/53 [00:21<00:13,  1.52it/s]Loading checkpoint shards:  62%|   | 33/53 [00:22<00:12,  1.58it/s]Loading checkpoint shards:  58%|    | 31/53 [00:22<00:14,  1.50it/s]Loading checkpoint shards:  58%|    | 31/53 [00:22<00:15,  1.42it/s]Loading checkpoint shards:  58%|    | 31/53 [00:22<00:14,  1.47it/s]Loading checkpoint shards:  62%|   | 33/53 [00:22<00:13,  1.49it/s]Loading checkpoint shards:  66%|   | 35/53 [00:23<00:11,  1.55it/s]Loading checkpoint shards:  64%|   | 34/53 [00:22<00:12,  1.52it/s]Loading checkpoint shards:  62%|   | 33/53 [00:22<00:13,  1.53it/s]Loading checkpoint shards:  64%|   | 34/53 [00:22<00:12,  1.54it/s]Loading checkpoint shards:  60%|    | 32/53 [00:22<00:14,  1.44it/s]Loading checkpoint shards:  60%|    | 32/53 [00:22<00:14,  1.47it/s]Loading checkpoint shards:  60%|    | 32/53 [00:23<00:15,  1.40it/s]Loading checkpoint shards:  64%|   | 34/53 [00:22<00:12,  1.50it/s]Loading checkpoint shards:  68%|   | 36/53 [00:23<00:10,  1.56it/s]Loading checkpoint shards:  66%|   | 35/53 [00:23<00:11,  1.53it/s]Loading checkpoint shards:  64%|   | 34/53 [00:23<00:12,  1.57it/s]Loading checkpoint shards:  66%|   | 35/53 [00:23<00:11,  1.55it/s]Loading checkpoint shards:  62%|   | 33/53 [00:23<00:13,  1.50it/s]Loading checkpoint shards:  62%|   | 33/53 [00:23<00:14,  1.42it/s]Loading checkpoint shards:  62%|   | 33/53 [00:23<00:14,  1.42it/s]Loading checkpoint shards:  66%|   | 35/53 [00:23<00:12,  1.49it/s]Loading checkpoint shards:  70%|   | 37/53 [00:24<00:10,  1.51it/s]Loading checkpoint shards:  66%|   | 35/53 [00:23<00:11,  1.54it/s]Loading checkpoint shards:  68%|   | 36/53 [00:24<00:11,  1.45it/s]Loading checkpoint shards:  68%|   | 36/53 [00:24<00:11,  1.51it/s]Loading checkpoint shards:  64%|   | 34/53 [00:24<00:12,  1.54it/s]Loading checkpoint shards:  68%|   | 36/53 [00:24<00:11,  1.51it/s]Loading checkpoint shards:  64%|   | 34/53 [00:24<00:13,  1.42it/s]Loading checkpoint shards:  64%|   | 34/53 [00:24<00:13,  1.39it/s]Loading checkpoint shards:  72%|  | 38/53 [00:25<00:09,  1.53it/s]Loading checkpoint shards:  68%|   | 36/53 [00:24<00:10,  1.58it/s]Loading checkpoint shards:  70%|   | 37/53 [00:24<00:10,  1.47it/s]Loading checkpoint shards:  70%|   | 37/53 [00:24<00:10,  1.53it/s]Loading checkpoint shards:  66%|   | 35/53 [00:24<00:11,  1.53it/s]Loading checkpoint shards:  70%|   | 37/53 [00:24<00:10,  1.54it/s]Loading checkpoint shards:  70%|   | 37/53 [00:24<00:09,  1.61it/s]Loading checkpoint shards:  66%|   | 35/53 [00:25<00:12,  1.41it/s]Loading checkpoint shards:  66%|   | 35/53 [00:24<00:12,  1.42it/s]Loading checkpoint shards:  74%|  | 39/53 [00:25<00:09,  1.52it/s]Loading checkpoint shards:  72%|  | 38/53 [00:25<00:10,  1.49it/s]Loading checkpoint shards:  72%|  | 38/53 [00:25<00:09,  1.54it/s]Loading checkpoint shards:  68%|   | 36/53 [00:25<00:11,  1.52it/s]Loading checkpoint shards:  72%|  | 38/53 [00:25<00:10,  1.50it/s]Loading checkpoint shards:  68%|   | 36/53 [00:25<00:12,  1.38it/s]Loading checkpoint shards:  68%|   | 36/53 [00:26<00:12,  1.37it/s]Loading checkpoint shards:  72%|  | 38/53 [00:25<00:10,  1.49it/s]Loading checkpoint shards:  75%|  | 40/53 [00:26<00:08,  1.46it/s]Loading checkpoint shards:  74%|  | 39/53 [00:26<00:09,  1.43it/s]Loading checkpoint shards:  74%|  | 39/53 [00:26<00:09,  1.49it/s]Loading checkpoint shards:  70%|   | 37/53 [00:26<00:10,  1.54it/s]Loading checkpoint shards:  74%|  | 39/53 [00:26<00:09,  1.47it/s]Loading checkpoint shards:  74%|  | 39/53 [00:26<00:09,  1.48it/s]Loading checkpoint shards:  70%|   | 37/53 [00:26<00:11,  1.38it/s]Loading checkpoint shards:  70%|   | 37/53 [00:26<00:11,  1.36it/s]Loading checkpoint shards:  77%|  | 41/53 [00:27<00:08,  1.39it/s]Loading checkpoint shards:  75%|  | 40/53 [00:27<00:09,  1.38it/s]Loading checkpoint shards:  75%|  | 40/53 [00:26<00:08,  1.47it/s]Loading checkpoint shards:  72%|  | 38/53 [00:26<00:09,  1.55it/s]Loading checkpoint shards:  75%|  | 40/53 [00:26<00:08,  1.50it/s]Loading checkpoint shards:  75%|  | 40/53 [00:27<00:08,  1.53it/s]Loading checkpoint shards:  72%|  | 38/53 [00:27<00:10,  1.38it/s]Loading checkpoint shards:  72%|  | 38/53 [00:27<00:11,  1.36it/s]Loading checkpoint shards:  79%|  | 42/53 [00:28<00:07,  1.41it/s]Loading checkpoint shards:  74%|  | 39/53 [00:27<00:09,  1.54it/s]Loading checkpoint shards:  77%|  | 41/53 [00:27<00:08,  1.44it/s]Loading checkpoint shards:  77%|  | 41/53 [00:27<00:08,  1.38it/s]Loading checkpoint shards:  77%|  | 41/53 [00:27<00:07,  1.55it/s]Loading checkpoint shards:  77%|  | 41/53 [00:27<00:07,  1.57it/s]Loading checkpoint shards:  74%|  | 39/53 [00:28<00:10,  1.39it/s]Loading checkpoint shards:  81%|  | 43/53 [00:28<00:07,  1.41it/s]Loading checkpoint shards:  74%|  | 39/53 [00:28<00:10,  1.34it/s]Loading checkpoint shards:  75%|  | 40/53 [00:28<00:08,  1.54it/s]Loading checkpoint shards:  79%|  | 42/53 [00:28<00:07,  1.40it/s]Loading checkpoint shards:  79%|  | 42/53 [00:28<00:07,  1.44it/s]Loading checkpoint shards:  79%|  | 42/53 [00:28<00:07,  1.56it/s]Loading checkpoint shards:  79%|  | 42/53 [00:28<00:06,  1.61it/s]Loading checkpoint shards:  77%|  | 41/53 [00:28<00:07,  1.56it/s]Loading checkpoint shards:  75%|  | 40/53 [00:28<00:09,  1.39it/s]Loading checkpoint shards:  83%| | 44/53 [00:29<00:06,  1.42it/s]Loading checkpoint shards:  81%|  | 43/53 [00:29<00:07,  1.40it/s]Loading checkpoint shards:  81%|  | 43/53 [00:28<00:06,  1.43it/s]Loading checkpoint shards:  75%|  | 40/53 [00:28<00:09,  1.33it/s]Loading checkpoint shards:  81%|  | 43/53 [00:28<00:06,  1.54it/s]Loading checkpoint shards:  81%|  | 43/53 [00:28<00:06,  1.59it/s]Loading checkpoint shards:  79%|  | 42/53 [00:29<00:06,  1.59it/s]Loading checkpoint shards:  85%| | 45/53 [00:30<00:05,  1.43it/s]Loading checkpoint shards:  77%|  | 41/53 [00:29<00:08,  1.40it/s]Loading checkpoint shards:  83%| | 44/53 [00:29<00:05,  1.57it/s]Loading checkpoint shards:  83%| | 44/53 [00:29<00:06,  1.46it/s]Loading checkpoint shards:  83%| | 44/53 [00:29<00:06,  1.42it/s]Loading checkpoint shards:  83%| | 44/53 [00:29<00:05,  1.62it/s]Loading checkpoint shards:  77%|  | 41/53 [00:29<00:08,  1.34it/s]Loading checkpoint shards:  81%|  | 43/53 [00:29<00:06,  1.58it/s]Loading checkpoint shards:  87%| | 46/53 [00:30<00:04,  1.45it/s]Loading checkpoint shards:  85%| | 45/53 [00:30<00:05,  1.56it/s]Loading checkpoint shards:  79%|  | 42/53 [00:30<00:08,  1.37it/s]Loading checkpoint shards:  85%| | 45/53 [00:30<00:05,  1.46it/s]Loading checkpoint shards:  85%| | 45/53 [00:30<00:05,  1.58it/s]Loading checkpoint shards:  85%| | 45/53 [00:30<00:05,  1.43it/s]Loading checkpoint shards:  79%|  | 42/53 [00:30<00:08,  1.32it/s]Loading checkpoint shards:  83%| | 44/53 [00:30<00:05,  1.61it/s]Loading checkpoint shards:  89%| | 47/53 [00:31<00:04,  1.50it/s]Loading checkpoint shards:  87%| | 46/53 [00:30<00:04,  1.55it/s]Loading checkpoint shards:  87%| | 46/53 [00:30<00:04,  1.50it/s]Loading checkpoint shards:  87%| | 46/53 [00:30<00:04,  1.58it/s]Loading checkpoint shards:  87%| | 46/53 [00:31<00:04,  1.47it/s]Loading checkpoint shards:  81%|  | 43/53 [00:31<00:07,  1.38it/s]Loading checkpoint shards:  81%|  | 43/53 [00:30<00:07,  1.37it/s]Loading checkpoint shards:  85%| | 45/53 [00:31<00:04,  1.60it/s]Loading checkpoint shards:  91%| | 48/53 [00:32<00:03,  1.53it/s]Loading checkpoint shards:  89%| | 47/53 [00:31<00:03,  1.56it/s]Loading checkpoint shards:  89%| | 47/53 [00:31<00:03,  1.53it/s]Loading checkpoint shards:  89%| | 47/53 [00:31<00:03,  1.59it/s]Loading checkpoint shards:  89%| | 47/53 [00:31<00:03,  1.51it/s]Loading checkpoint shards:  83%| | 44/53 [00:31<00:06,  1.40it/s]Loading checkpoint shards:  83%| | 44/53 [00:31<00:06,  1.44it/s]Loading checkpoint shards:  87%| | 46/53 [00:31<00:04,  1.62it/s]Loading checkpoint shards:  92%|| 49/53 [00:32<00:02,  1.53it/s]Loading checkpoint shards:  91%| | 48/53 [00:31<00:03,  1.53it/s]Loading checkpoint shards:  91%| | 48/53 [00:32<00:03,  1.51it/s]Loading checkpoint shards:  91%| | 48/53 [00:32<00:03,  1.56it/s]Loading checkpoint shards:  91%| | 48/53 [00:32<00:03,  1.49it/s]Loading checkpoint shards:  85%| | 45/53 [00:32<00:05,  1.44it/s]Loading checkpoint shards:  85%| | 45/53 [00:32<00:05,  1.50it/s]Loading checkpoint shards:  89%| | 47/53 [00:32<00:03,  1.62it/s]Loading checkpoint shards:  94%|| 50/53 [00:33<00:01,  1.54it/s]Loading checkpoint shards:  92%|| 49/53 [00:32<00:02,  1.54it/s]Loading checkpoint shards:  92%|| 49/53 [00:32<00:02,  1.56it/s]Loading checkpoint shards:  92%|| 49/53 [00:32<00:02,  1.51it/s]Loading checkpoint shards:  92%|| 49/53 [00:33<00:02,  1.50it/s]Loading checkpoint shards:  87%| | 46/53 [00:32<00:04,  1.52it/s]Loading checkpoint shards:  87%| | 46/53 [00:33<00:04,  1.44it/s]Loading checkpoint shards:  91%| | 48/53 [00:33<00:03,  1.59it/s]Loading checkpoint shards:  96%|| 51/53 [00:34<00:01,  1.54it/s]Loading checkpoint shards:  94%|| 50/53 [00:33<00:01,  1.57it/s]Loading checkpoint shards:  94%|| 50/53 [00:33<00:01,  1.58it/s]Loading checkpoint shards:  94%|| 50/53 [00:33<00:01,  1.53it/s]Loading checkpoint shards:  94%|| 50/53 [00:33<00:01,  1.51it/s]Loading checkpoint shards:  89%| | 47/53 [00:33<00:03,  1.56it/s]Loading checkpoint shards:  89%| | 47/53 [00:33<00:04,  1.48it/s]Loading checkpoint shards:  92%|| 49/53 [00:33<00:02,  1.61it/s]Loading checkpoint shards:  98%|| 52/53 [00:34<00:00,  1.56it/s]Loading checkpoint shards:  96%|| 51/53 [00:33<00:01,  1.56it/s]Loading checkpoint shards:  96%|| 51/53 [00:33<00:01,  1.53it/s]Loading checkpoint shards:  96%|| 51/53 [00:34<00:01,  1.51it/s]Loading checkpoint shards:  91%| | 48/53 [00:34<00:03,  1.56it/s]Loading checkpoint shards:  96%|| 51/53 [00:34<00:01,  1.48it/s]Loading checkpoint shards:  91%| | 48/53 [00:34<00:03,  1.47it/s]Loading checkpoint shards:  94%|| 50/53 [00:34<00:01,  1.60it/s]Loading checkpoint shards:  98%|| 52/53 [00:34<00:00,  1.55it/s]Loading checkpoint shards:  98%|| 52/53 [00:34<00:00,  1.52it/s]Loading checkpoint shards:  98%|| 52/53 [00:34<00:00,  1.51it/s]Loading checkpoint shards:  92%|| 49/53 [00:34<00:02,  1.55it/s]Loading checkpoint shards:  98%|| 52/53 [00:35<00:00,  1.47it/s]Loading checkpoint shards:  92%|| 49/53 [00:35<00:02,  1.47it/s]Loading checkpoint shards:  96%|| 51/53 [00:34<00:01,  1.58it/s]Loading checkpoint shards: 100%|| 53/53 [00:36<00:00,  1.21it/s]Loading checkpoint shards: 100%|| 53/53 [00:36<00:00,  1.47it/s]
Loading checkpoint shards:  94%|| 50/53 [00:35<00:01,  1.52it/s]Loading checkpoint shards:  98%|| 52/53 [00:35<00:00,  1.55it/s]Loading checkpoint shards:  94%|| 50/53 [00:35<00:02,  1.45it/s]Loading checkpoint shards: 100%|| 53/53 [00:35<00:00,  1.20it/s]Loading checkpoint shards: 100%|| 53/53 [00:35<00:00,  1.48it/s]
Loading checkpoint shards: 100%|| 53/53 [00:36<00:00,  1.18it/s]Loading checkpoint shards: 100%|| 53/53 [00:36<00:00,  1.47it/s]
Loading checkpoint shards: 100%|| 53/53 [00:35<00:00,  1.15it/s]Loading checkpoint shards: 100%|| 53/53 [00:35<00:00,  1.47it/s]
Loading checkpoint shards: 100%|| 53/53 [00:36<00:00,  1.16it/s]Loading checkpoint shards: 100%|| 53/53 [00:36<00:00,  1.45it/s]
[INFO|modeling_utils.py:3775] 2023-10-23 07:23:47,521 >> All model checkpoint weights were used when initializing SkyworkForCausalLM.

[INFO|modeling_utils.py:3783] 2023-10-23 07:23:47,521 >> All the weights of SkyworkForCausalLM were initialized from the model checkpoint at /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base.
If your task is similar to the task the model of the checkpoint was trained on, you can already use SkyworkForCausalLM for predictions without further training.
[INFO|configuration_utils.py:728] 2023-10-23 07:23:47,525 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/generation_config.json
[INFO|configuration_utils.py:770] 2023-10-23 07:23:47,525 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "do_sample": true,
  "eos_token_id": 2,
  "max_length": 4096,
  "pad_token_id": 0,
  "temperature": 0.6,
  "top_p": 0.9
}

Loading checkpoint shards:  96%|| 51/53 [00:36<00:01,  1.48it/s]Loading checkpoint shards:  96%|| 51/53 [00:36<00:01,  1.43it/s]10/23/2023 07:23:47 - INFO - __main__ - Model vocab size: 65519
10/23/2023 07:23:47 - INFO - __main__ - len(tokenizer):65519
[INFO|trainer.py:400] 2023-10-23 07:23:47,966 >> You have loaded a model on multiple GPUs. `is_model_parallel` attribute will be force-set to `True` to avoid any unexpected behavior such as device placement mismatching.
[INFO|trainer.py:576] 2023-10-23 07:23:47,966 >> max_steps is given, it will override any value given in num_train_epochs
[INFO|deepspeed.py:303] 2023-10-23 07:23:48,091 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
Loading checkpoint shards: 100%|| 53/53 [00:36<00:00,  1.26it/s]Loading checkpoint shards: 100%|| 53/53 [00:36<00:00,  1.44it/s]
Loading checkpoint shards:  98%|| 52/53 [00:36<00:00,  1.54it/s]Loading checkpoint shards:  98%|| 52/53 [00:37<00:00,  1.52it/s]Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Loading checkpoint shards: 100%|| 53/53 [00:37<00:00,  1.29it/s]Loading checkpoint shards: 100%|| 53/53 [00:37<00:00,  1.40it/s]
Loading checkpoint shards: 100%|| 53/53 [00:38<00:00,  1.27it/s]Loading checkpoint shards: 100%|| 53/53 [00:38<00:00,  1.39it/s]
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /root/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Creating extension directory /root/.cache/torch_extensions/py38_cu121/cpu_adam...
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Detected CUDA files, patching ldflags
Emitting ninja build file /root/.cache/torch_extensions/py38_cu121/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /root/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /root/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /root/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /root/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /root/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /root/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /root/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
[1/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/usr/local/lib/python3.8/dist-packages/deepspeed/ops/csrc/includes -I/usr/local/cuda/include -isystem /usr/local/lib/python3.8/dist-packages/torch/include -isystem /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.8/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.8/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_80,code=compute_80 -DBF16_AVAILABLE -c /usr/local/lib/python3.8/dist-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu -o custom_cuda_kernel.cuda.o 
[2/3] c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/usr/local/lib/python3.8/dist-packages/deepspeed/ops/csrc/includes -I/usr/local/cuda/include -isystem /usr/local/lib/python3.8/dist-packages/torch/include -isystem /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.8/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.8/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/usr/local/cuda/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX512__ -D__ENABLE_CUDA__ -DBF16_AVAILABLE -c /usr/local/lib/python3.8/dist-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp -o cpu_adam.o 
[3/3] c++ cpu_adam.o custom_cuda_kernel.cuda.o -shared -lcurand -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o cpu_adam.so
Loading extension module cpu_adam...
Time to load cpu_adam op: 28.047027587890625 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 25.61267876625061 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 27.22883176803589 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 27.119017601013184 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 26.78621506690979 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 27.214367866516113 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 27.405910968780518 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 25.446147918701172 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1
[2023-10-23 07:24:18,173] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 426, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1591, in train
    return inner_training_loop(
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1726, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1198, in prepare
    result = self._prepare_deepspeed(*args)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1537, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/__init__.py", line 171, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 268, in __init__
    self._configure_distributed_model(model)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 1069, in _configure_distributed_model
    self.module.to(self.device)
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2179, in to
    return super().to(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1160, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 833, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1158, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 108.00 MiB. GPU 2 has a total capacty of 79.35 GiB of which 62.19 MiB is free. Process 83512 has 8.31 GiB memory in use. Process 83514 has 8.31 GiB memory in use. Process 83515 has 8.31 GiB memory in use. Process 83513 has 21.09 GiB memory in use. Process 83517 has 8.31 GiB memory in use. Process 83516 has 8.31 GiB memory in use. Process 83518 has 8.31 GiB memory in use. Process 83511 has 8.31 GiB memory in use. Of the allocated memory 20.40 GiB is allocated by PyTorch, and 181.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 426, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1591, in train
    return inner_training_loop(
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1726, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1198, in prepare
    result = self._prepare_deepspeed(*args)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1537, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/__init__.py", line 171, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 268, in __init__
    self._configure_distributed_model(model)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 1069, in _configure_distributed_model
    self.module.to(self.device)
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2179, in to
    return super().to(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1160, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 833, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1158, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 108.00 MiB. GPU 4 has a total capacty of 79.35 GiB of which 62.19 MiB is free. Process 83512 has 8.31 GiB memory in use. Process 83514 has 8.31 GiB memory in use. Process 83515 has 21.09 GiB memory in use. Process 83513 has 8.31 GiB memory in use. Process 83517 has 8.31 GiB memory in use. Process 83516 has 8.31 GiB memory in use. Process 83518 has 8.31 GiB memory in use. Process 83511 has 8.31 GiB memory in use. Of the allocated memory 20.40 GiB is allocated by PyTorch, and 181.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 426, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1591, in train
    return inner_training_loop(
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1726, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1198, in prepare
    result = self._prepare_deepspeed(*args)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1537, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/__init__.py", line 171, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 268, in __init__
    self._configure_distributed_model(model)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 1069, in _configure_distributed_model
    self.module.to(self.device)
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2179, in to
    return super().to(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1160, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 833, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1158, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 108.00 MiB. GPU 5 has a total capacty of 79.35 GiB of which 64.19 MiB is free. Process 83512 has 8.31 GiB memory in use. Process 83514 has 8.31 GiB memory in use. Process 83515 has 8.31 GiB memory in use. Process 83513 has 8.31 GiB memory in use. Process 83517 has 8.31 GiB memory in use. Process 83516 has 21.09 GiB memory in use. Process 83518 has 8.31 GiB memory in use. Process 83511 has 8.31 GiB memory in use. Of the allocated memory 20.40 GiB is allocated by PyTorch, and 181.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 426, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1591, in train
    return inner_training_loop(
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1726, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1198, in prepare
    result = self._prepare_deepspeed(*args)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1537, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/__init__.py", line 171, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 268, in __init__
    self._configure_distributed_model(model)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 1069, in _configure_distributed_model
    self.module.to(self.device)
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2179, in to
    return super().to(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1160, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 833, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1158, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 108.00 MiB. GPU 3 has a total capacty of 79.35 GiB of which 62.19 MiB is free. Process 83512 has 8.31 GiB memory in use. Process 83514 has 21.09 GiB memory in use. Process 83515 has 8.31 GiB memory in use. Process 83513 has 8.31 GiB memory in use. Process 83517 has 8.31 GiB memory in use. Process 83516 has 8.31 GiB memory in use. Process 83518 has 8.31 GiB memory in use. Process 83511 has 8.31 GiB memory in use. Of the allocated memory 20.40 GiB is allocated by PyTorch, and 181.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 426, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1591, in train
    return inner_training_loop(
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1726, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1198, in prepare
    result = self._prepare_deepspeed(*args)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1537, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/__init__.py", line 171, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 268, in __init__
    self._configure_distributed_model(model)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 1069, in _configure_distributed_model
    self.module.to(self.device)
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2179, in to
    return super().to(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1160, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 833, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1158, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 108.00 MiB. GPU 1 has a total capacty of 79.35 GiB of which 62.19 MiB is free. Process 83512 has 21.09 GiB memory in use. Process 83514 has 8.31 GiB memory in use. Process 83515 has 8.31 GiB memory in use. Process 83513 has 8.31 GiB memory in use. Process 83517 has 8.31 GiB memory in use. Process 83516 has 8.31 GiB memory in use. Process 83518 has 8.31 GiB memory in use. Process 83511 has 8.31 GiB memory in use. Of the allocated memory 20.40 GiB is allocated by PyTorch, and 181.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 426, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1591, in train
    return inner_training_loop(
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1726, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1198, in prepare
    result = self._prepare_deepspeed(*args)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1537, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/__init__.py", line 171, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 268, in __init__
    self._configure_distributed_model(model)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 1109, in _configure_distributed_model
    self._broadcast_model()
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 1033, in _broadcast_model
    dist.broadcast(p, groups._get_broadcast_src_rank(), group=self.data_parallel_group)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/comm/comm.py", line 116, in log_wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/comm/comm.py", line 216, in broadcast
    return cdb.broadcast(tensor=tensor, src=src, group=group, async_op=async_op)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/comm/torch.py", line 188, in broadcast
    return torch.distributed.broadcast(tensor=tensor, src=src, group=group, async_op=async_op)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/distributed_c10d.py", line 1890, in broadcast
    work = group.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1194, unhandled cuda error, NCCL version 2.17.1
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 'invalid resource handle'
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 426, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1591, in train
    return inner_training_loop(
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1726, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1198, in prepare
    result = self._prepare_deepspeed(*args)
  File "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py", line 1537, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/__init__.py", line 171, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 268, in __init__
    self._configure_distributed_model(model)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 1109, in _configure_distributed_model
    self._broadcast_model()
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 1033, in _broadcast_model
    dist.broadcast(p, groups._get_broadcast_src_rank(), group=self.data_parallel_group)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/comm/comm.py", line 116, in log_wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/comm/comm.py", line 216, in broadcast
    return cdb.broadcast(tensor=tensor, src=src, group=group, async_op=async_op)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/comm/torch.py", line 188, in broadcast
    return torch.distributed.broadcast(tensor=tensor, src=src, group=group, async_op=async_op)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/distributed_c10d.py", line 1890, in broadcast
    work = group.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1194, unhandled cuda error, NCCL version 2.17.1
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 'invalid resource handle'
[2023-10-23 07:24:29,375] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 58244 closing signal SIGTERM
[2023-10-23 07:24:29,375] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 58250 closing signal SIGTERM
[2023-10-23 07:24:29,375] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 58251 closing signal SIGTERM
[2023-10-23 07:24:45,840] torch.distributed.run: [WARNING] 
[2023-10-23 07:24:45,840] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:24:45,840] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-10-23 07:24:45,840] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:24:50,372] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:24:50,404] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:24:50,404] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:24:50,474] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:24:50,475] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:24:50,521] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:24:50,531] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:24:50,540] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:24:51,042] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:24:51,042] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:24:51,081] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:24:51,081] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:24:51,096] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:24:51,096] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:24:51,125] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:24:51,125] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:24:51,170] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:24:51,170] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:24:51,202] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:24:51,202] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:24:51,246] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:24:51,246] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:24:51,246] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:24:51,282] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:24:51,282] [INFO] [comm.py:616:init_distributed] cdb=None
10/23/2023 07:24:51 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[INFO|configuration_utils.py:713] 2023-10-23 07:24:51,512 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
[INFO|configuration_utils.py:713] 2023-10-23 07:24:51,514 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
[INFO|configuration_utils.py:775] 2023-10-23 07:24:51,515 >> Model config SkyworkConfig {
  "_name_or_path": "/data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base",
  "architectures": [
    "SkyworkForCausalLM"
  ],
  "attention_bias": false,
  "auto_map": {
    "AutoConfig": "configuration_skywork.SkyworkConfig",
    "AutoModelForCausalLM": "modeling_skywork.SkyworkForCausalLM"
  },
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4608,
  "initializer_range": 0.01,
  "intermediate_size": 12288,
  "max_position_embeddings": 4096,
  "model_type": "skywork",
  "num_attention_heads": 36,
  "num_hidden_layers": 52,
  "num_key_value_heads": 36,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.34.0",
  "use_cache": true,
  "use_flash_attention": false,
  "vocab_size": 65519
}

[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:24:51,516 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:24:51,516 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:24:51,516 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:24:51,516 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:24:51,516 >> loading file tokenizer.json
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
[INFO|tokenization_utils.py:493] 2023-10-23 07:24:51,664 >> Adding <s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:24:51,664 >> Adding </s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:24:51,664 >> Adding <unk> to the vocabulary
10/23/2023 07:24:51 - INFO - __main__ - Start shuffling training dataset.
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
Loading cached shuffled indices for dataset at /data/user/liang.zhao/skywork-13b-opensource/data_cache/pt_train_demo/pt_train/train/cache-82bd44c04d4089ca.arrow
10/23/2023 07:24:51 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /data/user/liang.zhao/skywork-13b-opensource/data_cache/pt_train_demo/pt_train/train/cache-82bd44c04d4089ca.arrow
10/23/2023 07:24:51 - INFO - __main__ - shuffle successively!
10/23/2023 07:24:51 - INFO - __main__ - Num train_samples  321
10/23/2023 07:24:51 - INFO - __main__ - Training example:
10/23/2023 07:24:51 - INFO - __main__ - subtract the combined number of speeding tickets from the total number of tickets to find the combined number of parking tickets: 24 - 12 = <<24-12=12>>12
Now express Mark's number of parking tickets in terms of the number of parking tickets Sarah got: m = <<2=2>>2s
We know that m + s = 12, so substitute in the value of m from the previous step to get 2s + s = 12
Combine like terms to get 3s = 12
Divide both sides of the equation to get s = <<4=4>>4
Now multiply the number of parking tickets Sarah got by 2 to find the number Mark got: 4 * 2 = <<4*2=8>>8
#### 8<s> Cooper makes 7 apple pies a day. He does this for 12 days. Ashley then eats 50 of his pies. How many apple pies remain with Cooper? The number of pies Cooper makes in 12 days is 7 pies/day * 12 days = <<7*12=84>>84 apple pies.
After Ashley eats 50 of them, there are 84 pies  50 pies = <<84-50=34>>34 apple pies.
#### 34<s> Lindsey bought 2 exercise bands to intensify her workout.  Each band adds an extra 5 pounds of resistance to her workout.  If she doubles up both sets of bands and places them around her legs and picks up a 10-pound dumbbell, how much weight will she squat? She has 2 exercise bands that are both 5 pounds of resistance so thats 2*5 = <<2*5=10>>10 pounds
She has a pair of 10-pound dumbbells so thats 2*10 = <<10*2=20>>20 pounds
With both the bands and dumbbells, she will squat 10+20 = <<10+20=30>>30 pounds
#### 30<s> Wendy just started working at an Italian restaurant. She polished 50 small glasses and 10 more large glasses than small glasses. How many glasses did she polish? She polished 50 + 10 = <<50+10=60>>60 large glasses.
Therefore, Wendy polished 50 + 60 = <<50+60=110>>110 glasses.
#### 110<s> Miss Darlington has a basket of 20 blueberries. She picked 9 more baskets with the same amount of berries. How many blueberries did Miss Darlington have in all? Miss Darlington picked 9 x 20 = <<9*20=180>>180 blueberries more.
So she had a total of 180 + 20 = <<180+20=200>>200 blueberries.
#### 200<s> In a basketball game, Jon scored 3 points. Jack scored 5 points more than Jon, and Tom scored 4 less than the points of Jon and Jack together. How many points did they score altogether? Jack scored 3 + 5 = <<3+5=8>>8 points.
Together, Jon and Jack scored 8 + 3 = <<8+3=11>>11 points.
So, Tom scored 11 - 4 = <<11-4=7>>7 points.
Thus, Jon, Jack, and Tom scored a total of 3 + 8 + 7 = <<3+8+7=18>>18 points.
#### 18<s> In a shipping container, there are 10 crates. Each crate is filled with 6 boxes and each box is filled with 4 washing machines. A worker removes 1 washing machine from each box. There are no other changes. How many washing machines were removed from the shipping container? Initially, there were 6 boxes * 4 washing machines per box = <<6*4=24>>24 washing machines in each crate.
So there were 24 washing machines per crate * 10 crates = <<24*10=240>>240 washing machines in the shipping container.
A worker removes 1 washing machine from each box so there are now 4 original washing machines - 1 removed washing machine = <<4-1=3>>3 washing machines in each box.
This means there are 6 boxes * 3 washing machines per box = <<6*3=18>>18 washing machines in each crate.
So there are now 18 washing machines per crate * 10 crates = <<18*10=180>>180 washing machines in the shipping container.
The difference is how many machine washing machines were removed which is 240 initial washing machines  180 current washing machines = <<240-180=60>>60 washing machines.
#### 60<s> Darnell has 1000 square feet of fabric that he's using to make mini flags. He makes square flags that are 4 feet by 4 feet, wide rectangular flags that are 5 feet by 3 feet, and tall rectangular flags that are 3 feet by 5 feet. He has already made 16 square flags, 20 wide flags, and 10 tall flags. How many square feet of fabric does he have left? The square flags use 16 square feet of fabric per flag because four times four equals <<4*4=16>>16
The wide flags each use 15 feet of fabric per flag because five times three equals <<5*3=15>>15
The tall flags each use 15 feet of fabric per flag because five times three equals <<5*3=15>>15
He has used 256 square feet for the square flags because 16 times 16 equals <<16*16=256>>256
He has used 300 square feet for the wide flags because 20 times 15 equals <<20*15=300>>300
He has used 150 square feet for the tall flags because ten times 15 equals 150.
He has used 706 square feet because 256 plus 300 plus 150 equals <<256+300+150=706>>706.
He has 294 square feet left because 1,000 minus 706 equals <<1000-706=294>>294
#### 294<s> Matthias has 40 soccer balls and 15 basketballs. 30 soccer balls and 7 basketballs have a hole in them. How many balls in total does Matthias have without holes in them? Matthias has 40-30 = <<40-30=10>>10 soccer balls without holes.
Matthias has 15-7 = <<15-7=8>>8 basketballs without holes.
A total of 10+8 = <<10+8=18>>18 balls do not have holes.
#### 18<s> Jenny is scraping gum off the bottom of the seats in a stadium with two sections. Section A has 1 subsection with 60 seats and 3 subsections with 80 seats each. Section B has 20 more seats than 3 times as many seats as Section A has total. How many seats does Section B have? First find how many total seats are in the 80-seat subsections: 80 seats/subsection * 3 subsections = 240 seats
Then add the number of seats in the 60-seat section to find the total number of seats in Section A: 240 seats + 60 seats = <<240+60=300>>300 seats
Then triple that number: 300 seats * 3 = <<300*3=900>>900 seats
Then add 20 seats to find the total number of seats in Section B: 900 seats + 20 seats = <<900+20=920>>920 seats
#### 920<s> The running time of Beast of War: Armoured Command is 10 minutes longer than that of Alpha Epsilon, which is 30 minutes shorter than that of Millennium. If Millennium runs for 2 hours, what is the running time of Beast of War: Armoured Command in minutes? One hour contains 60 minutes so 2 hours contain 60*2 = <<2*60=120>>120 minutes
Alpha Epsilon's running time is 30 minutes less than that of Millennium (which runs for 120 minutes) hence 120-30 = <<120-30=90>>90 minutes
Beast of War: Armoured Command runs for 10 minutes more than Alpha Epsilon hence 90+10 = <<10+90=100>>100 minutes
#### 100<s> A packet of candy sweets has 30 cherry-flavored sweets, 40 strawberry-flavored sweets, and 50 pineapple-flavored sweets. Aaron eats half of each of the flavored sweets and gives 5 cherry-flavored sweets to his friend. How many sweets are still in the packet of candy? Aaron eats 1/2*30 sweets + 1/2*40 sweets + 1/2*50 sweets = <<1/2*30+1/2*40+1/2*50=60>>60 candy sweets.
The packet of candy sweets still has 60 sweets - 5 sweets = <<60-5=55>>55 candy sweets.
#### 55<s> Oliver has two bags of vegetables. Each bag weighs 1/6 as much as Jamess bag, which weighs 18kg. What is the combined weight of both Olivers bags? Each of Olivers bags weighs 18 kg * 1/6 =<<18*1/6=3>>3 kg.
Combined, both his bags weigh 3 kg * 2 = <<3*2=6>>6 kg.
#### 6<s> Greg's PPO algorithm obtained 90% of the possible reward on the CoinRun environment. CoinRun's maximum reward is half as much as the maximum ProcGen reward of 240. How much reward did Greg's PPO algorithm get? Half of much as ProcGen's maximum reward is 240/2=<<240/2=120>>120 reward
90% of CoinRun's maximum reward is 120*.9=<<120*.9=108>>108 reward
#### 108<s> Julia has a parrot and a rabbit. She buys food for both of the animals for $30 in total a week. Julia has the rabbit for 5 weeks, and the parrot for 3 weeks. How much money did Julia already spend on food for her animals, if the weekly cost of the rabbit food is $12? If the rabbit food costs $12 a week, then the parrot food costs $30 - $12 = $18 a week.
Julia has the parrot for 3 weeks, so she spent 3 weeks * $18/week = $<<3*18=54>>54 on her.
The rabbit is her only for 5 weeks, so she spent 5 weeks * $12/week = $<<5*12=60>>60 on him.
In total, Julia spent $54 + $60 = $<<54+60=114>>114 on food for her animals.
#### 114<s> Janet has 60 less than four times as many siblings as Masud. Carlos has 3/4 times as many siblings as Masud. If Masud has 60 siblings, how many more siblings does Janet have more than Carlos? If Masud has 60 siblings, and Carlos has 3/4 times as many siblings as Masud, Carlos has 3/4*60=<<60*3/4=45>>45 siblings.
Four times as many siblings as Masud has is 4*60=<<4*60=240>>240
Janet has 60 less than four times as many siblings as Masud, a total of 240-60=<<240-60=180>>180 siblings.
The number of siblings Janet have more than Carlos is 180-45=<<180-45=135>>135
#### 135<s> A highway is being extended from its current length of 200 miles up to 650 miles. 50 miles are built on the first day, and three times this amount are built on the second day.  How many miles still need to be added to the highway to finish extending it? The length of the highway that needs to be constructed is 650  200 = <<650-200=450>>450 miles.
After the first day, there are still 450  50 = <<450-50=400>>400 miles that need to be constructed.
On the second day, 50 miles * 3 = <<50*3=150>>150 miles are added to the highway.
This means that 400  150 = <<400-150=250>>250 miles still need to be added to the highway.
#### 250<s> Susan is making jewelry with a repeating pattern that has 3 green beads, 5 purple beads, and twice as many red beads as green beads. If the pattern repeats three times per bracelet and 5 times per necklace, how many beads does she need to make 1 bracelets and 10 necklaces? First find the number of red beads per repeat: 3 green * 2 red/green = <<3*2=6>>6 red
Then add the number of beads of each color to find the total number of bead per repeat: 6 beads + 3 beads + 5 beads = <<6+3+5=14>>14 beads
Then multiply the number of beads per repeat by the number of repeats per bracelet to find the number of beads per bracelet: 14 beads/repeat * 3 repeats/bracelet = <<14*3=42>>42 beads/bracelet
Then multiply the number of beads per repeat by the number of repeats per necklace to find the number of beads per necklace: 14 beads/repeat * 5 repeats/necklace = <<14*5=70>>70 beads/necklace
Then multiply the number of beads per necklace by the number of necklaces to find the total number of beads used in the necklaces: 70 beads/necklace * 10 necklaces = <<70*10=700>>700 beads
Then add the number of beads used in a bracelet to the number of beads in the necklaces to find the total number of beads used: 700 beads + 42 beads = <<700+42=742>>742 beads
#### 742<s> Janet counts 30 crows on the powerlines and 60% more hawks than crows. How many birds does she count total? First find how many more hawks than crows there are: 60% * 30 crows = <<60*.01*30=18>>18 crows
Then add that number to the number of crows to find the total number of hawks: 18 crows + 30 crows = <<18+30=48>>48 crows
Then add the number of crows to the number of hawks to find the total number of birds: 48 crows + 30 crows = <<48+30=78>>78 crows
#### 78<s> Joan has 180 socks. Two thirds of the socks are white, and the rest of the socks are blue. How many blue socks does Joan have? Joan has (180/3)*2 = <<(180/3)*2=120>>120 white socks.
The number of blue socks Joan has is 180-120 = <<180-120=60>>60.
#### 60<s> Simon collected treasures on the beach during his summer vacation. He collected a bucket of pearly seashells, a jar full of smooth sea glass, and a bag of ten sand dollars. If the jar holds three times as many pieces of glass as the bag does sand dollars, and the bucket holds five times as many seashells as the jar holds pieces of glass, how many treasures did Simon find on the beach? The jar holds 
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2577, in from_pretrained
    raise ValueError(
ValueError: DeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.
10/23/2023 07:24:51 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:24:51 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
10/23/2023 07:24:52 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2577, in from_pretrained
    raise ValueError(
ValueError: DeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.
10/23/2023 07:24:52 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True
10/23/2023 07:24:52 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:24:52 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2577, in from_pretrained
    raise ValueError(
ValueError: DeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16

torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2577, in from_pretrained
    raise ValueError(
ValueError: DeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2577, in from_pretrained
    raise ValueError(
ValueError: DeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2577, in from_pretrained
    raise ValueError(
ValueError: DeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2577, in from_pretrained
    raise ValueError(
ValueError: DeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.
10/23/2023 07:24:52 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Traceback (most recent call last):
  File "train/run_pt.py", line 454, in <module>
    main()
  File "train/run_pt.py", line 358, in main
    model = transformers.AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py", line 560, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py", line 2577, in from_pretrained
    raise ValueError(
ValueError: DeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.
[2023-10-23 07:24:55,949] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 60801) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train/run_pt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-23_07:24:55
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 60802)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-10-23_07:24:55
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 60803)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-10-23_07:24:55
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 60804)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-10-23_07:24:55
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 60805)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-10-23_07:24:55
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 60806)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-10-23_07:24:55
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 60807)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-10-23_07:24:55
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 60808)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-23_07:24:55
  host      : dsw-459-85b8f44fc-frbmh
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 60801)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[2023-10-23 07:25:34,044] torch.distributed.run: [WARNING] 
[2023-10-23 07:25:34,044] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:25:34,044] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-10-23 07:25:34,044] torch.distributed.run: [WARNING] *****************************************
[2023-10-23 07:25:39,003] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:25:39,009] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:25:39,014] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:25:39,091] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:25:39,122] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:25:39,128] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:25:39,148] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-23 07:25:39,171] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:25:39,633] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:25:39,633] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:25:39,653] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:25:39,654] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:25:39,668] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:25:39,668] [INFO] [comm.py:616:init_distributed] cdb=None
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:25:39,807] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:25:39,807] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:25:39,813] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:25:39,813] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:25:39,813] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2023-10-23 07:25:39,856] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:25:39,856] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:25:39,865] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:25:39,865] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-10-23 07:25:39,869] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-10-23 07:25:39,869] [INFO] [comm.py:616:init_distributed] cdb=None
10/23/2023 07:25:40 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[INFO|configuration_utils.py:713] 2023-10-23 07:25:40,069 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
[INFO|configuration_utils.py:713] 2023-10-23 07:25:40,070 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/config.json
[INFO|configuration_utils.py:775] 2023-10-23 07:25:40,071 >> Model config SkyworkConfig {
  "_name_or_path": "/data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base",
  "architectures": [
    "SkyworkForCausalLM"
  ],
  "attention_bias": false,
  "auto_map": {
    "AutoConfig": "configuration_skywork.SkyworkConfig",
    "AutoModelForCausalLM": "modeling_skywork.SkyworkForCausalLM"
  },
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4608,
  "initializer_range": 0.01,
  "intermediate_size": 12288,
  "max_position_embeddings": 4096,
  "model_type": "skywork",
  "num_attention_heads": 36,
  "num_hidden_layers": 52,
  "num_key_value_heads": 36,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.34.0",
  "use_cache": true,
  "use_flash_attention": false,
  "vocab_size": 65519
}

[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:25:40,072 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:25:40,072 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:25:40,072 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:25:40,072 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2041] 2023-10-23 07:25:40,072 >> loading file tokenizer.json
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
[INFO|tokenization_utils.py:493] 2023-10-23 07:25:40,221 >> Adding <s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:25:40,221 >> Adding </s> to the vocabulary
[INFO|tokenization_utils.py:493] 2023-10-23 07:25:40,221 >> Adding <unk> to the vocabulary
10/23/2023 07:25:40 - INFO - __main__ - Start shuffling training dataset.
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
Loading cached shuffled indices for dataset at /data/user/liang.zhao/skywork-13b-opensource/data_cache/pt_train_demo/pt_train/train/cache-82bd44c04d4089ca.arrow
10/23/2023 07:25:40 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /data/user/liang.zhao/skywork-13b-opensource/data_cache/pt_train_demo/pt_train/train/cache-82bd44c04d4089ca.arrow
10/23/2023 07:25:40 - INFO - __main__ - shuffle successively!
10/23/2023 07:25:40 - INFO - __main__ - Num train_samples  321
10/23/2023 07:25:40 - INFO - __main__ - Training example:
10/23/2023 07:25:40 - INFO - __main__ - subtract the combined number of speeding tickets from the total number of tickets to find the combined number of parking tickets: 24 - 12 = <<24-12=12>>12
Now express Mark's number of parking tickets in terms of the number of parking tickets Sarah got: m = <<2=2>>2s
We know that m + s = 12, so substitute in the value of m from the previous step to get 2s + s = 12
Combine like terms to get 3s = 12
Divide both sides of the equation to get s = <<4=4>>4
Now multiply the number of parking tickets Sarah got by 2 to find the number Mark got: 4 * 2 = <<4*2=8>>8
#### 8<s> Cooper makes 7 apple pies a day. He does this for 12 days. Ashley then eats 50 of his pies. How many apple pies remain with Cooper? The number of pies Cooper makes in 12 days is 7 pies/day * 12 days = <<7*12=84>>84 apple pies.
After Ashley eats 50 of them, there are 84 pies  50 pies = <<84-50=34>>34 apple pies.
#### 34<s> Lindsey bought 2 exercise bands to intensify her workout.  Each band adds an extra 5 pounds of resistance to her workout.  If she doubles up both sets of bands and places them around her legs and picks up a 10-pound dumbbell, how much weight will she squat? She has 2 exercise bands that are both 5 pounds of resistance so thats 2*5 = <<2*5=10>>10 pounds
She has a pair of 10-pound dumbbells so thats 2*10 = <<10*2=20>>20 pounds
With both the bands and dumbbells, she will squat 10+20 = <<10+20=30>>30 pounds
#### 30<s> Wendy just started working at an Italian restaurant. She polished 50 small glasses and 10 more large glasses than small glasses. How many glasses did she polish? She polished 50 + 10 = <<50+10=60>>60 large glasses.
Therefore, Wendy polished 50 + 60 = <<50+60=110>>110 glasses.
#### 110<s> Miss Darlington has a basket of 20 blueberries. She picked 9 more baskets with the same amount of berries. How many blueberries did Miss Darlington have in all? Miss Darlington picked 9 x 20 = <<9*20=180>>180 blueberries more.
So she had a total of 180 + 20 = <<180+20=200>>200 blueberries.
#### 200<s> In a basketball game, Jon scored 3 points. Jack scored 5 points more than Jon, and Tom scored 4 less than the points of Jon and Jack together. How many points did they score altogether? Jack scored 3 + 5 = <<3+5=8>>8 points.
Together, Jon and Jack scored 8 + 3 = <<8+3=11>>11 points.
So, Tom scored 11 - 4 = <<11-4=7>>7 points.
Thus, Jon, Jack, and Tom scored a total of 3 + 8 + 7 = <<3+8+7=18>>18 points.
#### 18<s> In a shipping container, there are 10 crates. Each crate is filled with 6 boxes and each box is filled with 4 washing machines. A worker removes 1 washing machine from each box. There are no other changes. How many washing machines were removed from the shipping container? Initially, there were 6 boxes * 4 washing machines per box = <<6*4=24>>24 washing machines in each crate.
So there were 24 washing machines per crate * 10 crates = <<24*10=240>>240 washing machines in the shipping container.
A worker removes 1 washing machine from each box so there are now 4 original washing machines - 1 removed washing machine = <<4-1=3>>3 washing machines in each box.
This means there are 6 boxes * 3 washing machines per box = <<6*3=18>>18 washing machines in each crate.
So there are now 18 washing machines per crate * 10 crates = <<18*10=180>>180 washing machines in the shipping container.
The difference is how many machine washing machines were removed which is 240 initial washing machines  180 current washing machines = <<240-180=60>>60 washing machines.
#### 60<s> Darnell has 1000 square feet of fabric that he's using to make mini flags. He makes square flags that are 4 feet by 4 feet, wide rectangular flags that are 5 feet by 3 feet, and tall rectangular flags that are 3 feet by 5 feet. He has already made 16 square flags, 20 wide flags, and 10 tall flags. How many square feet of fabric does he have left? The square flags use 16 square feet of fabric per flag because four times four equals <<4*4=16>>16
The wide flags each use 15 feet of fabric per flag because five times three equals <<5*3=15>>15
The tall flags each use 15 feet of fabric per flag because five times three equals <<5*3=15>>15
He has used 256 square feet for the square flags because 16 times 16 equals <<16*16=256>>256
He has used 300 square feet for the wide flags because 20 times 15 equals <<20*15=300>>300
He has used 150 square feet for the tall flags because ten times 15 equals 150.
He has used 706 square feet because 256 plus 300 plus 150 equals <<256+300+150=706>>706.
He has 294 square feet left because 1,000 minus 706 equals <<1000-706=294>>294
#### 294<s> Matthias has 40 soccer balls and 15 basketballs. 30 soccer balls and 7 basketballs have a hole in them. How many balls in total does Matthias have without holes in them? Matthias has 40-30 = <<40-30=10>>10 soccer balls without holes.
Matthias has 15-7 = <<15-7=8>>8 basketballs without holes.
A total of 10+8 = <<10+8=18>>18 balls do not have holes.
#### 18<s> Jenny is scraping gum off the bottom of the seats in a stadium with two sections. Section A has 1 subsection with 60 seats and 3 subsections with 80 seats each. Section B has 20 more seats than 3 times as many seats as Section A has total. How many seats does Section B have? First find how many total seats are in the 80-seat subsections: 80 seats/subsection * 3 subsections = 240 seats
Then add the number of seats in the 60-seat section to find the total number of seats in Section A: 240 seats + 60 seats = <<240+60=300>>300 seats
Then triple that number: 300 seats * 3 = <<300*3=900>>900 seats
Then add 20 seats to find the total number of seats in Section B: 900 seats + 20 seats = <<900+20=920>>920 seats
#### 920<s> The running time of Beast of War: Armoured Command is 10 minutes longer than that of Alpha Epsilon, which is 30 minutes shorter than that of Millennium. If Millennium runs for 2 hours, what is the running time of Beast of War: Armoured Command in minutes? One hour contains 60 minutes so 2 hours contain 60*2 = <<2*60=120>>120 minutes
Alpha Epsilon's running time is 30 minutes less than that of Millennium (which runs for 120 minutes) hence 120-30 = <<120-30=90>>90 minutes
Beast of War: Armoured Command runs for 10 minutes more than Alpha Epsilon hence 90+10 = <<10+90=100>>100 minutes
#### 100<s> A packet of candy sweets has 30 cherry-flavored sweets, 40 strawberry-flavored sweets, and 50 pineapple-flavored sweets. Aaron eats half of each of the flavored sweets and gives 5 cherry-flavored sweets to his friend. How many sweets are still in the packet of candy? Aaron eats 1/2*30 sweets + 1/2*40 sweets + 1/2*50 sweets = <<1/2*30+1/2*40+1/2*50=60>>60 candy sweets.
The packet of candy sweets still has 60 sweets - 5 sweets = <<60-5=55>>55 candy sweets.
#### 55<s> Oliver has two bags of vegetables. Each bag weighs 1/6 as much as Jamess bag, which weighs 18kg. What is the combined weight of both Olivers bags? Each of Olivers bags weighs 18 kg * 1/6 =<<18*1/6=3>>3 kg.
Combined, both his bags weigh 3 kg * 2 = <<3*2=6>>6 kg.
#### 6<s> Greg's PPO algorithm obtained 90% of the possible reward on the CoinRun environment. CoinRun's maximum reward is half as much as the maximum ProcGen reward of 240. How much reward did Greg's PPO algorithm get? Half of much as ProcGen's maximum reward is 240/2=<<240/2=120>>120 reward
90% of CoinRun's maximum reward is 120*.9=<<120*.9=108>>108 reward
#### 108<s> Julia has a parrot and a rabbit. She buys food for both of the animals for $30 in total a week. Julia has the rabbit for 5 weeks, and the parrot for 3 weeks. How much money did Julia already spend on food for her animals, if the weekly cost of the rabbit food is $12? If the rabbit food costs $12 a week, then the parrot food costs $30 - $12 = $18 a week.
Julia has the parrot for 3 weeks, so she spent 3 weeks * $18/week = $<<3*18=54>>54 on her.
The rabbit is her only for 5 weeks, so she spent 5 weeks * $12/week = $<<5*12=60>>60 on him.
In total, Julia spent $54 + $60 = $<<54+60=114>>114 on food for her animals.
#### 114<s> Janet has 60 less than four times as many siblings as Masud. Carlos has 3/4 times as many siblings as Masud. If Masud has 60 siblings, how many more siblings does Janet have more than Carlos? If Masud has 60 siblings, and Carlos has 3/4 times as many siblings as Masud, Carlos has 3/4*60=<<60*3/4=45>>45 siblings.
Four times as many siblings as Masud has is 4*60=<<4*60=240>>240
Janet has 60 less than four times as many siblings as Masud, a total of 240-60=<<240-60=180>>180 siblings.
The number of siblings Janet have more than Carlos is 180-45=<<180-45=135>>135
#### 135<s> A highway is being extended from its current length of 200 miles up to 650 miles. 50 miles are built on the first day, and three times this amount are built on the second day.  How many miles still need to be added to the highway to finish extending it? The length of the highway that needs to be constructed is 650  200 = <<650-200=450>>450 miles.
After the first day, there are still 450  50 = <<450-50=400>>400 miles that need to be constructed.
On the second day, 50 miles * 3 = <<50*3=150>>150 miles are added to the highway.
This means that 400  150 = <<400-150=250>>250 miles still need to be added to the highway.
#### 250<s> Susan is making jewelry with a repeating pattern that has 3 green beads, 5 purple beads, and twice as many red beads as green beads. If the pattern repeats three times per bracelet and 5 times per necklace, how many beads does she need to make 1 bracelets and 10 necklaces? First find the number of red beads per repeat: 3 green * 2 red/green = <<3*2=6>>6 red
Then add the number of beads of each color to find the total number of bead per repeat: 6 beads + 3 beads + 5 beads = <<6+3+5=14>>14 beads
Then multiply the number of beads per repeat by the number of repeats per bracelet to find the number of beads per bracelet: 14 beads/repeat * 3 repeats/bracelet = <<14*3=42>>42 beads/bracelet
Then multiply the number of beads per repeat by the number of repeats per necklace to find the number of beads per necklace: 14 beads/repeat * 5 repeats/necklace = <<14*5=70>>70 beads/necklace
Then multiply the number of beads per necklace by the number of necklaces to find the total number of beads used in the necklaces: 70 beads/necklace * 10 necklaces = <<70*10=700>>700 beads
Then add the number of beads used in a bracelet to the number of beads in the necklaces to find the total number of beads used: 700 beads + 42 beads = <<700+42=742>>742 beads
#### 742<s> Janet counts 30 crows on the powerlines and 60% more hawks than crows. How many birds does she count total? First find how many more hawks than crows there are: 60% * 30 crows = <<60*.01*30=18>>18 crows
Then add that number to the number of crows to find the total number of hawks: 18 crows + 30 crows = <<18+30=48>>48 crows
Then add the number of crows to the number of hawks to find the total number of birds: 48 crows + 30 crows = <<48+30=78>>78 crows
#### 78<s> Joan has 180 socks. Two thirds of the socks are white, and the rest of the socks are blue. How many blue socks does Joan have? Joan has (180/3)*2 = <<(180/3)*2=120>>120 white socks.
The number of blue socks Joan has is 180-120 = <<180-120=60>>60.
#### 60<s> Simon collected treasures on the beach during his summer vacation. He collected a bucket of pearly seashells, a jar full of smooth sea glass, and a bag of ten sand dollars. If the jar holds three times as many pieces of glass as the bag does sand dollars, and the bucket holds five times as many seashells as the jar holds pieces of glass, how many treasures did Simon find on the beach? The jar holds 
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
[INFO|modeling_utils.py:2990] 2023-10-23 07:25:40,301 >> loading weights file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/pytorch_model.bin.index.json
[INFO|modeling_utils.py:3076] 2023-10-23 07:25:40,302 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[INFO|configuration_utils.py:770] 2023-10-23 07:25:40,305 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "pad_token_id": 0
}

10/23/2023 07:25:40 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:25:40 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:25:40 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
10/23/2023 07:25:41 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
10/23/2023 07:25:41 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:25:41 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
10/23/2023 07:25:41 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
Ignored unknown kwarg option __type
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
train_dataset Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 321
})
torch_dtype: torch.bfloat16, compute_dtype: torch.bfloat16
[2023-10-23 07:25:48,751] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 13.85B parameters
Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/53 [00:00<?, ?it/s]Loading checkpoint shards:   2%|         | 1/53 [00:00<00:21,  2.47it/s]Loading checkpoint shards:   2%|         | 1/53 [00:00<00:21,  2.46it/s]Loading checkpoint shards:   2%|         | 1/53 [00:00<00:21,  2.46it/s]Loading checkpoint shards:   2%|         | 1/53 [00:00<00:21,  2.45it/s]Loading checkpoint shards:   2%|         | 1/53 [00:00<00:21,  2.44it/s]Loading checkpoint shards:   2%|         | 1/53 [00:00<00:21,  2.43it/s]Loading checkpoint shards:   2%|         | 1/53 [00:00<00:21,  2.39it/s]Loading checkpoint shards:   2%|         | 1/53 [00:00<00:24,  2.14it/s]Loading checkpoint shards:   4%|         | 2/53 [00:00<00:21,  2.40it/s]Loading checkpoint shards:   4%|         | 2/53 [00:00<00:21,  2.40it/s]Loading checkpoint shards:   4%|         | 2/53 [00:00<00:21,  2.40it/s]Loading checkpoint shards:   4%|         | 2/53 [00:00<00:21,  2.40it/s]Loading checkpoint shards:   4%|         | 2/53 [00:00<00:21,  2.39it/s]Loading checkpoint shards:   4%|         | 2/53 [00:00<00:21,  2.40it/s]Loading checkpoint shards:   4%|         | 2/53 [00:00<00:21,  2.33it/s]Loading checkpoint shards:   4%|         | 2/53 [00:00<00:22,  2.26it/s]Loading checkpoint shards:   6%|         | 3/53 [00:01<00:21,  2.38it/s]Loading checkpoint shards:   6%|         | 3/53 [00:01<00:21,  2.37it/s]Loading checkpoint shards:   6%|         | 3/53 [00:01<00:21,  2.37it/s]Loading checkpoint shards:   6%|         | 3/53 [00:01<00:21,  2.37it/s]Loading checkpoint shards:   6%|         | 3/53 [00:01<00:21,  2.35it/s]Loading checkpoint shards:   6%|         | 3/53 [00:01<00:21,  2.37it/s]Loading checkpoint shards:   6%|         | 3/53 [00:01<00:21,  2.35it/s]Loading checkpoint shards:   6%|         | 3/53 [00:01<00:21,  2.30it/s]Loading checkpoint shards:   8%|         | 4/53 [00:01<00:20,  2.37it/s]Loading checkpoint shards:   8%|         | 4/53 [00:01<00:20,  2.37it/s]Loading checkpoint shards:   8%|         | 4/53 [00:01<00:20,  2.37it/s]Loading checkpoint shards:   8%|         | 4/53 [00:01<00:20,  2.38it/s]Loading checkpoint shards:   8%|         | 4/53 [00:01<00:20,  2.37it/s]Loading checkpoint shards:   8%|         | 4/53 [00:01<00:20,  2.37it/s]Loading checkpoint shards:   8%|         | 4/53 [00:01<00:20,  2.36it/s]Loading checkpoint shards:   8%|         | 4/53 [00:01<00:21,  2.33it/s]Loading checkpoint shards:   9%|         | 5/53 [00:02<00:20,  2.37it/s]Loading checkpoint shards:   9%|         | 5/53 [00:02<00:20,  2.36it/s]Loading checkpoint shards:   9%|         | 5/53 [00:02<00:20,  2.36it/s]Loading checkpoint shards:   9%|         | 5/53 [00:02<00:20,  2.36it/s]Loading checkpoint shards:   9%|         | 5/53 [00:02<00:20,  2.36it/s]Loading checkpoint shards:   9%|         | 5/53 [00:02<00:20,  2.37it/s]Loading checkpoint shards:   9%|         | 5/53 [00:02<00:20,  2.38it/s]Loading checkpoint shards:   9%|         | 5/53 [00:02<00:21,  2.25it/s]Loading checkpoint shards:  11%|        | 6/53 [00:02<00:20,  2.29it/s]Loading checkpoint shards:  11%|        | 6/53 [00:02<00:20,  2.29it/s]Loading checkpoint shards:  11%|        | 6/53 [00:02<00:20,  2.29it/s]Loading checkpoint shards:  11%|        | 6/53 [00:02<00:20,  2.29it/s]Loading checkpoint shards:  11%|        | 6/53 [00:02<00:20,  2.29it/s]Loading checkpoint shards:  11%|        | 6/53 [00:02<00:20,  2.29it/s]Loading checkpoint shards:  11%|        | 6/53 [00:02<00:20,  2.29it/s]Loading checkpoint shards:  11%|        | 6/53 [00:02<00:19,  2.35it/s]Loading checkpoint shards:  13%|        | 7/53 [00:02<00:19,  2.37it/s]Loading checkpoint shards:  13%|        | 7/53 [00:02<00:19,  2.37it/s]Loading checkpoint shards:  13%|        | 7/53 [00:02<00:19,  2.37it/s]Loading checkpoint shards:  13%|        | 7/53 [00:02<00:19,  2.37it/s]Loading checkpoint shards:  13%|        | 7/53 [00:02<00:19,  2.37it/s]Loading checkpoint shards:  13%|        | 7/53 [00:02<00:19,  2.37it/s]Loading checkpoint shards:  13%|        | 7/53 [00:02<00:19,  2.37it/s]Loading checkpoint shards:  13%|        | 7/53 [00:02<00:19,  2.42it/s]Loading checkpoint shards:  15%|        | 8/53 [00:03<00:18,  2.43it/s]Loading checkpoint shards:  15%|        | 8/53 [00:03<00:18,  2.43it/s]Loading checkpoint shards:  15%|        | 8/53 [00:03<00:18,  2.43it/s]Loading checkpoint shards:  15%|        | 8/53 [00:03<00:18,  2.42it/s]Loading checkpoint shards:  15%|        | 8/53 [00:03<00:18,  2.42it/s]Loading checkpoint shards:  15%|        | 8/53 [00:03<00:18,  2.42it/s]Loading checkpoint shards:  15%|        | 8/53 [00:03<00:18,  2.43it/s]Loading checkpoint shards:  15%|        | 8/53 [00:03<00:18,  2.43it/s]Loading checkpoint shards:  17%|        | 9/53 [00:03<00:18,  2.42it/s]Loading checkpoint shards:  17%|        | 9/53 [00:03<00:18,  2.42it/s]Loading checkpoint shards:  17%|        | 9/53 [00:03<00:18,  2.42it/s]Loading checkpoint shards:  17%|        | 9/53 [00:03<00:18,  2.42it/s]Loading checkpoint shards:  17%|        | 9/53 [00:03<00:18,  2.42it/s]Loading checkpoint shards:  17%|        | 9/53 [00:03<00:18,  2.42it/s]Loading checkpoint shards:  17%|        | 9/53 [00:03<00:18,  2.41it/s]Loading checkpoint shards:  17%|        | 9/53 [00:03<00:18,  2.42it/s]Loading checkpoint shards:  19%|        | 10/53 [00:04<00:17,  2.43it/s]Loading checkpoint shards:  19%|        | 10/53 [00:04<00:17,  2.43it/s]Loading checkpoint shards:  19%|        | 10/53 [00:04<00:17,  2.43it/s]Loading checkpoint shards:  19%|        | 10/53 [00:04<00:17,  2.43it/s]Loading checkpoint shards:  19%|        | 10/53 [00:04<00:17,  2.43it/s]Loading checkpoint shards:  19%|        | 10/53 [00:04<00:17,  2.43it/s]Loading checkpoint shards:  19%|        | 10/53 [00:04<00:17,  2.43it/s]Loading checkpoint shards:  19%|        | 10/53 [00:04<00:17,  2.45it/s]Loading checkpoint shards:  21%|        | 11/53 [00:04<00:16,  2.48it/s]Loading checkpoint shards:  21%|        | 11/53 [00:04<00:16,  2.48it/s]Loading checkpoint shards:  21%|        | 11/53 [00:04<00:16,  2.48it/s]Loading checkpoint shards:  21%|        | 11/53 [00:04<00:16,  2.47it/s]Loading checkpoint shards:  21%|        | 11/53 [00:04<00:16,  2.47it/s]Loading checkpoint shards:  21%|        | 11/53 [00:04<00:16,  2.47it/s]Loading checkpoint shards:  21%|        | 11/53 [00:04<00:16,  2.47it/s]Loading checkpoint shards:  21%|        | 11/53 [00:04<00:16,  2.47it/s]Loading checkpoint shards:  23%|       | 12/53 [00:04<00:16,  2.48it/s]Loading checkpoint shards:  23%|       | 12/53 [00:04<00:16,  2.48it/s]Loading checkpoint shards:  23%|       | 12/53 [00:04<00:16,  2.48it/s]Loading checkpoint shards:  23%|       | 12/53 [00:04<00:16,  2.47it/s]Loading checkpoint shards:  23%|       | 12/53 [00:04<00:16,  2.47it/s]Loading checkpoint shards:  23%|       | 12/53 [00:04<00:16,  2.47it/s]Loading checkpoint shards:  23%|       | 12/53 [00:04<00:16,  2.48it/s]Loading checkpoint shards:  23%|       | 12/53 [00:05<00:16,  2.48it/s]Loading checkpoint shards:  25%|       | 13/53 [00:05<00:16,  2.49it/s]Loading checkpoint shards:  25%|       | 13/53 [00:05<00:16,  2.48it/s]Loading checkpoint shards:  25%|       | 13/53 [00:05<00:16,  2.48it/s]Loading checkpoint shards:  25%|       | 13/53 [00:05<00:16,  2.49it/s]Loading checkpoint shards:  25%|       | 13/53 [00:05<00:16,  2.48it/s]Loading checkpoint shards:  25%|       | 13/53 [00:05<00:16,  2.49it/s]Loading checkpoint shards:  25%|       | 13/53 [00:05<00:16,  2.49it/s]Loading checkpoint shards:  25%|       | 13/53 [00:05<00:16,  2.38it/s]Loading checkpoint shards:  26%|       | 14/53 [00:05<00:15,  2.45it/s]Loading checkpoint shards:  26%|       | 14/53 [00:05<00:15,  2.45it/s]Loading checkpoint shards:  26%|       | 14/53 [00:05<00:15,  2.44it/s]Loading checkpoint shards:  26%|       | 14/53 [00:05<00:15,  2.44it/s]Loading checkpoint shards:  26%|       | 14/53 [00:05<00:15,  2.45it/s]Loading checkpoint shards:  26%|       | 14/53 [00:05<00:15,  2.44it/s]Loading checkpoint shards:  26%|       | 14/53 [00:05<00:15,  2.48it/s]Loading checkpoint shards:  26%|       | 14/53 [00:05<00:16,  2.34it/s]Loading checkpoint shards:  28%|       | 15/53 [00:06<00:15,  2.38it/s]Loading checkpoint shards:  28%|       | 15/53 [00:06<00:15,  2.40it/s]Loading checkpoint shards:  28%|       | 15/53 [00:06<00:15,  2.38it/s]Loading checkpoint shards:  28%|       | 15/53 [00:06<00:16,  2.37it/s]Loading checkpoint shards:  28%|       | 15/53 [00:06<00:15,  2.38it/s]Loading checkpoint shards:  28%|       | 15/53 [00:06<00:15,  2.38it/s]Loading checkpoint shards:  28%|       | 15/53 [00:06<00:15,  2.38it/s]Loading checkpoint shards:  28%|       | 15/53 [00:06<00:15,  2.45it/s]Loading checkpoint shards:  30%|       | 16/53 [00:06<00:15,  2.46it/s]Loading checkpoint shards:  30%|       | 16/53 [00:06<00:14,  2.48it/s]Loading checkpoint shards:  30%|       | 16/53 [00:06<00:15,  2.46it/s]Loading checkpoint shards:  30%|       | 16/53 [00:06<00:15,  2.46it/s]Loading checkpoint shards:  30%|       | 16/53 [00:06<00:15,  2.46it/s]Loading checkpoint shards:  30%|       | 16/53 [00:06<00:15,  2.46it/s]Loading checkpoint shards:  30%|       | 16/53 [00:06<00:15,  2.45it/s]Loading checkpoint shards:  30%|       | 16/53 [00:06<00:14,  2.52it/s]Loading checkpoint shards:  32%|      | 17/53 [00:06<00:14,  2.52it/s]Loading checkpoint shards:  32%|      | 17/53 [00:06<00:14,  2.52it/s]Loading checkpoint shards:  32%|      | 17/53 [00:06<00:14,  2.52it/s]Loading checkpoint shards:  32%|      | 17/53 [00:06<00:14,  2.53it/s]Loading checkpoint shards:  32%|      | 17/53 [00:06<00:14,  2.52it/s]Loading checkpoint shards:  32%|      | 17/53 [00:06<00:14,  2.52it/s]Loading checkpoint shards:  32%|      | 17/53 [00:06<00:14,  2.52it/s]Loading checkpoint shards:  32%|      | 17/53 [00:07<00:14,  2.47it/s]Loading checkpoint shards:  34%|      | 18/53 [00:07<00:14,  2.48it/s]Loading checkpoint shards:  34%|      | 18/53 [00:07<00:14,  2.48it/s]Loading checkpoint shards:  34%|      | 18/53 [00:07<00:14,  2.48it/s]Loading checkpoint shards:  34%|      | 18/53 [00:07<00:14,  2.49it/s]Loading checkpoint shards:  34%|      | 18/53 [00:07<00:14,  2.48it/s]Loading checkpoint shards:  34%|      | 18/53 [00:07<00:14,  2.48it/s]Loading checkpoint shards:  34%|      | 18/53 [00:07<00:14,  2.48it/s]Loading checkpoint shards:  34%|      | 18/53 [00:07<00:14,  2.44it/s]Loading checkpoint shards:  36%|      | 19/53 [00:07<00:13,  2.45it/s]Loading checkpoint shards:  36%|      | 19/53 [00:07<00:13,  2.46it/s]Loading checkpoint shards:  36%|      | 19/53 [00:07<00:13,  2.45it/s]Loading checkpoint shards:  36%|      | 19/53 [00:07<00:13,  2.45it/s]Loading checkpoint shards:  36%|      | 19/53 [00:07<00:13,  2.45it/s]Loading checkpoint shards:  36%|      | 19/53 [00:07<00:13,  2.45it/s]Loading checkpoint shards:  36%|      | 19/53 [00:07<00:14,  2.35it/s]Loading checkpoint shards:  36%|      | 19/53 [00:07<00:14,  2.37it/s]Loading checkpoint shards:  38%|      | 20/53 [00:08<00:13,  2.38it/s]Loading checkpoint shards:  38%|      | 20/53 [00:08<00:13,  2.38it/s]Loading checkpoint shards:  38%|      | 20/53 [00:08<00:13,  2.38it/s]Loading checkpoint shards:  38%|      | 20/53 [00:08<00:13,  2.38it/s]Loading checkpoint shards:  38%|      | 20/53 [00:08<00:13,  2.38it/s]Loading checkpoint shards:  38%|      | 20/53 [00:08<00:14,  2.33it/s]Loading checkpoint shards:  38%|      | 20/53 [00:08<00:13,  2.39it/s]Loading checkpoint shards:  38%|      | 20/53 [00:08<00:14,  2.32it/s]Loading checkpoint shards:  40%|      | 21/53 [00:08<00:13,  2.39it/s]Loading checkpoint shards:  40%|      | 21/53 [00:08<00:13,  2.41it/s]Loading checkpoint shards:  40%|      | 21/53 [00:08<00:13,  2.39it/s]Loading checkpoint shards:  40%|      | 21/53 [00:08<00:13,  2.39it/s]Loading checkpoint shards:  40%|      | 21/53 [00:08<00:13,  2.39it/s]Loading checkpoint shards:  40%|      | 21/53 [00:08<00:13,  2.39it/s]Loading checkpoint shards:  40%|      | 21/53 [00:08<00:13,  2.43it/s]Loading checkpoint shards:  40%|      | 21/53 [00:08<00:12,  2.47it/s]Loading checkpoint shards:  42%|     | 22/53 [00:09<00:12,  2.44it/s]Loading checkpoint shards:  42%|     | 22/53 [00:09<00:12,  2.45it/s]Loading checkpoint shards:  42%|     | 22/53 [00:09<00:12,  2.44it/s]Loading checkpoint shards:  42%|     | 22/53 [00:09<00:12,  2.44it/s]Loading checkpoint shards:  42%|     | 22/53 [00:09<00:12,  2.47it/s]Loading checkpoint shards:  42%|     | 22/53 [00:09<00:12,  2.42it/s]Loading checkpoint shards:  42%|     | 22/53 [00:09<00:12,  2.41it/s]Loading checkpoint shards:  42%|     | 22/53 [00:09<00:12,  2.44it/s]Loading checkpoint shards:  43%|     | 23/53 [00:09<00:12,  2.45it/s]Loading checkpoint shards:  43%|     | 23/53 [00:09<00:12,  2.45it/s]Loading checkpoint shards:  43%|     | 23/53 [00:09<00:12,  2.45it/s]Loading checkpoint shards:  43%|     | 23/53 [00:09<00:12,  2.45it/s]Loading checkpoint shards:  43%|     | 23/53 [00:09<00:12,  2.45it/s]Loading checkpoint shards:  43%|     | 23/53 [00:09<00:12,  2.45it/s]Loading checkpoint shards:  43%|     | 23/53 [00:09<00:11,  2.52it/s]Loading checkpoint shards:  43%|     | 23/53 [00:09<00:12,  2.35it/s]Loading checkpoint shards:  45%|     | 24/53 [00:09<00:12,  2.41it/s]Loading checkpoint shards:  45%|     | 24/53 [00:09<00:11,  2.42it/s]Loading checkpoint shards:  45%|     | 24/53 [00:09<00:12,  2.41it/s]Loading checkpoint shards:  45%|     | 24/53 [00:09<00:12,  2.41it/s]Loading checkpoint shards:  45%|     | 24/53 [00:09<00:12,  2.41it/s]Loading checkpoint shards:  45%|     | 24/53 [00:09<00:11,  2.46it/s]Loading checkpoint shards:  45%|     | 24/53 [00:09<00:11,  2.45it/s]Loading checkpoint shards:  45%|     | 24/53 [00:10<00:12,  2.26it/s]Loading checkpoint shards:  47%|     | 25/53 [00:10<00:11,  2.35it/s]Loading checkpoint shards:  47%|     | 25/53 [00:10<00:11,  2.35it/s]Loading checkpoint shards:  47%|     | 25/53 [00:10<00:11,  2.36it/s]Loading checkpoint shards:  47%|     | 25/53 [00:10<00:11,  2.35it/s]Loading checkpoint shards:  47%|     | 25/53 [00:10<00:11,  2.40it/s]Loading checkpoint shards:  47%|     | 25/53 [00:10<00:11,  2.34it/s]Loading checkpoint shards:  47%|     | 25/53 [00:10<00:12,  2.30it/s]Loading checkpoint shards:  47%|     | 25/53 [00:10<00:12,  2.26it/s]Loading checkpoint shards:  49%|     | 26/53 [00:10<00:11,  2.32it/s]Loading checkpoint shards:  49%|     | 26/53 [00:10<00:11,  2.32it/s]Loading checkpoint shards:  49%|     | 26/53 [00:10<00:11,  2.32it/s]Loading checkpoint shards:  49%|     | 26/53 [00:10<00:11,  2.33it/s]Loading checkpoint shards:  49%|     | 26/53 [00:10<00:11,  2.32it/s]Loading checkpoint shards:  49%|     | 26/53 [00:10<00:11,  2.36it/s]Loading checkpoint shards:  49%|     | 26/53 [00:10<00:11,  2.31it/s]Loading checkpoint shards:  49%|     | 26/53 [00:10<00:11,  2.34it/s]Loading checkpoint shards:  51%|     | 27/53 [00:11<00:10,  2.44it/s]Loading checkpoint shards:  51%|     | 27/53 [00:11<00:10,  2.39it/s]Loading checkpoint shards:  51%|     | 27/53 [00:11<00:10,  2.39it/s]Loading checkpoint shards:  51%|     | 27/53 [00:11<00:10,  2.39it/s]Loading checkpoint shards:  51%|     | 27/53 [00:11<00:10,  2.40it/s]Loading checkpoint shards:  51%|     | 27/53 [00:11<00:10,  2.45it/s]Loading checkpoint shards:  51%|     | 27/53 [00:11<00:10,  2.39it/s]Loading checkpoint shards:  51%|     | 27/53 [00:11<00:10,  2.43it/s]Loading checkpoint shards:  53%|    | 28/53 [00:11<00:10,  2.45it/s]Loading checkpoint shards:  53%|    | 28/53 [00:11<00:10,  2.46it/s]Loading checkpoint shards:  53%|    | 28/53 [00:11<00:10,  2.46it/s]Loading checkpoint shards:  53%|    | 28/53 [00:11<00:10,  2.48it/s]Loading checkpoint shards:  53%|    | 28/53 [00:11<00:10,  2.46it/s]Loading checkpoint shards:  53%|    | 28/53 [00:11<00:10,  2.46it/s]Loading checkpoint shards:  53%|    | 28/53 [00:11<00:10,  2.45it/s]Loading checkpoint shards:  53%|    | 28/53 [00:11<00:10,  2.41it/s]Loading checkpoint shards:  55%|    | 29/53 [00:12<00:09,  2.42it/s]Loading checkpoint shards:  55%|    | 29/53 [00:12<00:09,  2.42it/s]Loading checkpoint shards:  55%|    | 29/53 [00:12<00:09,  2.42it/s]Loading checkpoint shards:  55%|    | 29/53 [00:12<00:09,  2.42it/s]Loading checkpoint shards:  55%|    | 29/53 [00:12<00:09,  2.45it/s]Loading checkpoint shards:  55%|    | 29/53 [00:12<00:09,  2.41it/s]Loading checkpoint shards:  55%|    | 29/53 [00:12<00:10,  2.31it/s]Loading checkpoint shards:  55%|    | 29/53 [00:12<00:10,  2.28it/s]Loading checkpoint shards:  57%|    | 30/53 [00:12<00:10,  2.29it/s]Loading checkpoint shards:  57%|    | 30/53 [00:12<00:10,  2.29it/s]Loading checkpoint shards:  57%|    | 30/53 [00:12<00:10,  2.29it/s]Loading checkpoint shards:  57%|    | 30/53 [00:12<00:10,  2.28it/s]Loading checkpoint shards:  57%|    | 30/53 [00:12<00:09,  2.30it/s]Loading checkpoint shards:  57%|    | 30/53 [00:12<00:10,  2.28it/s]Loading checkpoint shards:  57%|    | 30/53 [00:12<00:10,  2.29it/s]Loading checkpoint shards:  57%|    | 30/53 [00:12<00:10,  2.29it/s]Loading checkpoint shards:  58%|    | 31/53 [00:12<00:09,  2.32it/s]Loading checkpoint shards:  58%|    | 31/53 [00:12<00:09,  2.32it/s]Loading checkpoint shards:  58%|    | 31/53 [00:12<00:09,  2.32it/s]Loading checkpoint shards:  58%|    | 31/53 [00:12<00:09,  2.33it/s]Loading checkpoint shards:  58%|    | 31/53 [00:12<00:09,  2.31it/s]Loading checkpoint shards:  58%|    | 31/53 [00:12<00:09,  2.34it/s]Loading checkpoint shards:  58%|    | 31/53 [00:12<00:09,  2.41it/s]Loading checkpoint shards:  58%|    | 31/53 [00:12<00:09,  2.32it/s]Loading checkpoint shards:  60%|    | 32/53 [00:13<00:08,  2.39it/s]Loading checkpoint shards:  60%|    | 32/53 [00:13<00:08,  2.39it/s]Loading checkpoint shards:  60%|    | 32/53 [00:13<00:08,  2.39it/s]Loading checkpoint shards:  60%|    | 32/53 [00:13<00:08,  2.39it/s]Loading checkpoint shards:  60%|    | 32/53 [00:13<00:08,  2.42it/s]Loading checkpoint shards:  60%|    | 32/53 [00:13<00:08,  2.41it/s]Loading checkpoint shards:  60%|    | 32/53 [00:13<00:08,  2.44it/s]Loading checkpoint shards:  60%|    | 32/53 [00:13<00:08,  2.37it/s]Loading checkpoint shards:  62%|   | 33/53 [00:13<00:08,  2.45it/s]Loading checkpoint shards:  62%|   | 33/53 [00:13<00:08,  2.45it/s]Loading checkpoint shards:  62%|   | 33/53 [00:13<00:08,  2.45it/s]Loading checkpoint shards:  62%|   | 33/53 [00:13<00:08,  2.45it/s]Loading checkpoint shards:  62%|   | 33/53 [00:13<00:08,  2.46it/s]Loading checkpoint shards:  62%|   | 33/53 [00:13<00:08,  2.47it/s]Loading checkpoint shards:  62%|   | 33/53 [00:13<00:08,  2.49it/s]Loading checkpoint shards:  62%|   | 33/53 [00:13<00:08,  2.37it/s]Loading checkpoint shards:  64%|   | 34/53 [00:14<00:07,  2.42it/s]Loading checkpoint shards:  64%|   | 34/53 [00:14<00:07,  2.42it/s]Loading checkpoint shards:  64%|   | 34/53 [00:14<00:07,  2.42it/s]Loading checkpoint shards:  64%|   | 34/53 [00:14<00:07,  2.42it/s]Loading checkpoint shards:  64%|   | 34/53 [00:14<00:07,  2.43it/s]Loading checkpoint shards:  64%|   | 34/53 [00:14<00:07,  2.40it/s]Loading checkpoint shards:  64%|   | 34/53 [00:14<00:07,  2.42it/s]Loading checkpoint shards:  64%|   | 34/53 [00:14<00:08,  2.35it/s]Loading checkpoint shards:  66%|   | 35/53 [00:14<00:07,  2.39it/s]Loading checkpoint shards:  66%|   | 35/53 [00:14<00:07,  2.39it/s]Loading checkpoint shards:  66%|   | 35/53 [00:14<00:07,  2.39it/s]Loading checkpoint shards:  66%|   | 35/53 [00:14<00:07,  2.39it/s]Loading checkpoint shards:  66%|   | 35/53 [00:14<00:07,  2.39it/s]Loading checkpoint shards:  66%|   | 35/53 [00:14<00:07,  2.42it/s]Loading checkpoint shards:  66%|   | 35/53 [00:14<00:07,  2.39it/s]Loading checkpoint shards:  66%|   | 35/53 [00:14<00:07,  2.34it/s]Loading checkpoint shards:  68%|   | 36/53 [00:14<00:07,  2.37it/s]Loading checkpoint shards:  68%|   | 36/53 [00:14<00:07,  2.37it/s]Loading checkpoint shards:  68%|   | 36/53 [00:14<00:07,  2.37it/s]Loading checkpoint shards:  68%|   | 36/53 [00:14<00:07,  2.37it/s]Loading checkpoint shards:  68%|   | 36/53 [00:14<00:07,  2.40it/s]Loading checkpoint shards:  68%|   | 36/53 [00:14<00:07,  2.37it/s]Loading checkpoint shards:  68%|   | 36/53 [00:14<00:07,  2.37it/s]Loading checkpoint shards:  68%|   | 36/53 [00:15<00:07,  2.41it/s]Loading checkpoint shards:  70%|   | 37/53 [00:15<00:06,  2.42it/s]Loading checkpoint shards:  70%|   | 37/53 [00:15<00:06,  2.42it/s]Loading checkpoint shards:  70%|   | 37/53 [00:15<00:06,  2.42it/s]Loading checkpoint shards:  70%|   | 37/53 [00:15<00:06,  2.42it/s]Loading checkpoint shards:  70%|   | 37/53 [00:15<00:06,  2.45it/s]Loading checkpoint shards:  70%|   | 37/53 [00:15<00:06,  2.44it/s]Loading checkpoint shards:  70%|   | 37/53 [00:15<00:06,  2.42it/s]Loading checkpoint shards:  70%|   | 37/53 [00:15<00:06,  2.48it/s]Loading checkpoint shards:  72%|  | 38/53 [00:15<00:06,  2.50it/s]Loading checkpoint shards:  72%|  | 38/53 [00:15<00:06,  2.50it/s]Loading checkpoint shards:  72%|  | 38/53 [00:15<00:06,  2.50it/s]Loading checkpoint shards:  72%|  | 38/53 [00:15<00:05,  2.52it/s]Loading checkpoint shards:  72%|  | 38/53 [00:15<00:06,  2.50it/s]Loading checkpoint shards:  72%|  | 38/53 [00:15<00:05,  2.56it/s]Loading checkpoint shards:  72%|  | 38/53 [00:15<00:05,  2.51it/s]Loading checkpoint shards:  72%|  | 38/53 [00:15<00:05,  2.50it/s]Loading checkpoint shards:  74%|  | 39/53 [00:16<00:05,  2.56it/s]Loading checkpoint shards:  74%|  | 39/53 [00:16<00:05,  2.56it/s]Loading checkpoint shards:  74%|  | 39/53 [00:16<00:05,  2.57it/s]Loading checkpoint shards:  74%|  | 39/53 [00:16<00:05,  2.58it/s]Loading checkpoint shards:  74%|  | 39/53 [00:16<00:05,  2.56it/s]Loading checkpoint shards:  74%|  | 39/53 [00:16<00:05,  2.54it/s]Loading checkpoint shards:  74%|  | 39/53 [00:16<00:05,  2.54it/s]Loading checkpoint shards:  74%|  | 39/53 [00:16<00:05,  2.49it/s]Loading checkpoint shards:  75%|  | 40/53 [00:16<00:05,  2.49it/s]Loading checkpoint shards:  75%|  | 40/53 [00:16<00:05,  2.49it/s]Loading checkpoint shards:  75%|  | 40/53 [00:16<00:05,  2.49it/s]Loading checkpoint shards:  75%|  | 40/53 [00:16<00:05,  2.49it/s]Loading checkpoint shards:  75%|  | 40/53 [00:16<00:05,  2.50it/s]Loading checkpoint shards:  75%|  | 40/53 [00:16<00:05,  2.49it/s]Loading checkpoint shards:  75%|  | 40/53 [00:16<00:05,  2.47it/s]Loading checkpoint shards:  75%|  | 40/53 [00:16<00:05,  2.51it/s]Loading checkpoint shards:  77%|  | 41/53 [00:16<00:04,  2.51it/s]Loading checkpoint shards:  77%|  | 41/53 [00:16<00:04,  2.51it/s]Loading checkpoint shards:  77%|  | 41/53 [00:16<00:04,  2.51it/s]Loading checkpoint shards:  77%|  | 41/53 [00:16<00:04,  2.53it/s]Loading checkpoint shards:  77%|  | 41/53 [00:16<00:04,  2.51it/s]Loading checkpoint shards:  77%|  | 41/53 [00:16<00:04,  2.50it/s]Loading checkpoint shards:  77%|  | 41/53 [00:16<00:04,  2.50it/s]Loading checkpoint shards:  77%|  | 41/53 [00:16<00:04,  2.54it/s]Loading checkpoint shards:  79%|  | 42/53 [00:17<00:04,  2.53it/s]Loading checkpoint shards:  79%|  | 42/53 [00:17<00:04,  2.55it/s]Loading checkpoint shards:  79%|  | 42/53 [00:17<00:04,  2.54it/s]Loading checkpoint shards:  79%|  | 42/53 [00:17<00:04,  2.53it/s]Loading checkpoint shards:  79%|  | 42/53 [00:17<00:04,  2.55it/s]Loading checkpoint shards:  79%|  | 42/53 [00:17<00:04,  2.53it/s]Loading checkpoint shards:  79%|  | 42/53 [00:17<00:04,  2.54it/s]Loading checkpoint shards:  79%|  | 42/53 [00:17<00:04,  2.47it/s]Loading checkpoint shards:  81%|  | 43/53 [00:17<00:04,  2.49it/s]Loading checkpoint shards:  81%|  | 43/53 [00:17<00:04,  2.49it/s]Loading checkpoint shards:  81%|  | 43/53 [00:17<00:03,  2.50it/s]Loading checkpoint shards:  81%|  | 43/53 [00:17<00:04,  2.49it/s]Loading checkpoint shards:  81%|  | 43/53 [00:17<00:03,  2.51it/s]Loading checkpoint shards:  81%|  | 43/53 [00:17<00:04,  2.49it/s]Loading checkpoint shards:  81%|  | 43/53 [00:17<00:04,  2.48it/s]Loading checkpoint shards:  81%|  | 43/53 [00:17<00:04,  2.45it/s]Loading checkpoint shards:  83%| | 44/53 [00:18<00:03,  2.48it/s]Loading checkpoint shards:  83%| | 44/53 [00:18<00:03,  2.47it/s]Loading checkpoint shards:  83%| | 44/53 [00:18<00:03,  2.47it/s]Loading checkpoint shards:  83%| | 44/53 [00:18<00:03,  2.47it/s]Loading checkpoint shards:  83%| | 44/53 [00:18<00:03,  2.47it/s]Loading checkpoint shards:  83%| | 44/53 [00:18<00:03,  2.48it/s]Loading checkpoint shards:  83%| | 44/53 [00:18<00:03,  2.44it/s]Loading checkpoint shards:  83%| | 44/53 [00:18<00:03,  2.44it/s]Loading checkpoint shards:  85%| | 45/53 [00:18<00:03,  2.45it/s]Loading checkpoint shards:  85%| | 45/53 [00:18<00:03,  2.45it/s]Loading checkpoint shards:  85%| | 45/53 [00:18<00:03,  2.45it/s]Loading checkpoint shards:  85%| | 45/53 [00:18<00:03,  2.45it/s]Loading checkpoint shards:  85%| | 45/53 [00:18<00:03,  2.46it/s]Loading checkpoint shards:  85%| | 45/53 [00:18<00:03,  2.45it/s]Loading checkpoint shards:  85%| | 45/53 [00:18<00:03,  2.43it/s]Loading checkpoint shards:  85%| | 45/53 [00:18<00:03,  2.43it/s]Loading checkpoint shards:  87%| | 46/53 [00:18<00:02,  2.43it/s]Loading checkpoint shards:  87%| | 46/53 [00:18<00:02,  2.43it/s]Loading checkpoint shards:  87%| | 46/53 [00:18<00:02,  2.43it/s]Loading checkpoint shards:  87%| | 46/53 [00:18<00:02,  2.43it/s]Loading checkpoint shards:  87%| | 46/53 [00:18<00:02,  2.44it/s]Loading checkpoint shards:  87%| | 46/53 [00:18<00:02,  2.43it/s]Loading checkpoint shards:  87%| | 46/53 [00:18<00:02,  2.43it/s]Loading checkpoint shards:  87%| | 46/53 [00:19<00:02,  2.48it/s]Loading checkpoint shards:  89%| | 47/53 [00:19<00:02,  2.48it/s]Loading checkpoint shards:  89%| | 47/53 [00:19<00:02,  2.48it/s]Loading checkpoint shards:  89%| | 47/53 [00:19<00:02,  2.48it/s]Loading checkpoint shards:  89%| | 47/53 [00:19<00:02,  2.48it/s]Loading checkpoint shards:  89%| | 47/53 [00:19<00:02,  2.49it/s]Loading checkpoint shards:  89%| | 47/53 [00:19<00:02,  2.48it/s]Loading checkpoint shards:  89%| | 47/53 [00:19<00:02,  2.48it/s]Loading checkpoint shards:  89%| | 47/53 [00:19<00:02,  2.42it/s]Loading checkpoint shards:  91%| | 48/53 [00:19<00:02,  2.43it/s]Loading checkpoint shards:  91%| | 48/53 [00:19<00:02,  2.45it/s]Loading checkpoint shards:  91%| | 48/53 [00:19<00:02,  2.43it/s]Loading checkpoint shards:  91%| | 48/53 [00:19<00:02,  2.43it/s]Loading checkpoint shards:  91%| | 48/53 [00:19<00:02,  2.43it/s]Loading checkpoint shards:  91%| | 48/53 [00:19<00:02,  2.44it/s]Loading checkpoint shards:  91%| | 48/53 [00:19<00:02,  2.44it/s]Loading checkpoint shards:  91%| | 48/53 [00:19<00:02,  2.41it/s]Loading checkpoint shards:  92%|| 49/53 [00:20<00:01,  2.43it/s]Loading checkpoint shards:  92%|| 49/53 [00:20<00:01,  2.42it/s]Loading checkpoint shards:  92%|| 49/53 [00:20<00:01,  2.42it/s]Loading checkpoint shards:  92%|| 49/53 [00:20<00:01,  2.42it/s]Loading checkpoint shards:  92%|| 49/53 [00:20<00:01,  2.42it/s]Loading checkpoint shards:  92%|| 49/53 [00:20<00:01,  2.42it/s]Loading checkpoint shards:  92%|| 49/53 [00:20<00:01,  2.42it/s]Loading checkpoint shards:  92%|| 49/53 [00:20<00:01,  2.40it/s]Loading checkpoint shards:  94%|| 50/53 [00:20<00:01,  2.40it/s]Loading checkpoint shards:  94%|| 50/53 [00:20<00:01,  2.39it/s]Loading checkpoint shards:  94%|| 50/53 [00:20<00:01,  2.39it/s]Loading checkpoint shards:  94%|| 50/53 [00:20<00:01,  2.39it/s]Loading checkpoint shards:  94%|| 50/53 [00:20<00:01,  2.39it/s]Loading checkpoint shards:  94%|| 50/53 [00:20<00:01,  2.40it/s]Loading checkpoint shards:  94%|| 50/53 [00:20<00:01,  2.39it/s]Loading checkpoint shards:  94%|| 50/53 [00:20<00:01,  2.27it/s]Loading checkpoint shards:  96%|| 51/53 [00:21<00:00,  2.29it/s]Loading checkpoint shards:  96%|| 51/53 [00:21<00:00,  2.29it/s]Loading checkpoint shards:  96%|| 51/53 [00:21<00:00,  2.29it/s]Loading checkpoint shards:  96%|| 51/53 [00:21<00:00,  2.29it/s]Loading checkpoint shards:  96%|| 51/53 [00:21<00:00,  2.29it/s]Loading checkpoint shards:  96%|| 51/53 [00:21<00:00,  2.29it/s]Loading checkpoint shards:  96%|| 51/53 [00:21<00:00,  2.26it/s]Loading checkpoint shards:  96%|| 51/53 [00:21<00:00,  2.36it/s]Loading checkpoint shards:  98%|| 52/53 [00:21<00:00,  2.35it/s]Loading checkpoint shards:  98%|| 52/53 [00:21<00:00,  2.35it/s]Loading checkpoint shards:  98%|| 52/53 [00:21<00:00,  2.35it/s]Loading checkpoint shards:  98%|| 52/53 [00:21<00:00,  2.35it/s]Loading checkpoint shards:  98%|| 52/53 [00:21<00:00,  2.35it/s]Loading checkpoint shards:  98%|| 52/53 [00:21<00:00,  2.35it/s]Loading checkpoint shards:  98%|| 52/53 [00:21<00:00,  2.35it/s]Loading checkpoint shards:  98%|| 52/53 [00:21<00:00,  2.40it/s]Loading checkpoint shards: 100%|| 53/53 [00:22<00:00,  1.98it/s]Loading checkpoint shards: 100%|| 53/53 [00:22<00:00,  2.39it/s]
Loading checkpoint shards: 100%|| 53/53 [00:22<00:00,  1.98it/s]Loading checkpoint shards: 100%|| 53/53 [00:22<00:00,  2.39it/s]
Loading checkpoint shards: 100%|| 53/53 [00:22<00:00,  1.98it/s]Loading checkpoint shards: 100%|| 53/53 [00:22<00:00,  2.39it/s]
Loading checkpoint shards: 100%|| 53/53 [00:22<00:00,  1.98it/s]Loading checkpoint shards: 100%|| 53/53 [00:22<00:00,  2.39it/s]
Loading checkpoint shards: 100%|| 53/53 [00:22<00:00,  1.98it/s]Loading checkpoint shards: 100%|| 53/53 [00:22<00:00,  2.39it/s]
[INFO|modeling_utils.py:3775] 2023-10-23 07:26:11,028 >> All model checkpoint weights were used when initializing SkyworkForCausalLM.

[INFO|modeling_utils.py:3783] 2023-10-23 07:26:11,028 >> All the weights of SkyworkForCausalLM were initialized from the model checkpoint at /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base.
If your task is similar to the task the model of the checkpoint was trained on, you can already use SkyworkForCausalLM for predictions without further training.
[INFO|configuration_utils.py:728] 2023-10-23 07:26:11,032 >> loading configuration file /data/shared/public/liang.zhao/skywork-13b-models/skywork-13b-base/generation_config.json
[INFO|configuration_utils.py:770] 2023-10-23 07:26:11,032 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "do_sample": true,
  "eos_token_id": 2,
  "max_length": 4096,
  "pad_token_id": 0,
  "temperature": 0.6,
  "top_p": 0.9
}

10/23/2023 07:26:11 - INFO - __main__ - Model vocab size: 0
Loading checkpoint shards: 100%|| 53/53 [00:22<00:00,  1.98it/s]Loading checkpoint shards: 100%|| 53/53 [00:22<00:00,  2.39it/s]
Loading checkpoint shards: 100%|| 53/53 [00:22<00:00,  1.96it/s]Loading checkpoint shards: 100%|| 53/53 [00:22<00:00,  2.38it/s]
Loading checkpoint shards: 100%|| 53/53 [00:22<00:00,  1.96it/s]Loading checkpoint shards: 100%|| 53/53 [00:22<00:00,  2.38it/s]
10/23/2023 07:26:11 - INFO - __main__ - len(tokenizer):65519
10/23/2023 07:26:11 - INFO - __main__ - Resize model vocab size to 65519
[INFO|modeling_utils.py:1617] 2023-10-23 07:26:11,377 >> You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 65519. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[INFO|trainer.py:576] 2023-10-23 07:26:11,551 >> max_steps is given, it will override any value given in num_train_epochs
[INFO|deepspeed.py:303] 2023-10-23 07:26:11,686 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /root/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /root/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /root/.cache/torch_extensions/py38_cu121/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.5672335624694824 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.5672571659088135 seconds
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /root/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /root/.cache/torch_extensions/py38_cu121/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1
[2023-10-23 07:26:16,345] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.561838150024414 seconds
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /root/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /root/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /root/.cache/torch_extensions/py38_cu121/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /root/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /root/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /root/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.9471189975738525 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.9506828784942627 seconds
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.971525192260742 seconds
Time to load cpu_adam op: 3.011228322982788 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.025294780731201 seconds
[2023-10-23 07:26:21,944] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-10-23 07:26:21,946] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-10-23 07:26:21,946] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-10-23 07:26:21,965] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-10-23 07:26:21,965] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-10-23 07:26:21,965] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2023-10-23 07:26:21,965] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[2023-10-23 07:26:22,115] [INFO] [utils.py:785:see_memory_usage] Stage 3 initialize beginning
[2023-10-23 07:26:22,116] [INFO] [utils.py:786:see_memory_usage] MA 1.23 GB         Max_MA 2.45 GB         CA 2.35 GB         Max_CA 3 GB 
[2023-10-23 07:26:22,116] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 123.53 GB, percent = 6.1%
[2023-10-23 07:26:22,118] [INFO] [stage3.py:117:__init__] Reduce bucket size 10000000
[2023-10-23 07:26:22,118] [INFO] [stage3.py:118:__init__] Prefetch bucket size 10000000
[2023-10-23 07:26:22,214] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2023-10-23 07:26:22,215] [INFO] [utils.py:786:see_memory_usage] MA 1.23 GB         Max_MA 1.23 GB         CA 2.35 GB         Max_CA 2 GB 
[2023-10-23 07:26:22,215] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 123.53 GB, percent = 6.1%
Parameter Offload: Total persistent parameters: 483840 in 105 params
[2023-10-23 07:26:22,378] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2023-10-23 07:26:22,379] [INFO] [utils.py:786:see_memory_usage] MA 0.1 GB         Max_MA 1.23 GB         CA 2.35 GB         Max_CA 2 GB 
[2023-10-23 07:26:22,379] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 123.68 GB, percent = 6.1%
[2023-10-23 07:26:22,481] [INFO] [utils.py:785:see_memory_usage] Before creating fp16 partitions
[2023-10-23 07:26:22,482] [INFO] [utils.py:786:see_memory_usage] MA 0.1 GB         Max_MA 0.1 GB         CA 2.35 GB         Max_CA 2 GB 
[2023-10-23 07:26:22,482] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 123.68 GB, percent = 6.1%
[2023-10-23 07:26:25,211] [INFO] [utils.py:785:see_memory_usage] After creating fp16 partitions: 3
[2023-10-23 07:26:25,211] [INFO] [utils.py:786:see_memory_usage] MA 0.1 GB         Max_MA 0.1 GB         CA 2.35 GB         Max_CA 2 GB 
[2023-10-23 07:26:25,212] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 143.22 GB, percent = 7.1%
[2023-10-23 07:26:25,352] [INFO] [utils.py:785:see_memory_usage] Before creating fp32 partitions
[2023-10-23 07:26:25,353] [INFO] [utils.py:786:see_memory_usage] MA 0.1 GB         Max_MA 0.1 GB         CA 2.35 GB         Max_CA 2 GB 
[2023-10-23 07:26:25,353] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 145.13 GB, percent = 7.2%
[2023-10-23 07:26:27,979] [INFO] [utils.py:785:see_memory_usage] After creating fp32 partitions
[2023-10-23 07:26:27,979] [INFO] [utils.py:786:see_memory_usage] MA 0.1 GB         Max_MA 0.1 GB         CA 2.35 GB         Max_CA 2 GB 
[2023-10-23 07:26:27,980] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 190.28 GB, percent = 9.4%
[2023-10-23 07:26:28,121] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-10-23 07:26:28,122] [INFO] [utils.py:786:see_memory_usage] MA 0.1 GB         Max_MA 0.1 GB         CA 2.35 GB         Max_CA 2 GB 
[2023-10-23 07:26:28,122] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 195.35 GB, percent = 9.7%
[2023-10-23 07:26:35,550] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-10-23 07:26:35,551] [INFO] [utils.py:786:see_memory_usage] MA 0.1 GB         Max_MA 0.1 GB         CA 2.35 GB         Max_CA 2 GB 
[2023-10-23 07:26:35,551] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 345.42 GB, percent = 17.1%
[2023-10-23 07:26:35,552] [INFO] [stage3.py:424:_setup_for_real_optimizer] optimizer state initialized
[2023-10-23 07:26:36,968] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-10-23 07:26:36,969] [INFO] [utils.py:786:see_memory_usage] MA 0.12 GB         Max_MA 1.25 GB         CA 2.35 GB         Max_CA 2 GB 
[2023-10-23 07:26:36,969] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 371.27 GB, percent = 18.4%
[2023-10-23 07:26:36,969] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-10-23 07:26:36,969] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-10-23 07:26:36,969] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2023-10-23 07:26:36,969] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[2023-10-23 07:26:36,970] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-10-23 07:26:36,970] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-10-23 07:26:36,970] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   amp_params ................... False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   bfloat16_enabled ............. True
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa0501422e0>
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   dump_state ................... False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... None
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   fp16_auto_cast ............... None
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   fp16_enabled ................. False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 4
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 1
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   loss_scale ................... 1.0
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-10-23 07:26:36,971] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   pld_params ................... False
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   steps_per_print .............. inf
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   train_batch_size ............. 32
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   world_size ................... 8
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=10000000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=10000000 param_persistence_threshold=100000 model_persistence_threshold=sys.maxsize max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   zero_enabled ................. True
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-10-23 07:26:36,972] [INFO] [config.py:964:print]   zero_optimization_stage ...... 3
[2023-10-23 07:26:36,972] [INFO] [config.py:950:print_user_config]   json = {
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 1, 
    "steps_per_print": inf, 
    "gradient_accumulation_steps": 4, 
    "wall_clock_breakdown": false, 
    "zero_optimization": {
        "stage": 3, 
        "contiguous_gradients": true, 
        "stage3_max_live_parameters": 1.000000e+09, 
        "stage3_max_reuse_distance": 1.000000e+09, 
        "stage3_prefetch_bucket_size": 1.000000e+07, 
        "stage3_param_persistence_threshold": 1.000000e+05, 
        "reduce_bucket_size": 1.000000e+07, 
        "sub_group_size": 1.000000e+09, 
        "offload_optimizer": {
            "device": "cpu"
        }, 
        "offload_param": {
            "device": "cpu"
        }
    }, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
[INFO|trainer.py:1760] 2023-10-23 07:26:36,972 >> ***** Running training *****
[INFO|trainer.py:1761] 2023-10-23 07:26:36,972 >>   Num examples = 321
[INFO|trainer.py:1762] 2023-10-23 07:26:36,972 >>   Num Epochs = 100
[INFO|trainer.py:1763] 2023-10-23 07:26:36,972 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:1766] 2023-10-23 07:26:36,972 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1767] 2023-10-23 07:26:36,972 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:1768] 2023-10-23 07:26:36,972 >>   Total optimization steps = 1,000
[INFO|trainer.py:1769] 2023-10-23 07:26:36,974 >>   Number of trainable parameters = 13,854,113,280
[INFO|integration_utils.py:722] 2023-10-23 07:26:36,975 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: zhaol-nlp (skywork). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /data/user/liang.zhao/skywork-13b-opensource/wandb/run-20231023_072638-ez8f99o8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Skywork-13B-Base-pt-zero2-peaklr1e-4-steps1000-gbs32-maxlen
wandb:  View project at https://wandb.ai/skywork/skywork-13b-opensource
wandb:  View run at https://wandb.ai/skywork/skywork-13b-opensource/runs/ez8f99o8
  0%|          | 0/1000 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/zero/stage3.py:1252: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/zero/stage3.py:1252: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/zero/stage3.py:1252: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/zero/stage3.py:1252: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/zero/stage3.py:1252: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/zero/stage3.py:1252: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/zero/stage3.py:1252: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/zero/stage3.py:1252: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
  0%|          | 1/1000 [00:38<10:43:46, 38.67s/it]                                                   {'loss': 0.8272, 'learning_rate': 5e-06, 'epoch': 0.1}
  0%|          | 1/1000 [00:38<10:43:46, 38.67s/it]  0%|          | 2/1000 [01:15<10:28:35, 37.79s/it]                                                   {'loss': 0.8552, 'learning_rate': 1e-05, 'epoch': 0.2}
  0%|          | 2/1000 [01:15<10:28:35, 37.79s/it]  0%|          | 3/1000 [01:53<10:25:27, 37.64s/it]                                                   {'loss': 0.8136, 'learning_rate': 1.5e-05, 'epoch': 0.29}
  0%|          | 3/1000 [01:53<10:25:27, 37.64s/it]  0%|          | 4/1000 [02:29<10:17:41, 37.21s/it]                                                   {'loss': 0.7988, 'learning_rate': 2e-05, 'epoch': 0.39}
  0%|          | 4/1000 [02:29<10:17:41, 37.21s/it]